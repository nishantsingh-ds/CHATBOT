{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a516168",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The `chat.py` file connects with the previous code train_sequential.ipynb by utilizing the model and other components that were trained and saved in that notebook. Here's how the connection works:\n",
    "\n",
    "### 1. **Model Training and Saving in the Previous Code**:\n",
    "   - In the previous notebook, we built and trained a chatbot using a deep learning model (with Keras and TensorFlow).\n",
    "   - After training the model on the `intents2.json` data (which contains patterns and responses for various intents), we saved the model, tokenizer, and label encoder to disk. The model (`chat_model.h5`), tokenizer (`tokenizer.pickle`), and label encoder (`label_encoder.pickle`) were stored as files for later use.\n",
    "\n",
    "### 2. **Loading Saved Components in `chat.py`**:\n",
    "   - **Model**: The first step in the `chat.py` file is to load the trained model (`chat_model.h5`) using the `keras.models.load_model()` function. This model contains the learned weights and architecture that were built during the training process.\n",
    "   \n",
    "   - **Tokenizer**: The tokenizer, saved as a `.pickle` file, is loaded using Python's `pickle` module. The tokenizer is responsible for converting the user input (text) into sequences of integers that the model can understand. It maps each word in the input to a corresponding integer from its vocabulary.\n",
    "   \n",
    "   - **Label Encoder**: Similarly, the label encoder, also saved as a `.pickle` file, is loaded to convert the model's output (numerical class labels) back into human-readable tags (the chatbot's intents). The label encoder ensures that the output classes (like \"greeting\", \"booking\", etc.) are correctly mapped from their encoded form back into the original labels.\n",
    "\n",
    "### 3. **Using the Loaded Components in `chat.py`**:\n",
    "   - **User Input**: In the `chat()` function, the program enters an infinite loop, waiting for user input.\n",
    "   \n",
    "   - **Tokenizing User Input**: When the user types a message, the `tokenizer.texts_to_sequences()` function is used to convert the input into a sequence of integers based on the learned vocabulary from the training data.\n",
    "   \n",
    "   - **Model Prediction**: The tokenized and padded input is passed to the model for prediction. The model generates an output that represents the likelihood of each intent. This output is processed to find the intent with the highest probability.\n",
    "   \n",
    "   - **Label Decoding**: The predicted label (intent) is decoded back into its human-readable form using the `label_encoder.inverse_transform()`.\n",
    "   \n",
    "   - **Response Selection**: Based on the predicted intent, the corresponding response(s) from the `intents2.json` file are selected. The chatbot randomly picks one of these responses and displays it to the user.\n",
    "\n",
    "### 4. **Interactive Chatbot**:\n",
    "   - This loop of receiving user input, predicting the intent, and displaying the response continues until the user types \"quit\".\n",
    "   - The chatbot uses the knowledge and components saved during the training phase (the model, tokenizer, and label encoder) to make intelligent predictions and provide appropriate responses.\n",
    "\n",
    "### In Summary:\n",
    "- **Connection Flow**: The `chat.py` file utilizes the trained model, tokenizer, and label encoder from the previous notebook to process and predict user input during a real-time interaction. The entire process leverages the model’s learned weights and preprocessing tools, which were generated in the earlier training phase, to make the chatbot functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67cc035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi\n",
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 113ms/step\n",
      "ChatBot: hello thanks for checking in, how can i help you\n",
      "User: Reservation\n",
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step\n",
      "ChatBot: You can make an online reservation through this website, we have already inserted the guidance in the help section on this website, or please call the regional help desk 0774365562 \n",
      "User: tax\n",
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step\n",
      "ChatBot: this is different for each rooms and facilities or type of accommondation, for more information please check the rooms by clicking on the name of the room as you are interested\n",
      "User: thanks\n",
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step\n",
      "ChatBot: My pleasure\n",
      "User: bye\n",
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step\n",
      "ChatBot: bye bye\n",
      "User: quit\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open('C:/Users/nisha/Downloads/CHATBOT-20241115T051416Z-001/CHATBOT/intents2.json', encoding='utf-8') as data_file:\n",
    "    data = json.load(data_file)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model.h5')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "\n",
    "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
