{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764fec98",
   "metadata": {},
   "source": [
    "# Advanced Chatbot Using RNN, LSTM, BiRNN, and Encoder-Decoder Architectures\n",
    "\n",
    "This project leverages advanced Recurrent Neural Network (RNN) architectures like LSTM (Long Short-Term Memory), BiRNN (Bidirectional RNN), and Encoder-Decoder networks to build a sophisticated chatbot. These models are well-suited for handling sequential data and are particularly effective for tasks involving natural language processing (NLP), such as chatbot development.\n",
    "\n",
    "### Key Components of the Project\n",
    "\n",
    "1. **Recurrent Neural Networks (RNNs)**:\n",
    "   - RNNs are designed to handle sequential data, which is essential for text processing tasks. They maintain a hidden state that captures information from previous time steps, making them suitable for understanding the context in a conversation.\n",
    "\n",
    "2. **Long Short-Term Memory (LSTM)**:\n",
    "   - LSTM is a special type of RNN that overcomes the limitations of vanilla RNNs by addressing the vanishing gradient problem. It is capable of remembering long-term dependencies in the data, which is crucial for understanding longer dialogues and context in conversations.\n",
    "\n",
    "3. **Bidirectional RNN (BiRNN)**:\n",
    "   - A BiRNN processes the input data in both forward and backward directions, capturing context from both past and future tokens. This is particularly useful in NLP tasks where context from both sides of a word or sentence is important for accurate predictions.\n",
    "\n",
    "4. **Encoder-Decoder Architecture**:\n",
    "   - The Encoder-Decoder model is a popular architecture for sequence-to-sequence tasks, where one sequence (e.g., a user’s input) is mapped to another sequence (e.g., the chatbot’s response). The encoder processes the input sequence and encodes it into a fixed-length context vector, while the decoder generates the output sequence based on this encoded information.\n",
    "\n",
    "### Benefits of Using These Advanced Architectures\n",
    "\n",
    "- **Handling Long-Term Dependencies**: LSTM and BiRNNs are particularly effective for remembering long-term dependencies in conversations, which helps the chatbot maintain context across multiple turns.\n",
    "- **Improved Accuracy**: The encoder-decoder architecture is highly effective in generating meaningful responses in sequence-to-sequence tasks, leading to more coherent and contextually relevant replies.\n",
    "- **Advanced NLP Capabilities**: By combining these models, the chatbot can handle more complex queries, understand nuanced dialogues, and produce more sophisticated responses.\n",
    "\n",
    "### Why Use These Models Over Simpler Architectures?\n",
    "\n",
    "While simpler models like Feedforward Neural Networks and Sequential models (as used in the previous project) can be effective, RNNs, LSTMs, BiRNNs, and Encoder-Decoder architectures are specifically designed to process sequences. They are particularly beneficial for NLP tasks because they can capture the temporal relationships and context inherent in language, leading to a more intelligent and context-aware chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee22a1b",
   "metadata": {},
   "source": [
    "Here is a breakdown of the code, including descriptions for each section that you can use in a markdown cell:\n",
    "\n",
    "---\n",
    "\n",
    "### Importing Required Libraries\n",
    "\n",
    "This section imports the necessary libraries for building, training, and evaluating the chatbot model.\n",
    "\n",
    "- `json`: Used to load and parse the dataset (in this case, `intents2.json`) containing the patterns, tags, and responses.\n",
    "- `numpy`: Essential for numerical operations, such as handling arrays and matrices for data manipulation.\n",
    "- `train_test_split`: From `sklearn.model_selection`, used for splitting the dataset into training and testing sets.\n",
    "- `LabelEncoder`: From `sklearn.preprocessing`, used to encode the categorical labels (tags) into numerical values for model training.\n",
    "- `Tokenizer`: From `tensorflow.keras.preprocessing.text`, used for converting text into a sequence of tokens for the neural network to process.\n",
    "- `pad_sequences`: From `tensorflow.keras.utils`, used to pad sequences to ensure consistent input size for the model.\n",
    "- `matplotlib.pyplot`: For plotting graphs, useful for visualizing training progress (e.g., accuracy or loss curves).\n",
    "- `Sequential`: From `tensorflow.keras.models`, used to define the deep learning model as a linear stack of layers.\n",
    "- `Embedding`, `LSTM`, `SimpleRNN`, `Dense`, `Bidirectional`: Keras layers used to define the neural network architecture. `Embedding` is for word embeddings, `LSTM` and `SimpleRNN` are types of recurrent neural networks, and `Dense` is used for fully connected layers. `Bidirectional` is used to enhance the LSTM or RNN model by processing data in both forward and backward directions.\n",
    "- `RepeatVector`: A layer used in sequence-to-sequence models, particularly in encoder-decoder architectures, to repeat the encoded input for decoding.\n",
    "\n",
    "---\n",
    "\n",
    "This setup lays the foundation for loading data, processing it, and defining the deep learning model architecture using Keras, which will then be used to build and train a chatbot capable of understanding and responding to user queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a9fa9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, SimpleRNN, Dense, Bidirectional  # Add any layers needed\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea63e8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Loading and Preprocessing the Dataset\n",
    "\n",
    "This section loads the intent data from a JSON file and preprocesses it to extract the necessary information for training the chatbot model.\n",
    "\n",
    "- **Loading the JSON Data**:\n",
    "  - The code reads the `intents2.json` file using the `json.load()` method to load the contents into a Python dictionary. This file contains various user queries (patterns) mapped to their respective tags and possible responses.\n",
    "  \n",
    "- **Preprocessing the Data**:\n",
    "  - **Extracting Training Sentences and Labels**:\n",
    "    - A loop iterates through each intent in the dataset. For each intent, its `patterns` (user queries) are added to `training_sentences` and its `tag` (category of the query) is added to `training_labels`. These two lists will be used as input and output for training the chatbot model.\n",
    "  \n",
    "  - **Extracting Responses**:\n",
    "    - Each intent also contains responses. These are collected and added to the `responses` list. This will be used later for generating chatbot replies based on the predicted intent.\n",
    "  \n",
    "  - **Storing Unique Labels**:\n",
    "    - The code ensures that all unique intent tags are stored in the `labels` list, which is important for encoding the labels before model training.\n",
    "\n",
    "The end result of this preprocessing step is that we have:\n",
    "- `training_sentences`: A list of user queries (patterns).\n",
    "- `training_labels`: A list of tags corresponding to each query.\n",
    "- `responses`: A list of possible responses for each tag.\n",
    "- `labels`: A list of unique intent tags to help with label encoding.\n",
    "\n",
    "---\n",
    "\n",
    "This step prepares the data for the subsequent stages, including tokenization, padding, and encoding, which will be used to train the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "711768f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the intents data from the JSON file\n",
    "with open('C:/Users/nisha/Downloads/CHATBOT-20241115T051416Z-001/CHATBOT/intents2.json', encoding='utf-8') as data_file:\n",
    "    data = json.load(data_file)\n",
    "\n",
    "# Preprocess the data\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []\n",
    "responses = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    responses.append(intent['responses'])\n",
    "    \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60736c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Label Encoding and Text Tokenization\n",
    "\n",
    "This section prepares the data for the neural network by encoding the labels (intent tags) and tokenizing the user input sentences.\n",
    "\n",
    "- **Label Encoding**:\n",
    "  - **Using `LabelEncoder`**:\n",
    "    - The `LabelEncoder` from `sklearn.preprocessing` is used to convert the categorical labels (intent tags) into numerical format. The `fit_transform()` function encodes the `training_labels` into numerical values, which are stored in the `labels_encoded` array. This is necessary because machine learning models typically work with numerical data.\n",
    "\n",
    "- **Text Tokenization**:\n",
    "  - **Using `Tokenizer`**:\n",
    "    - The `Tokenizer` from Keras is used to convert the `training_sentences` (user input queries) into sequences of integers. Each word in the training sentences is assigned a unique integer based on its frequency in the corpus. \n",
    "    - The `fit_on_texts()` method is used to build the word index, which is a dictionary of words mapped to unique integer indices. \n",
    "    - The `vocab_size` is determined by the length of the word index plus one (to account for padding).\n",
    "\n",
    "  - **Converting Sentences to Sequences**:\n",
    "    - The `texts_to_sequences()` method is used to convert the `training_sentences` into sequences of integers based on the word index.\n",
    "\n",
    "- **Padding the Sequences**:\n",
    "  - **Ensuring Uniform Sequence Length**:\n",
    "    - Since input sequences for neural networks need to have a consistent length, the `pad_sequences()` function from Keras is used to ensure that all sequences are padded to the maximum sequence length (`max_len`).\n",
    "    - The padding is added at the end of the sequences (`padding='post'`), ensuring that the input to the model is of uniform length.\n",
    "\n",
    "The result of this step is:\n",
    "- `labels_encoded`: A numerical representation of the intent tags.\n",
    "- `X`: A padded sequence of integers representing the tokenized sentences, ready to be used as input for training the model.\n",
    "\n",
    "---\n",
    "\n",
    "This step prepares the data for model training by converting the text data into numerical format and ensuring that the input sequences have a consistent length for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85a02bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels (intent tags) using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(training_labels)\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "X = tokenizer.texts_to_sequences(training_sentences)\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_len = max([len(seq) for seq in X])  # maximum sequence length\n",
    "X = pad_sequences(X, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66adf45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Splitting Data into Training and Test Sets\n",
    "\n",
    "This step involves splitting the prepared data (`X` for sentences and `labels_encoded` for intent tags) into training and test datasets.\n",
    "\n",
    "- **`train_test_split()`**:\n",
    "  - The `train_test_split()` function from `sklearn.model_selection` is used to randomly divide the data into training and testing sets. This is essential for evaluating the model’s performance on unseen data, ensuring that it generalizes well rather than just memorizing the training data.\n",
    "  \n",
    "  - **Arguments**:\n",
    "    - `X`: The input data (tokenized and padded sentences).\n",
    "    - `labels_encoded`: The corresponding labels (numerical intent tags).\n",
    "    - `test_size=0.2`: This indicates that 20% of the data will be used for testing, and the remaining 80% will be used for training.\n",
    "    - `random_state=42`: This sets a fixed random seed for reproducibility. Using the same `random_state` ensures that the split will be the same each time the code is run, which is important for consistency in experiments.\n",
    "\n",
    "- **Output**:\n",
    "  - `X_train`, `y_train`: The training data (input sentences and corresponding intent labels).\n",
    "  - `X_test`, `y_test`: The test data (input sentences and corresponding intent labels), which will be used to evaluate the performance of the trained model.\n",
    "\n",
    "---\n",
    "\n",
    "This step ensures that the model is trained on one portion of the data (`X_train` and `y_train`) and evaluated on a separate, unseen portion (`X_test` and `y_test`), helping prevent overfitting and giving a better estimate of the model’s real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f29f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706aea3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Model Definitions: LSTM, RNN, Bidirectional RNN (BRNN), and Encoder-Decoder\n",
    "\n",
    "In this section, we define four distinct models for text classification, each utilizing a different architecture. These models include **LSTM (Long Short-Term Memory)**, **RNN (Recurrent Neural Network)**, **Bidirectional RNN (BRNN)**, and **Encoder-Decoder**. All models are built using the Keras Sequential API and are designed for intent classification from text input. Below is a detailed explanation of each model's components, their values, and their significance in sequence processing tasks:\n",
    "\n",
    "#### 1. **LSTM (Long Short-Term Memory) Model**:\n",
    "   - **Purpose**: LSTM is a type of recurrent neural network (RNN) designed to handle sequences where long-term dependencies exist. It is capable of learning and remembering information for long periods, making it suitable for tasks where context from earlier in the sequence is important, such as in natural language processing (NLP).\n",
    "   - **Architecture**:\n",
    "     - **Embedding Layer**:\n",
    "       - The `Embedding` layer transforms integer-encoded words into dense vectors of fixed size. Here, we set the vocabulary size (`vocab_size`) and the dimensionality of the embeddings (64). The input length (`max_len`) defines the maximum length of sequences to ensure all inputs have the same length.\n",
    "       - **`vocab_size`** represents the number of unique words in the dataset (i.e., the total words plus one for padding).\n",
    "       - **`64`** indicates the dimensionality of the word embeddings, meaning each word will be represented by a vector of length 64. Larger values can capture more complex relationships but increase computational cost.\n",
    "       - **`max_len`** is the maximum sequence length. Any input longer than this is truncated, and shorter inputs are padded.\n",
    "     - **LSTM Layer**:\n",
    "       - The `LSTM(64, activation='tanh', return_sequences=False)` layer is the core of the LSTM model. It uses 64 units to process the input sequence and apply the `tanh` activation function. The `return_sequences=False` ensures that only the final output is passed to the next layer, which is appropriate for classification tasks where the sequence is summarized into a single output.\n",
    "     - **Dense Layers**:\n",
    "       - A fully connected `Dense(16, activation='relu')` layer with 16 units and ReLU activation is added to introduce non-linearity into the network. This helps the model to learn more complex patterns.\n",
    "     - **Output Layer**:\n",
    "       - The final `Dense(len(labels), activation='softmax')` layer predicts the class for each input sequence. The number of units in this layer corresponds to the number of unique classes (`len(labels)`), with softmax activation ensuring the output values represent class probabilities.\n",
    "   - **Loss and Optimizer**:\n",
    "     - **Loss Function**: `sparse_categorical_crossentropy` is used because the task is a multi-class classification problem, where each sequence corresponds to one class (intent).\n",
    "     - **Optimizer**: Adam optimizer is chosen for its efficiency in training deep learning models by adapting the learning rate based on the gradients.\n",
    "\n",
    "#### 2. **RNN (Recurrent Neural Network) Model**:\n",
    "   - **Purpose**: The RNN model processes sequential data by maintaining a hidden state across time steps. However, unlike LSTMs, RNNs struggle with long-term dependencies due to vanishing gradient problems, making them more suited for tasks with short-term dependencies or simpler sequence relationships.\n",
    "   - **Architecture**:\n",
    "     - **Embedding Layer**:\n",
    "       - The `Embedding` layer works as described in the LSTM model, transforming word indices into dense word embeddings.\n",
    "     - **RNN Layer**:\n",
    "       - `SimpleRNN(64, activation='tanh', return_sequences=False)` defines an RNN with 64 units and `tanh` activation. This simple RNN processes the sequence step by step and updates its internal state. Like the LSTM model, `return_sequences=False` means that only the final output is passed to the next layer.\n",
    "     - **Dense Layers**:\n",
    "       - The same fully connected dense layer with ReLU activation is used to add complexity and allow the model to learn non-linear relationships.\n",
    "     - **Output Layer**:\n",
    "       - The output layer is the same as the LSTM model and uses a softmax activation to predict the intent class for each sequence.\n",
    "   - **Loss and Optimizer**:\n",
    "     - **Loss Function** and **Optimizer**: Same as the LSTM model, using sparse categorical cross-entropy and Adam optimizer.\n",
    "\n",
    "#### 3. **Bidirectional RNN (BRNN) Model**:\n",
    "   - **Purpose**: Bidirectional RNNs process the input sequence in both directions: from past to future (forward) and future to past (backward). This allows the model to capture context from both sides of the sequence, making it especially useful when both past and future information are important for understanding the sequence.\n",
    "   - **Architecture**:\n",
    "     - **Embedding Layer**: Same as the previous models.\n",
    "     - **Bidirectional RNN Layer**:\n",
    "       - `Bidirectional(LSTM(64, activation='tanh'))` applies LSTM units in both forward and backward directions. This bidirectional architecture allows the model to use both past and future context for each time step, potentially improving performance over unidirectional models.\n",
    "     - **Dense Layers**:\n",
    "       - A `Dense(16, activation='relu')` layer is included to capture complex patterns in the data.\n",
    "     - **Output Layer**:\n",
    "       - The output layer is the same as the LSTM model, using softmax activation to predict the intent class.\n",
    "   - **Loss and Optimizer**:\n",
    "     - **Loss Function** and **Optimizer**: Same as the LSTM model, using sparse categorical cross-entropy and Adam optimizer.\n",
    "\n",
    "#### 4. **Encoder-Decoder Model**:\n",
    "   - **Purpose**: The Encoder-Decoder architecture is typically used in sequence-to-sequence tasks, where the input and output sequences have different lengths. The encoder processes the input sequence into a context vector (a fixed-size summary), and the decoder generates the output sequence from this context. This model is useful when the input sequence should be transformed into an output class or another sequence.\n",
    "   - **Architecture**:\n",
    "     - **Encoder Part**:\n",
    "       - The encoder is an `LSTM` layer that processes the input sequence. It outputs a context vector that summarizes the information of the entire sequence.\n",
    "     - **RepeatVector**:\n",
    "       - `RepeatVector(max_len)` repeats the context vector for each time step in the sequence, effectively preparing it for the decoder.\n",
    "     - **Decoder Part**:\n",
    "       - The decoder is another `LSTM` layer, which processes the repeated context vector and generates the output.\n",
    "     - **Dense Layer**:\n",
    "       - A fully connected layer is used for the output, predicting the intent class for each input sequence.\n",
    "   - **Loss and Optimizer**:\n",
    "     - **Loss Function** and **Optimizer**: Same as the previous models, using sparse categorical cross-entropy and Adam optimizer.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Key Values and Model Architecture:\n",
    "\n",
    "- **`vocab_size`**: This represents the total number of unique words in the dataset. It is crucial for the embedding layer to know how many distinct words exist in the text data. We add `1` to account for padding.\n",
    "  \n",
    "- **`64`**: This value indicates the dimensionality of the word embeddings and the number of units in the LSTM, RNN, and other recurrent layers. A larger value can capture more complex relationships within the data but requires more computational resources.\n",
    "\n",
    "- **`max_len`**: The maximum sequence length, which determines how long each input sequence should be. Sequences longer than `max_len` will be truncated, and shorter ones will be padded. This ensures that all input data has the same shape, which is necessary for training.\n",
    "\n",
    "- **`len(labels)`**: The number of unique intent classes (tags) in the dataset. This determines the number of neurons in the output layer, where each neuron corresponds to a class.\n",
    "\n",
    "These models aim to compare different architectures for sequence classification tasks, and each one brings unique strengths. The LSTM model is well-suited for longer sequences with complex relationships, while the RNN is more basic and works well for simpler problems. The Bidirectional RNN improves performance by processing sequences in both directions, and the Encoder-Decoder architecture is used for sequence transformation tasks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed7719ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models as functions (LSTM, RNN, BRNN, Encoder-Decoder)\n",
    "def build_lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 64, input_length=max_len))\n",
    "    model.add(LSTM(64, activation='tanh', return_sequences=False))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(len(labels), activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 64, input_length=max_len))\n",
    "    model.add(SimpleRNN(64, activation='tanh', return_sequences=False))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(len(labels), activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def build_brnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 64, input_length=max_len))\n",
    "    model.add(Bidirectional(LSTM(64, activation='tanh')))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(len(labels), activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_encoder_decoder_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Encoder part (LSTM)\n",
    "    model.add(Embedding(vocab_size, 64, input_length=max_len))\n",
    "    model.add(LSTM(64, activation='tanh', return_sequences=False))  # Encoder LSTM\n",
    "    \n",
    "    # Decoder part (RepeatVector and LSTM)\n",
    "    model.add(RepeatVector(max_len))  # Repeat vector for decoder\n",
    "    model.add(LSTM(64, activation='tanh', return_sequences=False))  # Decoder LSTM\n",
    "    \n",
    "    # Output layer (Single output class prediction)\n",
    "    model.add(Dense(len(labels), activation='softmax'))  # Predict only one class for the entire sequence\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d036484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.18.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nisha\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889bcbe4",
   "metadata": {},
   "source": [
    "### Training, Evaluation, and Saving Multiple Models Function\n",
    "\n",
    "The `train_evaluate_and_save_multiple` function is a higher-level function designed to train, evaluate, and save multiple models at once. It iterates over a list of models, training each one, evaluating its performance on a test set, and saving the trained model to a file. Below is a detailed description of the parameters and the function's operation:\n",
    "\n",
    "#### Parameters:\n",
    "- **`models`**: A list of Keras model objects (e.g., LSTM, RNN, BRNN, Encoder-Decoder) that need to be trained and evaluated.\n",
    "- **`model_names`**: A list of strings, each corresponding to a model name. These names will be used when saving the models to disk and when printing training progress.\n",
    "- **`X_train`**: The training data (tokenized and padded sentences) that will be used to train each model.\n",
    "- **`y_train`**: The target labels for the training data (e.g., intent tags).\n",
    "- **`X_test`**: The test data, used to evaluate each model after training.\n",
    "- **`y_test`**: The target labels for the test data.\n",
    "- **`epochs`** (default 500): The number of training epochs for each model. More epochs generally result in better training, but too many can lead to overfitting.\n",
    "- **`batch_size`** (default 32): The number of samples processed at once during training. Smaller values lead to noisier updates, but potentially faster convergence.\n",
    "\n",
    "#### Function Steps:\n",
    "1. **Initialize an Empty Dictionary**:\n",
    "   - The function creates an empty dictionary (`history_dict`) to store the training history of each model. This history includes the loss and accuracy metrics for both training and validation.\n",
    "\n",
    "2. **Iterate Through Models**:\n",
    "   - The function loops over each model in the `models` list and its corresponding name in the `model_names` list, using the `zip()` function to pair each model with its name.\n",
    "   \n",
    "3. **Train Each Model**:\n",
    "   - For each model, it calls the `train_evaluate_and_save` function (described earlier), passing in the current model, its name, training and test data, and the number of epochs and batch size.\n",
    "   - The function prints the model name for clarity, indicating which model is being trained.\n",
    "\n",
    "4. **Store History**:\n",
    "   - After training, the function stores the returned `history` object (which contains the model’s training history) in the `history_dict` under the corresponding model name.\n",
    "\n",
    "5. **Return History**:\n",
    "   - Once all models have been trained, evaluated, and saved, the function returns the `history_dict`, which contains the training history for all models. This allows for later analysis or plotting of performance metrics across models.\n",
    "\n",
    "#### Summary:\n",
    "This function simplifies the process of training and saving multiple models in one go. It is particularly useful when comparing different types of models (such as LSTM, RNN, BRNN, Encoder-Decoder) on the same task, allowing for easy comparison of performance and ensuring that all models are saved for future use. The `history_dict` returned allows for detailed analysis of how each model performed during training and evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83a54950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each model and train, evaluate, and save it\n",
    "def train_evaluate_and_save_multiple(models, model_names, X_train, y_train, X_test, y_test, epochs=500, batch_size=32):\n",
    "    history_dict = {}\n",
    "    for model, name in zip(models, model_names):\n",
    "        print(f\"Training model: {name}\")\n",
    "        \n",
    "        # Train and save each model\n",
    "        history = train_evaluate_and_save(model, name, X_train, y_train, X_test, y_test, epochs, batch_size)\n",
    "        history_dict[name] = history\n",
    "    \n",
    "    return history_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be923c1b",
   "metadata": {},
   "source": [
    "### Defining, Training, and Saving Multiple Models\n",
    "\n",
    "This section of the code defines, trains, and saves multiple models, including LSTM, RNN, BRNN, and Encoder-Decoder architectures. Here’s a breakdown of what happens in this part:\n",
    "\n",
    "#### Steps:\n",
    "1. **Define Models**:\n",
    "   - **`models`**: A list is created containing the four models we want to train. Each model is instantiated by calling the respective functions (`build_lstm_model()`, `build_rnn_model()`, `build_brnn_model()`, and `build_encoder_decoder_model()`). These functions return a compiled Keras model.\n",
    "   - The four models include:\n",
    "     - **LSTM** (Long Short-Term Memory): A deep learning model designed to handle sequential data with long-range dependencies.\n",
    "     - **RNN** (Recurrent Neural Network): A simpler recurrent network that also works well for sequential data.\n",
    "     - **BRNN** (Bidirectional RNN): An extension of RNN, where the network learns from the data in both forward and backward directions.\n",
    "     - **Encoder-Decoder**: A more complex architecture, typically used for sequence-to-sequence tasks, where an encoder processes input data and a decoder generates output based on the encoded information.\n",
    "\n",
    "2. **Model Names**:\n",
    "   - **`model_names`**: A list of strings that correspond to the names of the models, used for printing and saving the models. The names in the list are 'LSTM', 'RNN', 'BRNN', and 'Encoder-Decoder'.\n",
    "\n",
    "3. **Train, Evaluate, and Save Models**:\n",
    "   - **`train_evaluate_and_save_multiple()`**: This function is called with the following parameters:\n",
    "     - **`models`**: The list of models to train.\n",
    "     - **`model_names`**: The list of model names for saving and identifying each model.\n",
    "     - **`X_train`, `y_train`**: The training data and labels.\n",
    "     - **`X_test`, `y_test`**: The test data and labels for evaluating the models.\n",
    "   - The function trains each model sequentially using the provided training data, evaluates them using the test data, and saves the trained models to disk. It returns a dictionary (`history_dict`) containing the training history for each model. This dictionary allows us to track the performance (loss and accuracy) of each model during training and evaluation.\n",
    "\n",
    "#### Summary:\n",
    "This part of the code defines the four models we want to use, trains them, evaluates their performance, and saves them to disk. Each model is handled individually, but all are processed in a loop using the `train_evaluate_and_save_multiple` function, which ensures that the models are trained and saved efficiently. The resulting `history_dict` provides a detailed record of the performance for each model, which can later be used for further analysis or comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fdfc15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_20 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_21 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_5 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_22 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_23 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector_4 (\u001b[38;5;33mRepeatVector\u001b[0m)       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_22 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LSTM\n",
      "Training model: LSTM\n",
      "Epoch 1/500\n",
      "2/2 - 3s - 1s/step - accuracy: 0.0741 - loss: 2.7056 - val_accuracy: 0.1429 - val_loss: 2.6982\n",
      "Epoch 2/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.2037 - loss: 2.6976 - val_accuracy: 0.0714 - val_loss: 2.6895\n",
      "Epoch 3/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.2037 - loss: 2.6878 - val_accuracy: 0.0714 - val_loss: 2.6817\n",
      "Epoch 4/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.2037 - loss: 2.6785 - val_accuracy: 0.0714 - val_loss: 2.6725\n",
      "Epoch 5/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.2037 - loss: 2.6677 - val_accuracy: 0.0714 - val_loss: 2.6618\n",
      "Epoch 6/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.2037 - loss: 2.6538 - val_accuracy: 0.0714 - val_loss: 2.6505\n",
      "Epoch 7/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.2037 - loss: 2.6390 - val_accuracy: 0.0714 - val_loss: 2.6385\n",
      "Epoch 8/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.2037 - loss: 2.6218 - val_accuracy: 0.0714 - val_loss: 2.6268\n",
      "Epoch 9/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.2037 - loss: 2.6010 - val_accuracy: 0.0714 - val_loss: 2.6154\n",
      "Epoch 10/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.2037 - loss: 2.5814 - val_accuracy: 0.0714 - val_loss: 2.6077\n",
      "Epoch 11/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.2222 - loss: 2.5682 - val_accuracy: 0.0714 - val_loss: 2.6054\n",
      "Epoch 12/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.2222 - loss: 2.5520 - val_accuracy: 0.0714 - val_loss: 2.6085\n",
      "Epoch 13/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.2222 - loss: 2.5427 - val_accuracy: 0.0714 - val_loss: 2.6091\n",
      "Epoch 14/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.2222 - loss: 2.5344 - val_accuracy: 0.0714 - val_loss: 2.6034\n",
      "Epoch 15/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.2222 - loss: 2.5223 - val_accuracy: 0.0714 - val_loss: 2.5901\n",
      "Epoch 16/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.2222 - loss: 2.5056 - val_accuracy: 0.0714 - val_loss: 2.5764\n",
      "Epoch 17/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.2222 - loss: 2.4875 - val_accuracy: 0.0714 - val_loss: 2.5632\n",
      "Epoch 18/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.2222 - loss: 2.4599 - val_accuracy: 0.0714 - val_loss: 2.5529\n",
      "Epoch 19/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.2222 - loss: 2.4312 - val_accuracy: 0.0714 - val_loss: 2.5437\n",
      "Epoch 20/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.2222 - loss: 2.3887 - val_accuracy: 0.0714 - val_loss: 2.5314\n",
      "Epoch 21/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.2222 - loss: 2.3327 - val_accuracy: 0.0714 - val_loss: 2.5172\n",
      "Epoch 22/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.2222 - loss: 2.2615 - val_accuracy: 0.0714 - val_loss: 2.5111\n",
      "Epoch 23/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.2222 - loss: 2.1902 - val_accuracy: 0.1429 - val_loss: 2.5271\n",
      "Epoch 24/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.2963 - loss: 2.1256 - val_accuracy: 0.1429 - val_loss: 2.5686\n",
      "Epoch 25/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.2963 - loss: 2.0973 - val_accuracy: 0.1429 - val_loss: 2.6165\n",
      "Epoch 26/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.3148 - loss: 2.0567 - val_accuracy: 0.2143 - val_loss: 2.6314\n",
      "Epoch 27/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.3519 - loss: 2.0010 - val_accuracy: 0.2143 - val_loss: 2.6270\n",
      "Epoch 28/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.3704 - loss: 1.9532 - val_accuracy: 0.2143 - val_loss: 2.5690\n",
      "Epoch 29/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.3889 - loss: 1.9022 - val_accuracy: 0.2143 - val_loss: 2.5081\n",
      "Epoch 30/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.3889 - loss: 1.8733 - val_accuracy: 0.2143 - val_loss: 2.4890\n",
      "Epoch 31/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.3889 - loss: 1.8283 - val_accuracy: 0.2143 - val_loss: 2.5266\n",
      "Epoch 32/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.3889 - loss: 1.7865 - val_accuracy: 0.2143 - val_loss: 2.5736\n",
      "Epoch 33/500\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.3889 - loss: 1.7595 - val_accuracy: 0.1429 - val_loss: 2.5621\n",
      "Epoch 34/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.3889 - loss: 1.7284 - val_accuracy: 0.1429 - val_loss: 2.5377\n",
      "Epoch 35/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.3889 - loss: 1.7068 - val_accuracy: 0.1429 - val_loss: 2.5276\n",
      "Epoch 36/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.3889 - loss: 1.6817 - val_accuracy: 0.1429 - val_loss: 2.5447\n",
      "Epoch 37/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.4074 - loss: 1.6542 - val_accuracy: 0.1429 - val_loss: 2.5394\n",
      "Epoch 38/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.4074 - loss: 1.6316 - val_accuracy: 0.1429 - val_loss: 2.5125\n",
      "Epoch 39/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.3889 - loss: 1.6082 - val_accuracy: 0.1429 - val_loss: 2.4916\n",
      "Epoch 40/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.4074 - loss: 1.5862 - val_accuracy: 0.1429 - val_loss: 2.5366\n",
      "Epoch 41/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.4815 - loss: 1.5641 - val_accuracy: 0.1429 - val_loss: 2.5149\n",
      "Epoch 42/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.4630 - loss: 1.5385 - val_accuracy: 0.1429 - val_loss: 2.4575\n",
      "Epoch 43/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.5000 - loss: 1.5103 - val_accuracy: 0.2143 - val_loss: 2.5536\n",
      "Epoch 44/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.5185 - loss: 1.4833 - val_accuracy: 0.2143 - val_loss: 2.4024\n",
      "Epoch 45/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.5185 - loss: 1.4597 - val_accuracy: 0.2143 - val_loss: 2.4974\n",
      "Epoch 46/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.5185 - loss: 1.4402 - val_accuracy: 0.2143 - val_loss: 2.4936\n",
      "Epoch 47/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.5370 - loss: 1.4137 - val_accuracy: 0.2857 - val_loss: 2.3240\n",
      "Epoch 48/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.5185 - loss: 1.4115 - val_accuracy: 0.2143 - val_loss: 2.5503\n",
      "Epoch 49/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.5370 - loss: 1.3844 - val_accuracy: 0.1429 - val_loss: 2.6714\n",
      "Epoch 50/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.5370 - loss: 1.3702 - val_accuracy: 0.2143 - val_loss: 2.5397\n",
      "Epoch 51/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.5370 - loss: 1.3590 - val_accuracy: 0.2143 - val_loss: 2.7213\n",
      "Epoch 52/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.5370 - loss: 1.3371 - val_accuracy: 0.1429 - val_loss: 2.8973\n",
      "Epoch 53/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.5370 - loss: 1.3278 - val_accuracy: 0.1429 - val_loss: 2.8203\n",
      "Epoch 54/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.5370 - loss: 1.3152 - val_accuracy: 0.1429 - val_loss: 2.8437\n",
      "Epoch 55/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.5370 - loss: 1.2915 - val_accuracy: 0.1429 - val_loss: 2.9606\n",
      "Epoch 56/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.5370 - loss: 1.2745 - val_accuracy: 0.1429 - val_loss: 2.8635\n",
      "Epoch 57/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.5556 - loss: 1.2549 - val_accuracy: 0.1429 - val_loss: 2.9383\n",
      "Epoch 58/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.5741 - loss: 1.2366 - val_accuracy: 0.1429 - val_loss: 3.1156\n",
      "Epoch 59/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.5556 - loss: 1.2168 - val_accuracy: 0.1429 - val_loss: 3.2388\n",
      "Epoch 60/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.5370 - loss: 1.2001 - val_accuracy: 0.0714 - val_loss: 3.1677\n",
      "Epoch 61/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.5370 - loss: 1.1824 - val_accuracy: 0.1429 - val_loss: 3.2430\n",
      "Epoch 62/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.5741 - loss: 1.1648 - val_accuracy: 0.1429 - val_loss: 3.2281\n",
      "Epoch 63/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.5741 - loss: 1.1481 - val_accuracy: 0.2143 - val_loss: 3.1591\n",
      "Epoch 64/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.5741 - loss: 1.1372 - val_accuracy: 0.2143 - val_loss: 3.2452\n",
      "Epoch 65/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.5926 - loss: 1.1200 - val_accuracy: 0.1429 - val_loss: 3.4382\n",
      "Epoch 66/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.6296 - loss: 1.1068 - val_accuracy: 0.2143 - val_loss: 3.4191\n",
      "Epoch 67/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.5926 - loss: 1.0951 - val_accuracy: 0.2143 - val_loss: 3.4831\n",
      "Epoch 68/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.6111 - loss: 1.0783 - val_accuracy: 0.1429 - val_loss: 3.6270\n",
      "Epoch 69/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.6481 - loss: 1.0682 - val_accuracy: 0.2143 - val_loss: 3.5887\n",
      "Epoch 70/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.6481 - loss: 1.0500 - val_accuracy: 0.2143 - val_loss: 3.7572\n",
      "Epoch 71/500\n",
      "2/2 - 0s - 110ms/step - accuracy: 0.6852 - loss: 1.0318 - val_accuracy: 0.1429 - val_loss: 4.0039\n",
      "Epoch 72/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.6852 - loss: 1.0229 - val_accuracy: 0.2143 - val_loss: 3.9222\n",
      "Epoch 73/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.6667 - loss: 1.0089 - val_accuracy: 0.1429 - val_loss: 4.0842\n",
      "Epoch 74/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.6852 - loss: 0.9979 - val_accuracy: 0.1429 - val_loss: 4.1163\n",
      "Epoch 75/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.6852 - loss: 0.9812 - val_accuracy: 0.2143 - val_loss: 3.9957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.6852 - loss: 0.9715 - val_accuracy: 0.1429 - val_loss: 4.3318\n",
      "Epoch 77/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7037 - loss: 0.9550 - val_accuracy: 0.1429 - val_loss: 4.3976\n",
      "Epoch 78/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.6852 - loss: 0.9414 - val_accuracy: 0.1429 - val_loss: 4.3673\n",
      "Epoch 79/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.6852 - loss: 0.9265 - val_accuracy: 0.1429 - val_loss: 4.4900\n",
      "Epoch 80/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.7037 - loss: 0.9161 - val_accuracy: 0.1429 - val_loss: 4.4842\n",
      "Epoch 81/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7037 - loss: 0.8979 - val_accuracy: 0.1429 - val_loss: 4.6379\n",
      "Epoch 82/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7222 - loss: 0.8829 - val_accuracy: 0.1429 - val_loss: 4.7528\n",
      "Epoch 83/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7222 - loss: 0.8639 - val_accuracy: 0.1429 - val_loss: 4.5771\n",
      "Epoch 84/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.7037 - loss: 0.8496 - val_accuracy: 0.1429 - val_loss: 4.7090\n",
      "Epoch 85/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7222 - loss: 0.8356 - val_accuracy: 0.0714 - val_loss: 4.6875\n",
      "Epoch 86/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7407 - loss: 0.8184 - val_accuracy: 0.1429 - val_loss: 4.6070\n",
      "Epoch 87/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7593 - loss: 0.8081 - val_accuracy: 0.0714 - val_loss: 4.8488\n",
      "Epoch 88/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.7593 - loss: 0.7984 - val_accuracy: 0.0714 - val_loss: 4.8118\n",
      "Epoch 89/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.7593 - loss: 0.7864 - val_accuracy: 0.0714 - val_loss: 5.0454\n",
      "Epoch 90/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.7778 - loss: 0.7724 - val_accuracy: 0.0714 - val_loss: 5.2746\n",
      "Epoch 91/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.7778 - loss: 0.7608 - val_accuracy: 0.1429 - val_loss: 5.0239\n",
      "Epoch 92/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.7593 - loss: 0.7523 - val_accuracy: 0.0714 - val_loss: 5.2315\n",
      "Epoch 93/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7778 - loss: 0.7440 - val_accuracy: 0.1429 - val_loss: 5.1468\n",
      "Epoch 94/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.7778 - loss: 0.7345 - val_accuracy: 0.0714 - val_loss: 5.2283\n",
      "Epoch 95/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8148 - loss: 0.7268 - val_accuracy: 0.0714 - val_loss: 5.4407\n",
      "Epoch 96/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.7127 - val_accuracy: 0.0714 - val_loss: 5.3641\n",
      "Epoch 97/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.8148 - loss: 0.7017 - val_accuracy: 0.0714 - val_loss: 5.6376\n",
      "Epoch 98/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.8148 - loss: 0.6988 - val_accuracy: 0.0714 - val_loss: 5.4282\n",
      "Epoch 99/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.7963 - loss: 0.6888 - val_accuracy: 0.0714 - val_loss: 5.6861\n",
      "Epoch 100/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8148 - loss: 0.6816 - val_accuracy: 0.0714 - val_loss: 5.5294\n",
      "Epoch 101/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8148 - loss: 0.6761 - val_accuracy: 0.0714 - val_loss: 5.4951\n",
      "Epoch 102/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.8148 - loss: 0.6670 - val_accuracy: 0.0714 - val_loss: 5.7142\n",
      "Epoch 103/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.6598 - val_accuracy: 0.1429 - val_loss: 5.5561\n",
      "Epoch 104/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8148 - loss: 0.6544 - val_accuracy: 0.0714 - val_loss: 5.9573\n",
      "Epoch 105/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.6463 - val_accuracy: 0.0714 - val_loss: 5.8809\n",
      "Epoch 106/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.6373 - val_accuracy: 0.0714 - val_loss: 5.9282\n",
      "Epoch 107/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.7963 - loss: 0.6305 - val_accuracy: 0.0714 - val_loss: 6.0140\n",
      "Epoch 108/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.8148 - loss: 0.6261 - val_accuracy: 0.0714 - val_loss: 5.9316\n",
      "Epoch 109/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.8148 - loss: 0.6173 - val_accuracy: 0.0714 - val_loss: 5.9817\n",
      "Epoch 110/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8148 - loss: 0.6096 - val_accuracy: 0.0714 - val_loss: 6.0619\n",
      "Epoch 111/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.6042 - val_accuracy: 0.0714 - val_loss: 5.9551\n",
      "Epoch 112/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.5975 - val_accuracy: 0.0714 - val_loss: 6.2007\n",
      "Epoch 113/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8148 - loss: 0.5917 - val_accuracy: 0.0714 - val_loss: 6.2447\n",
      "Epoch 114/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.5825 - val_accuracy: 0.1429 - val_loss: 6.1129\n",
      "Epoch 115/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8148 - loss: 0.5798 - val_accuracy: 0.0714 - val_loss: 6.4035\n",
      "Epoch 116/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.5735 - val_accuracy: 0.1429 - val_loss: 6.1041\n",
      "Epoch 117/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8148 - loss: 0.5676 - val_accuracy: 0.1429 - val_loss: 6.3234\n",
      "Epoch 118/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8148 - loss: 0.5583 - val_accuracy: 0.0714 - val_loss: 6.5131\n",
      "Epoch 119/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7963 - loss: 0.5530 - val_accuracy: 0.1429 - val_loss: 6.3642\n",
      "Epoch 120/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.7963 - loss: 0.5459 - val_accuracy: 0.1429 - val_loss: 6.4256\n",
      "Epoch 121/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.5402 - val_accuracy: 0.1429 - val_loss: 6.5117\n",
      "Epoch 122/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8148 - loss: 0.5340 - val_accuracy: 0.1429 - val_loss: 6.4490\n",
      "Epoch 123/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.7963 - loss: 0.5311 - val_accuracy: 0.0714 - val_loss: 6.6939\n",
      "Epoch 124/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8333 - loss: 0.5201 - val_accuracy: 0.0714 - val_loss: 6.8049\n",
      "Epoch 125/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8519 - loss: 0.5162 - val_accuracy: 0.1429 - val_loss: 6.6086\n",
      "Epoch 126/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8333 - loss: 0.5144 - val_accuracy: 0.0714 - val_loss: 6.7928\n",
      "Epoch 127/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8333 - loss: 0.5130 - val_accuracy: 0.1429 - val_loss: 6.5711\n",
      "Epoch 128/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.7963 - loss: 0.5177 - val_accuracy: 0.0714 - val_loss: 7.0374\n",
      "Epoch 129/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.5282 - val_accuracy: 0.2143 - val_loss: 6.2691\n",
      "Epoch 130/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.6111 - loss: 1.3966 - val_accuracy: 0.2143 - val_loss: 6.5753\n",
      "Epoch 131/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.6481 - loss: 1.0638 - val_accuracy: 0.0714 - val_loss: 7.7166\n",
      "Epoch 132/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.5000 - loss: 1.2202 - val_accuracy: 0.0714 - val_loss: 7.3743\n",
      "Epoch 133/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.6481 - loss: 0.7240 - val_accuracy: 0.1429 - val_loss: 7.1551\n",
      "Epoch 134/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.7037 - loss: 0.6964 - val_accuracy: 0.0714 - val_loss: 7.2492\n",
      "Epoch 135/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.7222 - loss: 0.7624 - val_accuracy: 0.0714 - val_loss: 7.1990\n",
      "Epoch 136/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.7407 - loss: 0.7188 - val_accuracy: 0.1429 - val_loss: 6.5087\n",
      "Epoch 137/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.6852 - loss: 0.7801 - val_accuracy: 0.1429 - val_loss: 6.4479\n",
      "Epoch 138/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.6481 - loss: 0.7706 - val_accuracy: 0.1429 - val_loss: 6.6096\n",
      "Epoch 139/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.7407 - loss: 0.6042 - val_accuracy: 0.0714 - val_loss: 6.8513\n",
      "Epoch 140/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7593 - loss: 0.5802 - val_accuracy: 0.0714 - val_loss: 6.8935\n",
      "Epoch 141/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.7778 - loss: 0.6890 - val_accuracy: 0.0714 - val_loss: 7.0126\n",
      "Epoch 142/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.7593 - loss: 0.6592 - val_accuracy: 0.0714 - val_loss: 7.1621\n",
      "Epoch 143/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.8333 - loss: 0.5090 - val_accuracy: 0.0714 - val_loss: 7.2628\n",
      "Epoch 144/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8333 - loss: 0.5021 - val_accuracy: 0.0714 - val_loss: 7.2379\n",
      "Epoch 145/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.8333 - loss: 0.4964 - val_accuracy: 0.0714 - val_loss: 7.1157\n",
      "Epoch 146/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.7963 - loss: 0.4863 - val_accuracy: 0.0714 - val_loss: 7.1881\n",
      "Epoch 147/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8148 - loss: 0.4609 - val_accuracy: 0.0714 - val_loss: 7.3757\n",
      "Epoch 148/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.8333 - loss: 0.4490 - val_accuracy: 0.0714 - val_loss: 7.4791\n",
      "Epoch 149/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.8333 - loss: 0.4433 - val_accuracy: 0.0714 - val_loss: 7.5183\n",
      "Epoch 150/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - 40ms/step - accuracy: 0.8333 - loss: 0.4345 - val_accuracy: 0.0714 - val_loss: 7.5023\n",
      "Epoch 151/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8519 - loss: 0.4259 - val_accuracy: 0.0714 - val_loss: 7.4772\n",
      "Epoch 152/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8519 - loss: 0.4212 - val_accuracy: 0.0714 - val_loss: 7.4943\n",
      "Epoch 153/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.8333 - loss: 0.4153 - val_accuracy: 0.0714 - val_loss: 7.5671\n",
      "Epoch 154/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8333 - loss: 0.4067 - val_accuracy: 0.0714 - val_loss: 7.6389\n",
      "Epoch 155/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8333 - loss: 0.4011 - val_accuracy: 0.0714 - val_loss: 7.6898\n",
      "Epoch 156/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.8704 - loss: 0.3960 - val_accuracy: 0.0714 - val_loss: 7.7189\n",
      "Epoch 157/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8704 - loss: 0.3903 - val_accuracy: 0.0714 - val_loss: 7.7273\n",
      "Epoch 158/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.8704 - loss: 0.3860 - val_accuracy: 0.0714 - val_loss: 7.7220\n",
      "Epoch 159/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.8704 - loss: 0.3819 - val_accuracy: 0.0714 - val_loss: 7.7301\n",
      "Epoch 160/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.8704 - loss: 0.3768 - val_accuracy: 0.1429 - val_loss: 7.7593\n",
      "Epoch 161/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9074 - loss: 0.3727 - val_accuracy: 0.1429 - val_loss: 7.8158\n",
      "Epoch 162/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9074 - loss: 0.3675 - val_accuracy: 0.1429 - val_loss: 7.8706\n",
      "Epoch 163/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.3635 - val_accuracy: 0.1429 - val_loss: 7.8988\n",
      "Epoch 164/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.3601 - val_accuracy: 0.1429 - val_loss: 7.9146\n",
      "Epoch 165/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.9074 - loss: 0.3559 - val_accuracy: 0.1429 - val_loss: 7.9134\n",
      "Epoch 166/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.3520 - val_accuracy: 0.1429 - val_loss: 7.9219\n",
      "Epoch 167/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9074 - loss: 0.3476 - val_accuracy: 0.1429 - val_loss: 7.9612\n",
      "Epoch 168/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9074 - loss: 0.3440 - val_accuracy: 0.1429 - val_loss: 8.0088\n",
      "Epoch 169/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9074 - loss: 0.3400 - val_accuracy: 0.1429 - val_loss: 8.0571\n",
      "Epoch 170/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9074 - loss: 0.3368 - val_accuracy: 0.1429 - val_loss: 8.0800\n",
      "Epoch 171/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9074 - loss: 0.3338 - val_accuracy: 0.1429 - val_loss: 8.0822\n",
      "Epoch 172/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.3293 - val_accuracy: 0.1429 - val_loss: 8.0993\n",
      "Epoch 173/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9074 - loss: 0.3263 - val_accuracy: 0.1429 - val_loss: 8.1246\n",
      "Epoch 174/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.3225 - val_accuracy: 0.1429 - val_loss: 8.1530\n",
      "Epoch 175/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.3194 - val_accuracy: 0.1429 - val_loss: 8.1891\n",
      "Epoch 176/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9074 - loss: 0.3161 - val_accuracy: 0.1429 - val_loss: 8.2155\n",
      "Epoch 177/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.3131 - val_accuracy: 0.1429 - val_loss: 8.2329\n",
      "Epoch 178/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9074 - loss: 0.3096 - val_accuracy: 0.1429 - val_loss: 8.2512\n",
      "Epoch 179/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9074 - loss: 0.3064 - val_accuracy: 0.1429 - val_loss: 8.2710\n",
      "Epoch 180/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.3034 - val_accuracy: 0.1429 - val_loss: 8.2942\n",
      "Epoch 181/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9074 - loss: 0.3002 - val_accuracy: 0.1429 - val_loss: 8.3198\n",
      "Epoch 182/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.2973 - val_accuracy: 0.1429 - val_loss: 8.3166\n",
      "Epoch 183/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9074 - loss: 0.2951 - val_accuracy: 0.1429 - val_loss: 8.3302\n",
      "Epoch 184/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9074 - loss: 0.2919 - val_accuracy: 0.1429 - val_loss: 8.3523\n",
      "Epoch 185/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9074 - loss: 0.2897 - val_accuracy: 0.1429 - val_loss: 8.3748\n",
      "Epoch 186/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.2861 - val_accuracy: 0.1429 - val_loss: 8.4099\n",
      "Epoch 187/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.2831 - val_accuracy: 0.1429 - val_loss: 8.4585\n",
      "Epoch 188/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9074 - loss: 0.2809 - val_accuracy: 0.1429 - val_loss: 8.4831\n",
      "Epoch 189/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.2780 - val_accuracy: 0.1429 - val_loss: 8.4804\n",
      "Epoch 190/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.2752 - val_accuracy: 0.1429 - val_loss: 8.4848\n",
      "Epoch 191/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9074 - loss: 0.2732 - val_accuracy: 0.1429 - val_loss: 8.5213\n",
      "Epoch 192/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.2724 - val_accuracy: 0.1429 - val_loss: 8.5138\n",
      "Epoch 193/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9074 - loss: 0.2708 - val_accuracy: 0.1429 - val_loss: 8.5137\n",
      "Epoch 194/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9074 - loss: 0.2692 - val_accuracy: 0.1429 - val_loss: 8.5859\n",
      "Epoch 195/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9074 - loss: 0.2635 - val_accuracy: 0.1429 - val_loss: 8.6441\n",
      "Epoch 196/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9074 - loss: 0.2646 - val_accuracy: 0.1429 - val_loss: 8.6134\n",
      "Epoch 197/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9074 - loss: 0.2603 - val_accuracy: 0.1429 - val_loss: 8.5904\n",
      "Epoch 198/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9074 - loss: 0.2623 - val_accuracy: 0.1429 - val_loss: 8.6265\n",
      "Epoch 199/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9074 - loss: 0.2563 - val_accuracy: 0.1429 - val_loss: 8.6901\n",
      "Epoch 200/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.2530 - val_accuracy: 0.1429 - val_loss: 8.7266\n",
      "Epoch 201/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.2536 - val_accuracy: 0.0714 - val_loss: 8.7092\n",
      "Epoch 202/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.2492 - val_accuracy: 0.0714 - val_loss: 8.7090\n",
      "Epoch 203/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.2496 - val_accuracy: 0.0714 - val_loss: 8.7345\n",
      "Epoch 204/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.2458 - val_accuracy: 0.0714 - val_loss: 8.7949\n",
      "Epoch 205/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.2434 - val_accuracy: 0.0714 - val_loss: 8.8229\n",
      "Epoch 206/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.2398 - val_accuracy: 0.0714 - val_loss: 8.8098\n",
      "Epoch 207/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.2387 - val_accuracy: 0.0714 - val_loss: 8.8202\n",
      "Epoch 208/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.2369 - val_accuracy: 0.0714 - val_loss: 8.8674\n",
      "Epoch 209/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.2340 - val_accuracy: 0.0714 - val_loss: 8.9075\n",
      "Epoch 210/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.2335 - val_accuracy: 0.0714 - val_loss: 8.8934\n",
      "Epoch 211/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.2312 - val_accuracy: 0.0714 - val_loss: 8.9067\n",
      "Epoch 212/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.2300 - val_accuracy: 0.0714 - val_loss: 8.9445\n",
      "Epoch 213/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.2279 - val_accuracy: 0.0714 - val_loss: 8.9976\n",
      "Epoch 214/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.2275 - val_accuracy: 0.0714 - val_loss: 9.0205\n",
      "Epoch 215/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.2241 - val_accuracy: 0.0714 - val_loss: 9.0165\n",
      "Epoch 216/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.2227 - val_accuracy: 0.0714 - val_loss: 9.0354\n",
      "Epoch 217/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.2208 - val_accuracy: 0.0714 - val_loss: 9.0826\n",
      "Epoch 218/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.2207 - val_accuracy: 0.0714 - val_loss: 9.1165\n",
      "Epoch 219/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.2170 - val_accuracy: 0.0714 - val_loss: 9.1312\n",
      "Epoch 220/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.2159 - val_accuracy: 0.0714 - val_loss: 9.1682\n",
      "Epoch 221/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9259 - loss: 0.2148 - val_accuracy: 0.0714 - val_loss: 9.2181\n",
      "Epoch 222/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9259 - loss: 0.2131 - val_accuracy: 0.0714 - val_loss: 9.2490\n",
      "Epoch 223/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9259 - loss: 0.2122 - val_accuracy: 0.0714 - val_loss: 9.2433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.2108 - val_accuracy: 0.0714 - val_loss: 9.2606\n",
      "Epoch 225/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.2083 - val_accuracy: 0.0714 - val_loss: 9.2802\n",
      "Epoch 226/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.2067 - val_accuracy: 0.0714 - val_loss: 9.2832\n",
      "Epoch 227/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.2066 - val_accuracy: 0.0714 - val_loss: 9.2994\n",
      "Epoch 228/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.2038 - val_accuracy: 0.0714 - val_loss: 9.3333\n",
      "Epoch 229/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.2031 - val_accuracy: 0.0714 - val_loss: 9.3463\n",
      "Epoch 230/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.2017 - val_accuracy: 0.0714 - val_loss: 9.3529\n",
      "Epoch 231/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9259 - loss: 0.2006 - val_accuracy: 0.0714 - val_loss: 9.3829\n",
      "Epoch 232/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1984 - val_accuracy: 0.0714 - val_loss: 9.3974\n",
      "Epoch 233/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1977 - val_accuracy: 0.0714 - val_loss: 9.3947\n",
      "Epoch 234/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9259 - loss: 0.1960 - val_accuracy: 0.0714 - val_loss: 9.4036\n",
      "Epoch 235/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1957 - val_accuracy: 0.0714 - val_loss: 9.4305\n",
      "Epoch 236/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9074 - loss: 0.1944 - val_accuracy: 0.0714 - val_loss: 9.4488\n",
      "Epoch 237/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.1927 - val_accuracy: 0.0714 - val_loss: 9.4620\n",
      "Epoch 238/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9259 - loss: 0.1922 - val_accuracy: 0.0714 - val_loss: 9.4867\n",
      "Epoch 239/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1905 - val_accuracy: 0.0714 - val_loss: 9.5161\n",
      "Epoch 240/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1905 - val_accuracy: 0.0714 - val_loss: 9.5366\n",
      "Epoch 241/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1881 - val_accuracy: 0.0714 - val_loss: 9.5507\n",
      "Epoch 242/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9259 - loss: 0.1875 - val_accuracy: 0.0714 - val_loss: 9.5709\n",
      "Epoch 243/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1858 - val_accuracy: 0.0714 - val_loss: 9.5873\n",
      "Epoch 244/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1851 - val_accuracy: 0.0714 - val_loss: 9.5838\n",
      "Epoch 245/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9259 - loss: 0.1843 - val_accuracy: 0.0714 - val_loss: 9.5911\n",
      "Epoch 246/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1830 - val_accuracy: 0.0714 - val_loss: 9.6118\n",
      "Epoch 247/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1837 - val_accuracy: 0.0714 - val_loss: 9.6166\n",
      "Epoch 248/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.1816 - val_accuracy: 0.0714 - val_loss: 9.6276\n",
      "Epoch 249/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1813 - val_accuracy: 0.0714 - val_loss: 9.6653\n",
      "Epoch 250/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1794 - val_accuracy: 0.0714 - val_loss: 9.6898\n",
      "Epoch 251/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1785 - val_accuracy: 0.0714 - val_loss: 9.6866\n",
      "Epoch 252/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1787 - val_accuracy: 0.0714 - val_loss: 9.6958\n",
      "Epoch 253/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1776 - val_accuracy: 0.0714 - val_loss: 9.7247\n",
      "Epoch 254/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1771 - val_accuracy: 0.0714 - val_loss: 9.7476\n",
      "Epoch 255/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9259 - loss: 0.1765 - val_accuracy: 0.0714 - val_loss: 9.7601\n",
      "Epoch 256/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1747 - val_accuracy: 0.0714 - val_loss: 9.7732\n",
      "Epoch 257/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1749 - val_accuracy: 0.0714 - val_loss: 9.7975\n",
      "Epoch 258/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1732 - val_accuracy: 0.0714 - val_loss: 9.8229\n",
      "Epoch 259/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1730 - val_accuracy: 0.0714 - val_loss: 9.8366\n",
      "Epoch 260/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1717 - val_accuracy: 0.0714 - val_loss: 9.8480\n",
      "Epoch 261/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9259 - loss: 0.1706 - val_accuracy: 0.0714 - val_loss: 9.8491\n",
      "Epoch 262/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9259 - loss: 0.1706 - val_accuracy: 0.0714 - val_loss: 9.8655\n",
      "Epoch 263/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1694 - val_accuracy: 0.0714 - val_loss: 9.8832\n",
      "Epoch 264/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1686 - val_accuracy: 0.0714 - val_loss: 9.8995\n",
      "Epoch 265/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1679 - val_accuracy: 0.0714 - val_loss: 9.9220\n",
      "Epoch 266/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9074 - loss: 0.1675 - val_accuracy: 0.0714 - val_loss: 9.9432\n",
      "Epoch 267/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1667 - val_accuracy: 0.0714 - val_loss: 9.9666\n",
      "Epoch 268/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9444 - loss: 0.1654 - val_accuracy: 0.0714 - val_loss: 9.9842\n",
      "Epoch 269/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1651 - val_accuracy: 0.0714 - val_loss: 10.0059\n",
      "Epoch 270/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1642 - val_accuracy: 0.0714 - val_loss: 10.0226\n",
      "Epoch 271/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9074 - loss: 0.1636 - val_accuracy: 0.0714 - val_loss: 10.0340\n",
      "Epoch 272/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1628 - val_accuracy: 0.0714 - val_loss: 10.0438\n",
      "Epoch 273/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1633 - val_accuracy: 0.0714 - val_loss: 10.0551\n",
      "Epoch 274/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1613 - val_accuracy: 0.0714 - val_loss: 10.0638\n",
      "Epoch 275/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1608 - val_accuracy: 0.0714 - val_loss: 10.0727\n",
      "Epoch 276/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1605 - val_accuracy: 0.0714 - val_loss: 10.0852\n",
      "Epoch 277/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1596 - val_accuracy: 0.0714 - val_loss: 10.1022\n",
      "Epoch 278/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1596 - val_accuracy: 0.0714 - val_loss: 10.1181\n",
      "Epoch 279/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9259 - loss: 0.1586 - val_accuracy: 0.0714 - val_loss: 10.1297\n",
      "Epoch 280/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1594 - val_accuracy: 0.0714 - val_loss: 10.1445\n",
      "Epoch 281/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1578 - val_accuracy: 0.0714 - val_loss: 10.1567\n",
      "Epoch 282/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1569 - val_accuracy: 0.0714 - val_loss: 10.1650\n",
      "Epoch 283/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1566 - val_accuracy: 0.0714 - val_loss: 10.1782\n",
      "Epoch 284/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1559 - val_accuracy: 0.0714 - val_loss: 10.1911\n",
      "Epoch 285/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1558 - val_accuracy: 0.0714 - val_loss: 10.2056\n",
      "Epoch 286/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1548 - val_accuracy: 0.0714 - val_loss: 10.2192\n",
      "Epoch 287/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9259 - loss: 0.1546 - val_accuracy: 0.0714 - val_loss: 10.2331\n",
      "Epoch 288/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1538 - val_accuracy: 0.0714 - val_loss: 10.2475\n",
      "Epoch 289/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1544 - val_accuracy: 0.0714 - val_loss: 10.2593\n",
      "Epoch 290/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1535 - val_accuracy: 0.0714 - val_loss: 10.2653\n",
      "Epoch 291/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1531 - val_accuracy: 0.0714 - val_loss: 10.2811\n",
      "Epoch 292/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1521 - val_accuracy: 0.0714 - val_loss: 10.2929\n",
      "Epoch 293/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9074 - loss: 0.1521 - val_accuracy: 0.0714 - val_loss: 10.3031\n",
      "Epoch 294/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1512 - val_accuracy: 0.0714 - val_loss: 10.3110\n",
      "Epoch 295/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1512 - val_accuracy: 0.0714 - val_loss: 10.3227\n",
      "Epoch 296/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1504 - val_accuracy: 0.0714 - val_loss: 10.3363\n",
      "Epoch 297/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1508 - val_accuracy: 0.0714 - val_loss: 10.3476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1501 - val_accuracy: 0.0714 - val_loss: 10.3585\n",
      "Epoch 299/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1498 - val_accuracy: 0.0714 - val_loss: 10.3708\n",
      "Epoch 300/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9259 - loss: 0.1489 - val_accuracy: 0.0714 - val_loss: 10.3791\n",
      "Epoch 301/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1482 - val_accuracy: 0.0714 - val_loss: 10.3867\n",
      "Epoch 302/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9259 - loss: 0.1486 - val_accuracy: 0.0714 - val_loss: 10.3973\n",
      "Epoch 303/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.1475 - val_accuracy: 0.0714 - val_loss: 10.4117\n",
      "Epoch 304/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1471 - val_accuracy: 0.0714 - val_loss: 10.4266\n",
      "Epoch 305/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9074 - loss: 0.1483 - val_accuracy: 0.0714 - val_loss: 10.4423\n",
      "Epoch 306/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1467 - val_accuracy: 0.0714 - val_loss: 10.4558\n",
      "Epoch 307/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9074 - loss: 0.1466 - val_accuracy: 0.0714 - val_loss: 10.4690\n",
      "Epoch 308/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1460 - val_accuracy: 0.0714 - val_loss: 10.4872\n",
      "Epoch 309/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1461 - val_accuracy: 0.0714 - val_loss: 10.4954\n",
      "Epoch 310/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1458 - val_accuracy: 0.0714 - val_loss: 10.4961\n",
      "Epoch 311/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9259 - loss: 0.1446 - val_accuracy: 0.0714 - val_loss: 10.4936\n",
      "Epoch 312/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1459 - val_accuracy: 0.0714 - val_loss: 10.5049\n",
      "Epoch 313/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1449 - val_accuracy: 0.0714 - val_loss: 10.5091\n",
      "Epoch 314/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1451 - val_accuracy: 0.0714 - val_loss: 10.5141\n",
      "Epoch 315/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1439 - val_accuracy: 0.0714 - val_loss: 10.5146\n",
      "Epoch 316/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1436 - val_accuracy: 0.0714 - val_loss: 10.5214\n",
      "Epoch 317/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1431 - val_accuracy: 0.0714 - val_loss: 10.5380\n",
      "Epoch 318/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9074 - loss: 0.1430 - val_accuracy: 0.0714 - val_loss: 10.5532\n",
      "Epoch 319/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9074 - loss: 0.1430 - val_accuracy: 0.0714 - val_loss: 10.5675\n",
      "Epoch 320/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9074 - loss: 0.1424 - val_accuracy: 0.0714 - val_loss: 10.5785\n",
      "Epoch 321/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1418 - val_accuracy: 0.0714 - val_loss: 10.5892\n",
      "Epoch 322/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9074 - loss: 0.1430 - val_accuracy: 0.0714 - val_loss: 10.5992\n",
      "Epoch 323/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1414 - val_accuracy: 0.0714 - val_loss: 10.6073\n",
      "Epoch 324/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1409 - val_accuracy: 0.0714 - val_loss: 10.6138\n",
      "Epoch 325/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1404 - val_accuracy: 0.0714 - val_loss: 10.6174\n",
      "Epoch 326/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1402 - val_accuracy: 0.0714 - val_loss: 10.6223\n",
      "Epoch 327/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9444 - loss: 0.1399 - val_accuracy: 0.0714 - val_loss: 10.6255\n",
      "Epoch 328/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9259 - loss: 0.1400 - val_accuracy: 0.0714 - val_loss: 10.6314\n",
      "Epoch 329/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9259 - loss: 0.1399 - val_accuracy: 0.0714 - val_loss: 10.6421\n",
      "Epoch 330/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1398 - val_accuracy: 0.0714 - val_loss: 10.6556\n",
      "Epoch 331/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1398 - val_accuracy: 0.0714 - val_loss: 10.6688\n",
      "Epoch 332/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1389 - val_accuracy: 0.0714 - val_loss: 10.6811\n",
      "Epoch 333/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1388 - val_accuracy: 0.0714 - val_loss: 10.6939\n",
      "Epoch 334/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.9259 - loss: 0.1387 - val_accuracy: 0.0714 - val_loss: 10.7052\n",
      "Epoch 335/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9074 - loss: 0.1387 - val_accuracy: 0.0714 - val_loss: 10.7126\n",
      "Epoch 336/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1377 - val_accuracy: 0.0714 - val_loss: 10.7192\n",
      "Epoch 337/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1375 - val_accuracy: 0.0714 - val_loss: 10.7274\n",
      "Epoch 338/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1375 - val_accuracy: 0.0714 - val_loss: 10.7333\n",
      "Epoch 339/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1374 - val_accuracy: 0.0714 - val_loss: 10.7371\n",
      "Epoch 340/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1371 - val_accuracy: 0.0714 - val_loss: 10.7429\n",
      "Epoch 341/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9259 - loss: 0.1368 - val_accuracy: 0.0714 - val_loss: 10.7501\n",
      "Epoch 342/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1368 - val_accuracy: 0.0714 - val_loss: 10.7559\n",
      "Epoch 343/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1367 - val_accuracy: 0.0714 - val_loss: 10.7624\n",
      "Epoch 344/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1364 - val_accuracy: 0.0714 - val_loss: 10.7719\n",
      "Epoch 345/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1359 - val_accuracy: 0.0714 - val_loss: 10.7835\n",
      "Epoch 346/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9259 - loss: 0.1358 - val_accuracy: 0.0714 - val_loss: 10.7955\n",
      "Epoch 347/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.1357 - val_accuracy: 0.0714 - val_loss: 10.8090\n",
      "Epoch 348/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1353 - val_accuracy: 0.0714 - val_loss: 10.8217\n",
      "Epoch 349/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1350 - val_accuracy: 0.0714 - val_loss: 10.8339\n",
      "Epoch 350/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1347 - val_accuracy: 0.0714 - val_loss: 10.8436\n",
      "Epoch 351/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1350 - val_accuracy: 0.0714 - val_loss: 10.8531\n",
      "Epoch 352/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1343 - val_accuracy: 0.0714 - val_loss: 10.8640\n",
      "Epoch 353/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1346 - val_accuracy: 0.0714 - val_loss: 10.8710\n",
      "Epoch 354/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.1346 - val_accuracy: 0.0714 - val_loss: 10.8743\n",
      "Epoch 355/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1347 - val_accuracy: 0.0714 - val_loss: 10.8787\n",
      "Epoch 356/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1344 - val_accuracy: 0.0714 - val_loss: 10.8889\n",
      "Epoch 357/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1340 - val_accuracy: 0.0714 - val_loss: 10.9000\n",
      "Epoch 358/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1336 - val_accuracy: 0.0714 - val_loss: 10.9080\n",
      "Epoch 359/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1339 - val_accuracy: 0.0714 - val_loss: 10.9156\n",
      "Epoch 360/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1335 - val_accuracy: 0.0714 - val_loss: 10.9237\n",
      "Epoch 361/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1330 - val_accuracy: 0.0714 - val_loss: 10.9301\n",
      "Epoch 362/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9259 - loss: 0.1328 - val_accuracy: 0.0714 - val_loss: 10.9359\n",
      "Epoch 363/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1329 - val_accuracy: 0.0714 - val_loss: 10.9410\n",
      "Epoch 364/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1325 - val_accuracy: 0.0714 - val_loss: 10.9462\n",
      "Epoch 365/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1323 - val_accuracy: 0.0714 - val_loss: 10.9557\n",
      "Epoch 366/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1323 - val_accuracy: 0.0714 - val_loss: 10.9629\n",
      "Epoch 367/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9074 - loss: 0.1333 - val_accuracy: 0.0714 - val_loss: 10.9663\n",
      "Epoch 368/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.1322 - val_accuracy: 0.0714 - val_loss: 10.9716\n",
      "Epoch 369/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1319 - val_accuracy: 0.0714 - val_loss: 10.9783\n",
      "Epoch 370/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9259 - loss: 0.1321 - val_accuracy: 0.0714 - val_loss: 10.9873\n",
      "Epoch 371/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9074 - loss: 0.1331 - val_accuracy: 0.0714 - val_loss: 10.9954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1316 - val_accuracy: 0.0714 - val_loss: 11.0059\n",
      "Epoch 373/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1319 - val_accuracy: 0.0714 - val_loss: 11.0157\n",
      "Epoch 374/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.1316 - val_accuracy: 0.0714 - val_loss: 11.0274\n",
      "Epoch 375/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1308 - val_accuracy: 0.0714 - val_loss: 11.0377\n",
      "Epoch 376/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1308 - val_accuracy: 0.0714 - val_loss: 11.0447\n",
      "Epoch 377/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1307 - val_accuracy: 0.0714 - val_loss: 11.0508\n",
      "Epoch 378/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.1307 - val_accuracy: 0.0714 - val_loss: 11.0603\n",
      "Epoch 379/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9259 - loss: 0.1305 - val_accuracy: 0.0714 - val_loss: 11.0667\n",
      "Epoch 380/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.1303 - val_accuracy: 0.0714 - val_loss: 11.0702\n",
      "Epoch 381/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1303 - val_accuracy: 0.0714 - val_loss: 11.0730\n",
      "Epoch 382/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1300 - val_accuracy: 0.0714 - val_loss: 11.0782\n",
      "Epoch 383/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9259 - loss: 0.1302 - val_accuracy: 0.0714 - val_loss: 11.0868\n",
      "Epoch 384/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1297 - val_accuracy: 0.0714 - val_loss: 11.0951\n",
      "Epoch 385/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1295 - val_accuracy: 0.0714 - val_loss: 11.1038\n",
      "Epoch 386/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1294 - val_accuracy: 0.0714 - val_loss: 11.1121\n",
      "Epoch 387/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1293 - val_accuracy: 0.0714 - val_loss: 11.1225\n",
      "Epoch 388/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9074 - loss: 0.1302 - val_accuracy: 0.0714 - val_loss: 11.1325\n",
      "Epoch 389/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1295 - val_accuracy: 0.0714 - val_loss: 11.1439\n",
      "Epoch 390/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1301 - val_accuracy: 0.0714 - val_loss: 11.1503\n",
      "Epoch 391/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9259 - loss: 0.1289 - val_accuracy: 0.0714 - val_loss: 11.1567\n",
      "Epoch 392/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1288 - val_accuracy: 0.0714 - val_loss: 11.1620\n",
      "Epoch 393/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1293 - val_accuracy: 0.0714 - val_loss: 11.1646\n",
      "Epoch 394/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9259 - loss: 0.1295 - val_accuracy: 0.0714 - val_loss: 11.1707\n",
      "Epoch 395/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1284 - val_accuracy: 0.0714 - val_loss: 11.1802\n",
      "Epoch 396/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1283 - val_accuracy: 0.0714 - val_loss: 11.1881\n",
      "Epoch 397/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9259 - loss: 0.1286 - val_accuracy: 0.0714 - val_loss: 11.1912\n",
      "Epoch 398/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1282 - val_accuracy: 0.0714 - val_loss: 11.1980\n",
      "Epoch 399/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1297 - val_accuracy: 0.0714 - val_loss: 11.2051\n",
      "Epoch 400/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9259 - loss: 0.1283 - val_accuracy: 0.0714 - val_loss: 11.2088\n",
      "Epoch 401/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1281 - val_accuracy: 0.0714 - val_loss: 11.2122\n",
      "Epoch 402/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1283 - val_accuracy: 0.0714 - val_loss: 11.2177\n",
      "Epoch 403/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1283 - val_accuracy: 0.0714 - val_loss: 11.2257\n",
      "Epoch 404/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9259 - loss: 0.1278 - val_accuracy: 0.0714 - val_loss: 11.2333\n",
      "Epoch 405/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1275 - val_accuracy: 0.0714 - val_loss: 11.2384\n",
      "Epoch 406/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1274 - val_accuracy: 0.0714 - val_loss: 11.2442\n",
      "Epoch 407/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.1281 - val_accuracy: 0.0714 - val_loss: 11.2521\n",
      "Epoch 408/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1275 - val_accuracy: 0.0714 - val_loss: 11.2635\n",
      "Epoch 409/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1274 - val_accuracy: 0.0714 - val_loss: 11.2715\n",
      "Epoch 410/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1282 - val_accuracy: 0.0714 - val_loss: 11.2767\n",
      "Epoch 411/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1271 - val_accuracy: 0.0714 - val_loss: 11.2844\n",
      "Epoch 412/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1271 - val_accuracy: 0.0714 - val_loss: 11.2905\n",
      "Epoch 413/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1266 - val_accuracy: 0.0714 - val_loss: 11.2959\n",
      "Epoch 414/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1267 - val_accuracy: 0.0714 - val_loss: 11.3014\n",
      "Epoch 415/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1266 - val_accuracy: 0.0714 - val_loss: 11.3078\n",
      "Epoch 416/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1266 - val_accuracy: 0.0714 - val_loss: 11.3146\n",
      "Epoch 417/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1264 - val_accuracy: 0.0714 - val_loss: 11.3177\n",
      "Epoch 418/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1261 - val_accuracy: 0.0714 - val_loss: 11.3208\n",
      "Epoch 419/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1266 - val_accuracy: 0.0714 - val_loss: 11.3273\n",
      "Epoch 420/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1260 - val_accuracy: 0.0714 - val_loss: 11.3332\n",
      "Epoch 421/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9259 - loss: 0.1261 - val_accuracy: 0.0714 - val_loss: 11.3389\n",
      "Epoch 422/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1258 - val_accuracy: 0.0714 - val_loss: 11.3450\n",
      "Epoch 423/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.1259 - val_accuracy: 0.0714 - val_loss: 11.3541\n",
      "Epoch 424/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1257 - val_accuracy: 0.0714 - val_loss: 11.3594\n",
      "Epoch 425/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9259 - loss: 0.1261 - val_accuracy: 0.0714 - val_loss: 11.3631\n",
      "Epoch 426/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1256 - val_accuracy: 0.0714 - val_loss: 11.3727\n",
      "Epoch 427/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1256 - val_accuracy: 0.0714 - val_loss: 11.3805\n",
      "Epoch 428/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1257 - val_accuracy: 0.0714 - val_loss: 11.3833\n",
      "Epoch 429/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1253 - val_accuracy: 0.0714 - val_loss: 11.3882\n",
      "Epoch 430/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1253 - val_accuracy: 0.0714 - val_loss: 11.3964\n",
      "Epoch 431/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1251 - val_accuracy: 0.0714 - val_loss: 11.4026\n",
      "Epoch 432/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9074 - loss: 0.1250 - val_accuracy: 0.0714 - val_loss: 11.4042\n",
      "Epoch 433/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1250 - val_accuracy: 0.0714 - val_loss: 11.4056\n",
      "Epoch 434/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1253 - val_accuracy: 0.0714 - val_loss: 11.4117\n",
      "Epoch 435/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1249 - val_accuracy: 0.0714 - val_loss: 11.4153\n",
      "Epoch 436/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1248 - val_accuracy: 0.0714 - val_loss: 11.4196\n",
      "Epoch 437/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1248 - val_accuracy: 0.0714 - val_loss: 11.4216\n",
      "Epoch 438/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.1247 - val_accuracy: 0.0714 - val_loss: 11.4242\n",
      "Epoch 439/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1247 - val_accuracy: 0.0714 - val_loss: 11.4291\n",
      "Epoch 440/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1247 - val_accuracy: 0.0714 - val_loss: 11.4334\n",
      "Epoch 441/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9259 - loss: 0.1247 - val_accuracy: 0.0714 - val_loss: 11.4403\n",
      "Epoch 442/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1246 - val_accuracy: 0.0714 - val_loss: 11.4458\n",
      "Epoch 443/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1247 - val_accuracy: 0.0714 - val_loss: 11.4533\n",
      "Epoch 444/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.1249 - val_accuracy: 0.0714 - val_loss: 11.4610\n",
      "Epoch 445/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1249 - val_accuracy: 0.0714 - val_loss: 11.4722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9259 - loss: 0.1247 - val_accuracy: 0.0714 - val_loss: 11.4778\n",
      "Epoch 447/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.1245 - val_accuracy: 0.0714 - val_loss: 11.4801\n",
      "Epoch 448/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1245 - val_accuracy: 0.0714 - val_loss: 11.4826\n",
      "Epoch 449/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.1241 - val_accuracy: 0.0714 - val_loss: 11.4893\n",
      "Epoch 450/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1247 - val_accuracy: 0.0714 - val_loss: 11.4957\n",
      "Epoch 451/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1237 - val_accuracy: 0.0714 - val_loss: 11.5002\n",
      "Epoch 452/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1237 - val_accuracy: 0.0714 - val_loss: 11.5026\n",
      "Epoch 453/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1239 - val_accuracy: 0.0714 - val_loss: 11.5036\n",
      "Epoch 454/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1245 - val_accuracy: 0.0714 - val_loss: 11.5073\n",
      "Epoch 455/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9259 - loss: 0.1247 - val_accuracy: 0.0714 - val_loss: 11.5125\n",
      "Epoch 456/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1245 - val_accuracy: 0.0714 - val_loss: 11.5129\n",
      "Epoch 457/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1235 - val_accuracy: 0.0714 - val_loss: 11.5104\n",
      "Epoch 458/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1235 - val_accuracy: 0.0714 - val_loss: 11.5082\n",
      "Epoch 459/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1235 - val_accuracy: 0.0714 - val_loss: 11.5107\n",
      "Epoch 460/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.1233 - val_accuracy: 0.0714 - val_loss: 11.5126\n",
      "Epoch 461/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9074 - loss: 0.1239 - val_accuracy: 0.0714 - val_loss: 11.5187\n",
      "Epoch 462/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1231 - val_accuracy: 0.0714 - val_loss: 11.5255\n",
      "Epoch 463/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9259 - loss: 0.1239 - val_accuracy: 0.0714 - val_loss: 11.5312\n",
      "Epoch 464/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1234 - val_accuracy: 0.0714 - val_loss: 11.5400\n",
      "Epoch 465/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1237 - val_accuracy: 0.0714 - val_loss: 11.5491\n",
      "Epoch 466/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1234 - val_accuracy: 0.0714 - val_loss: 11.5578\n",
      "Epoch 467/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9259 - loss: 0.1234 - val_accuracy: 0.0714 - val_loss: 11.5678\n",
      "Epoch 468/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.1229 - val_accuracy: 0.0714 - val_loss: 11.5728\n",
      "Epoch 469/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1234 - val_accuracy: 0.0714 - val_loss: 11.5743\n",
      "Epoch 470/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9259 - loss: 0.1227 - val_accuracy: 0.0714 - val_loss: 11.5786\n",
      "Epoch 471/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1228 - val_accuracy: 0.0714 - val_loss: 11.5829\n",
      "Epoch 472/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1229 - val_accuracy: 0.0714 - val_loss: 11.5850\n",
      "Epoch 473/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1229 - val_accuracy: 0.0714 - val_loss: 11.5845\n",
      "Epoch 474/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9259 - loss: 0.1231 - val_accuracy: 0.0714 - val_loss: 11.5819\n",
      "Epoch 475/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.1230 - val_accuracy: 0.0714 - val_loss: 11.5807\n",
      "Epoch 476/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1227 - val_accuracy: 0.0714 - val_loss: 11.5806\n",
      "Epoch 477/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.1225 - val_accuracy: 0.0714 - val_loss: 11.5856\n",
      "Epoch 478/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1223 - val_accuracy: 0.0714 - val_loss: 11.5925\n",
      "Epoch 479/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1223 - val_accuracy: 0.0714 - val_loss: 11.6013\n",
      "Epoch 480/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1223 - val_accuracy: 0.0714 - val_loss: 11.6052\n",
      "Epoch 481/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9444 - loss: 0.1221 - val_accuracy: 0.0714 - val_loss: 11.6063\n",
      "Epoch 482/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.1229 - val_accuracy: 0.0714 - val_loss: 11.6070\n",
      "Epoch 483/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1227 - val_accuracy: 0.0714 - val_loss: 11.6109\n",
      "Epoch 484/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9259 - loss: 0.1227 - val_accuracy: 0.0714 - val_loss: 11.6165\n",
      "Epoch 485/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.1222 - val_accuracy: 0.0714 - val_loss: 11.6243\n",
      "Epoch 486/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.1224 - val_accuracy: 0.0714 - val_loss: 11.6304\n",
      "Epoch 487/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1219 - val_accuracy: 0.0714 - val_loss: 11.6335\n",
      "Epoch 488/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.1219 - val_accuracy: 0.0714 - val_loss: 11.6362\n",
      "Epoch 489/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.1222 - val_accuracy: 0.0714 - val_loss: 11.6382\n",
      "Epoch 490/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1221 - val_accuracy: 0.0714 - val_loss: 11.6418\n",
      "Epoch 491/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1218 - val_accuracy: 0.0714 - val_loss: 11.6433\n",
      "Epoch 492/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.1225 - val_accuracy: 0.0714 - val_loss: 11.6453\n",
      "Epoch 493/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9074 - loss: 0.1236 - val_accuracy: 0.0714 - val_loss: 11.6447\n",
      "Epoch 494/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.1227 - val_accuracy: 0.0714 - val_loss: 11.6523\n",
      "Epoch 495/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.1215 - val_accuracy: 0.0714 - val_loss: 11.6575\n",
      "Epoch 496/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1222 - val_accuracy: 0.0714 - val_loss: 11.6605\n",
      "Epoch 497/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1217 - val_accuracy: 0.0714 - val_loss: 11.6656\n",
      "Epoch 498/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.1219 - val_accuracy: 0.0714 - val_loss: 11.6705\n",
      "Epoch 499/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.1216 - val_accuracy: 0.0714 - val_loss: 11.6769\n",
      "Epoch 500/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.1216 - val_accuracy: 0.0714 - val_loss: 11.6839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as LSTM_chat_model.h5\n",
      "Training model: RNN\n",
      "Training model: RNN\n",
      "Epoch 1/500\n",
      "2/2 - 2s - 977ms/step - accuracy: 0.1296 - loss: 2.7042 - val_accuracy: 0.2143 - val_loss: 2.6788\n",
      "Epoch 2/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.1852 - loss: 2.6475 - val_accuracy: 0.2143 - val_loss: 2.6662\n",
      "Epoch 3/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.1852 - loss: 2.5940 - val_accuracy: 0.2143 - val_loss: 2.6499\n",
      "Epoch 4/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.1852 - loss: 2.5508 - val_accuracy: 0.2143 - val_loss: 2.6398\n",
      "Epoch 5/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.1852 - loss: 2.5006 - val_accuracy: 0.2143 - val_loss: 2.6362\n",
      "Epoch 6/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.2037 - loss: 2.4546 - val_accuracy: 0.2143 - val_loss: 2.6299\n",
      "Epoch 7/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.2222 - loss: 2.4135 - val_accuracy: 0.2143 - val_loss: 2.6183\n",
      "Epoch 8/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.2778 - loss: 2.3703 - val_accuracy: 0.2143 - val_loss: 2.6043\n",
      "Epoch 9/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.3333 - loss: 2.3204 - val_accuracy: 0.2143 - val_loss: 2.5848\n",
      "Epoch 10/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.3704 - loss: 2.2692 - val_accuracy: 0.2143 - val_loss: 2.5650\n",
      "Epoch 11/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.4074 - loss: 2.2033 - val_accuracy: 0.2143 - val_loss: 2.5375\n",
      "Epoch 12/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.4259 - loss: 2.1318 - val_accuracy: 0.2143 - val_loss: 2.5051\n",
      "Epoch 13/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.4630 - loss: 2.0612 - val_accuracy: 0.2143 - val_loss: 2.4696\n",
      "Epoch 14/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.4444 - loss: 1.9842 - val_accuracy: 0.2857 - val_loss: 2.4415\n",
      "Epoch 15/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.5000 - loss: 1.9033 - val_accuracy: 0.2857 - val_loss: 2.4221\n",
      "Epoch 16/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.5185 - loss: 1.8225 - val_accuracy: 0.2857 - val_loss: 2.4177\n",
      "Epoch 17/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.5000 - loss: 1.7417 - val_accuracy: 0.2857 - val_loss: 2.4216\n",
      "Epoch 18/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.5000 - loss: 1.6573 - val_accuracy: 0.3571 - val_loss: 2.4324\n",
      "Epoch 19/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.5556 - loss: 1.5792 - val_accuracy: 0.3571 - val_loss: 2.4343\n",
      "Epoch 20/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.5926 - loss: 1.4986 - val_accuracy: 0.3571 - val_loss: 2.4290\n",
      "Epoch 21/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.6111 - loss: 1.4242 - val_accuracy: 0.3571 - val_loss: 2.4238\n",
      "Epoch 22/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.6296 - loss: 1.3549 - val_accuracy: 0.2857 - val_loss: 2.4249\n",
      "Epoch 23/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.6296 - loss: 1.2851 - val_accuracy: 0.2857 - val_loss: 2.4171\n",
      "Epoch 24/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.6481 - loss: 1.2250 - val_accuracy: 0.2857 - val_loss: 2.4190\n",
      "Epoch 25/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.6667 - loss: 1.1700 - val_accuracy: 0.2857 - val_loss: 2.4170\n",
      "Epoch 26/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.6852 - loss: 1.1088 - val_accuracy: 0.2857 - val_loss: 2.4264\n",
      "Epoch 27/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.6852 - loss: 1.0572 - val_accuracy: 0.2857 - val_loss: 2.4085\n",
      "Epoch 28/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.6852 - loss: 1.0070 - val_accuracy: 0.2857 - val_loss: 2.3704\n",
      "Epoch 29/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.7222 - loss: 0.9619 - val_accuracy: 0.3571 - val_loss: 2.3712\n",
      "Epoch 30/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.7222 - loss: 0.9176 - val_accuracy: 0.2857 - val_loss: 2.3509\n",
      "Epoch 31/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.7222 - loss: 0.8846 - val_accuracy: 0.3571 - val_loss: 2.3551\n",
      "Epoch 32/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.7222 - loss: 0.8464 - val_accuracy: 0.4286 - val_loss: 2.3725\n",
      "Epoch 33/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.7593 - loss: 0.8180 - val_accuracy: 0.4286 - val_loss: 2.3720\n",
      "Epoch 34/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7593 - loss: 0.7853 - val_accuracy: 0.4286 - val_loss: 2.3587\n",
      "Epoch 35/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.7963 - loss: 0.7528 - val_accuracy: 0.4286 - val_loss: 2.3303\n",
      "Epoch 36/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.7963 - loss: 0.7212 - val_accuracy: 0.3571 - val_loss: 2.3131\n",
      "Epoch 37/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.7963 - loss: 0.6957 - val_accuracy: 0.3571 - val_loss: 2.3037\n",
      "Epoch 38/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.7963 - loss: 0.6682 - val_accuracy: 0.3571 - val_loss: 2.2617\n",
      "Epoch 39/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.7963 - loss: 0.6451 - val_accuracy: 0.4286 - val_loss: 2.2453\n",
      "Epoch 40/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.8704 - loss: 0.6222 - val_accuracy: 0.3571 - val_loss: 2.2734\n",
      "Epoch 41/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.8704 - loss: 0.5979 - val_accuracy: 0.2857 - val_loss: 2.3009\n",
      "Epoch 42/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.8704 - loss: 0.5760 - val_accuracy: 0.3571 - val_loss: 2.3224\n",
      "Epoch 43/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.8889 - loss: 0.5581 - val_accuracy: 0.3571 - val_loss: 2.3161\n",
      "Epoch 44/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9074 - loss: 0.5384 - val_accuracy: 0.3571 - val_loss: 2.3169\n",
      "Epoch 45/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8889 - loss: 0.5102 - val_accuracy: 0.3571 - val_loss: 2.3267\n",
      "Epoch 46/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8889 - loss: 0.4945 - val_accuracy: 0.3571 - val_loss: 2.3248\n",
      "Epoch 47/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9074 - loss: 0.4713 - val_accuracy: 0.3571 - val_loss: 2.3527\n",
      "Epoch 48/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9259 - loss: 0.4551 - val_accuracy: 0.2857 - val_loss: 2.3739\n",
      "Epoch 49/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.4415 - val_accuracy: 0.2857 - val_loss: 2.3587\n",
      "Epoch 50/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9074 - loss: 0.4227 - val_accuracy: 0.2857 - val_loss: 2.3415\n",
      "Epoch 51/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.4070 - val_accuracy: 0.2857 - val_loss: 2.3275\n",
      "Epoch 52/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.3923 - val_accuracy: 0.2857 - val_loss: 2.3185\n",
      "Epoch 53/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9259 - loss: 0.3792 - val_accuracy: 0.2857 - val_loss: 2.3039\n",
      "Epoch 54/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.3654 - val_accuracy: 0.2857 - val_loss: 2.3113\n",
      "Epoch 55/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.3570 - val_accuracy: 0.3571 - val_loss: 2.3144\n",
      "Epoch 56/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.3407 - val_accuracy: 0.4286 - val_loss: 2.2926\n",
      "Epoch 57/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.3277 - val_accuracy: 0.4286 - val_loss: 2.2748\n",
      "Epoch 58/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.3170 - val_accuracy: 0.4286 - val_loss: 2.2717\n",
      "Epoch 59/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.3078 - val_accuracy: 0.4286 - val_loss: 2.2847\n",
      "Epoch 60/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.2968 - val_accuracy: 0.3571 - val_loss: 2.2997\n",
      "Epoch 61/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.2818 - val_accuracy: 0.3571 - val_loss: 2.3051\n",
      "Epoch 62/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.2756 - val_accuracy: 0.3571 - val_loss: 2.3141\n",
      "Epoch 63/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.2655 - val_accuracy: 0.4286 - val_loss: 2.2937\n",
      "Epoch 64/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.2534 - val_accuracy: 0.4286 - val_loss: 2.2716\n",
      "Epoch 65/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.2448 - val_accuracy: 0.4286 - val_loss: 2.2707\n",
      "Epoch 66/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9444 - loss: 0.2356 - val_accuracy: 0.4286 - val_loss: 2.2793\n",
      "Epoch 67/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.2278 - val_accuracy: 0.4286 - val_loss: 2.2913\n",
      "Epoch 68/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.2196 - val_accuracy: 0.4286 - val_loss: 2.3225\n",
      "Epoch 69/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.2140 - val_accuracy: 0.4286 - val_loss: 2.3162\n",
      "Epoch 70/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.2057 - val_accuracy: 0.4286 - val_loss: 2.2549\n",
      "Epoch 71/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.2004 - val_accuracy: 0.4286 - val_loss: 2.2189\n",
      "Epoch 72/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.1955 - val_accuracy: 0.4286 - val_loss: 2.2163\n",
      "Epoch 73/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.1871 - val_accuracy: 0.4286 - val_loss: 2.2259\n",
      "Epoch 74/500\n",
      "2/2 - 0s - 78ms/step - accuracy: 0.9444 - loss: 0.1812 - val_accuracy: 0.5000 - val_loss: 2.2289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9444 - loss: 0.1782 - val_accuracy: 0.5000 - val_loss: 2.2157\n",
      "Epoch 76/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.1713 - val_accuracy: 0.5000 - val_loss: 2.2121\n",
      "Epoch 77/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.1682 - val_accuracy: 0.5000 - val_loss: 2.2277\n",
      "Epoch 78/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.1632 - val_accuracy: 0.5000 - val_loss: 2.2625\n",
      "Epoch 79/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.1628 - val_accuracy: 0.5000 - val_loss: 2.2694\n",
      "Epoch 80/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.1565 - val_accuracy: 0.5000 - val_loss: 2.2544\n",
      "Epoch 81/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.1520 - val_accuracy: 0.5000 - val_loss: 2.2282\n",
      "Epoch 82/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.1473 - val_accuracy: 0.5000 - val_loss: 2.1996\n",
      "Epoch 83/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.1463 - val_accuracy: 0.5000 - val_loss: 2.1912\n",
      "Epoch 84/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.1423 - val_accuracy: 0.5000 - val_loss: 2.2011\n",
      "Epoch 85/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.1381 - val_accuracy: 0.5000 - val_loss: 2.2310\n",
      "Epoch 86/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.1350 - val_accuracy: 0.5000 - val_loss: 2.2359\n",
      "Epoch 87/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.1337 - val_accuracy: 0.5714 - val_loss: 2.2264\n",
      "Epoch 88/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.1299 - val_accuracy: 0.5714 - val_loss: 2.2133\n",
      "Epoch 89/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.1274 - val_accuracy: 0.5000 - val_loss: 2.1932\n",
      "Epoch 90/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.1254 - val_accuracy: 0.5714 - val_loss: 2.1943\n",
      "Epoch 91/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.1229 - val_accuracy: 0.5714 - val_loss: 2.2158\n",
      "Epoch 92/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.1204 - val_accuracy: 0.5714 - val_loss: 2.2373\n",
      "Epoch 93/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.1192 - val_accuracy: 0.5714 - val_loss: 2.2366\n",
      "Epoch 94/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.1162 - val_accuracy: 0.5714 - val_loss: 2.2188\n",
      "Epoch 95/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9815 - loss: 0.1142 - val_accuracy: 0.5714 - val_loss: 2.1867\n",
      "Epoch 96/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.1139 - val_accuracy: 0.5714 - val_loss: 2.1860\n",
      "Epoch 97/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.1098 - val_accuracy: 0.5714 - val_loss: 2.2058\n",
      "Epoch 98/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.1081 - val_accuracy: 0.5714 - val_loss: 2.2288\n",
      "Epoch 99/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.1066 - val_accuracy: 0.5000 - val_loss: 2.2436\n",
      "Epoch 100/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.1052 - val_accuracy: 0.5714 - val_loss: 2.2292\n",
      "Epoch 101/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.1035 - val_accuracy: 0.5714 - val_loss: 2.1938\n",
      "Epoch 102/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.1031 - val_accuracy: 0.6429 - val_loss: 2.1735\n",
      "Epoch 103/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.1000 - val_accuracy: 0.6429 - val_loss: 2.1910\n",
      "Epoch 104/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0990 - val_accuracy: 0.6429 - val_loss: 2.2225\n",
      "Epoch 105/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0978 - val_accuracy: 0.5714 - val_loss: 2.2375\n",
      "Epoch 106/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0960 - val_accuracy: 0.5714 - val_loss: 2.2287\n",
      "Epoch 107/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0955 - val_accuracy: 0.5714 - val_loss: 2.2035\n",
      "Epoch 108/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0937 - val_accuracy: 0.6429 - val_loss: 2.1772\n",
      "Epoch 109/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0925 - val_accuracy: 0.6429 - val_loss: 2.1859\n",
      "Epoch 110/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0917 - val_accuracy: 0.6429 - val_loss: 2.1990\n",
      "Epoch 111/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0899 - val_accuracy: 0.6429 - val_loss: 2.2067\n",
      "Epoch 112/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0899 - val_accuracy: 0.5714 - val_loss: 2.2060\n",
      "Epoch 113/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0881 - val_accuracy: 0.6429 - val_loss: 2.1945\n",
      "Epoch 114/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0880 - val_accuracy: 0.6429 - val_loss: 2.1812\n",
      "Epoch 115/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0861 - val_accuracy: 0.6429 - val_loss: 2.1938\n",
      "Epoch 116/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0850 - val_accuracy: 0.6429 - val_loss: 2.2178\n",
      "Epoch 117/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9259 - loss: 0.0872 - val_accuracy: 0.5714 - val_loss: 2.2453\n",
      "Epoch 118/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9444 - loss: 0.0846 - val_accuracy: 0.5714 - val_loss: 2.2416\n",
      "Epoch 119/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0832 - val_accuracy: 0.5714 - val_loss: 2.2288\n",
      "Epoch 120/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0819 - val_accuracy: 0.5714 - val_loss: 2.2047\n",
      "Epoch 121/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0807 - val_accuracy: 0.5714 - val_loss: 2.1881\n",
      "Epoch 122/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0810 - val_accuracy: 0.5714 - val_loss: 2.2017\n",
      "Epoch 123/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0824 - val_accuracy: 0.5714 - val_loss: 2.2372\n",
      "Epoch 124/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0814 - val_accuracy: 0.5714 - val_loss: 2.2565\n",
      "Epoch 125/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0800 - val_accuracy: 0.5714 - val_loss: 2.2674\n",
      "Epoch 126/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0798 - val_accuracy: 0.5714 - val_loss: 2.2544\n",
      "Epoch 127/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0784 - val_accuracy: 0.5714 - val_loss: 2.2319\n",
      "Epoch 128/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0766 - val_accuracy: 0.5714 - val_loss: 2.2145\n",
      "Epoch 129/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0766 - val_accuracy: 0.5714 - val_loss: 2.2031\n",
      "Epoch 130/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0764 - val_accuracy: 0.5714 - val_loss: 2.2168\n",
      "Epoch 131/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0755 - val_accuracy: 0.5714 - val_loss: 2.2430\n",
      "Epoch 132/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0747 - val_accuracy: 0.5714 - val_loss: 2.2683\n",
      "Epoch 133/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0737 - val_accuracy: 0.5714 - val_loss: 2.2899\n",
      "Epoch 134/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0736 - val_accuracy: 0.5714 - val_loss: 2.3014\n",
      "Epoch 135/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0738 - val_accuracy: 0.5714 - val_loss: 2.3001\n",
      "Epoch 136/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0740 - val_accuracy: 0.5714 - val_loss: 2.2849\n",
      "Epoch 137/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0725 - val_accuracy: 0.5714 - val_loss: 2.2645\n",
      "Epoch 138/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0728 - val_accuracy: 0.5714 - val_loss: 2.2518\n",
      "Epoch 139/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0714 - val_accuracy: 0.5714 - val_loss: 2.2445\n",
      "Epoch 140/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0709 - val_accuracy: 0.5714 - val_loss: 2.2423\n",
      "Epoch 141/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0709 - val_accuracy: 0.5714 - val_loss: 2.2432\n",
      "Epoch 142/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0704 - val_accuracy: 0.5714 - val_loss: 2.2560\n",
      "Epoch 143/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0700 - val_accuracy: 0.5714 - val_loss: 2.2704\n",
      "Epoch 144/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0700 - val_accuracy: 0.5714 - val_loss: 2.2839\n",
      "Epoch 145/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0697 - val_accuracy: 0.5714 - val_loss: 2.2913\n",
      "Epoch 146/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0697 - val_accuracy: 0.5714 - val_loss: 2.2980\n",
      "Epoch 147/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0707 - val_accuracy: 0.5714 - val_loss: 2.2974\n",
      "Epoch 148/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0688 - val_accuracy: 0.5714 - val_loss: 2.2973\n",
      "Epoch 149/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0718 - val_accuracy: 0.5714 - val_loss: 2.2931\n",
      "Epoch 150/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0681 - val_accuracy: 0.5714 - val_loss: 2.2847\n",
      "Epoch 151/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9444 - loss: 0.0695 - val_accuracy: 0.5714 - val_loss: 2.2782\n",
      "Epoch 152/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0685 - val_accuracy: 0.5714 - val_loss: 2.2821\n",
      "Epoch 153/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0698 - val_accuracy: 0.5714 - val_loss: 2.2814\n",
      "Epoch 154/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0684 - val_accuracy: 0.5714 - val_loss: 2.2971\n",
      "Epoch 155/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0675 - val_accuracy: 0.5714 - val_loss: 2.3139\n",
      "Epoch 156/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0667 - val_accuracy: 0.5714 - val_loss: 2.3301\n",
      "Epoch 157/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0662 - val_accuracy: 0.5714 - val_loss: 2.3454\n",
      "Epoch 158/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0662 - val_accuracy: 0.5714 - val_loss: 2.3553\n",
      "Epoch 159/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0687 - val_accuracy: 0.5714 - val_loss: 2.3552\n",
      "Epoch 160/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0657 - val_accuracy: 0.5714 - val_loss: 2.3432\n",
      "Epoch 161/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0654 - val_accuracy: 0.5714 - val_loss: 2.3295\n",
      "Epoch 162/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0671 - val_accuracy: 0.5714 - val_loss: 2.3195\n",
      "Epoch 163/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0659 - val_accuracy: 0.5714 - val_loss: 2.3232\n",
      "Epoch 164/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0653 - val_accuracy: 0.5714 - val_loss: 2.3341\n",
      "Epoch 165/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9259 - loss: 0.0676 - val_accuracy: 0.5714 - val_loss: 2.3425\n",
      "Epoch 166/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0650 - val_accuracy: 0.5714 - val_loss: 2.3413\n",
      "Epoch 167/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0645 - val_accuracy: 0.5714 - val_loss: 2.3416\n",
      "Epoch 168/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.0651 - val_accuracy: 0.5714 - val_loss: 2.3464\n",
      "Epoch 169/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0640 - val_accuracy: 0.5714 - val_loss: 2.3472\n",
      "Epoch 170/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0637 - val_accuracy: 0.5714 - val_loss: 2.3462\n",
      "Epoch 171/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0637 - val_accuracy: 0.5714 - val_loss: 2.3445\n",
      "Epoch 172/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0643 - val_accuracy: 0.5714 - val_loss: 2.3406\n",
      "Epoch 173/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.0646 - val_accuracy: 0.5714 - val_loss: 2.3326\n",
      "Epoch 174/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0647 - val_accuracy: 0.5714 - val_loss: 2.3297\n",
      "Epoch 175/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0636 - val_accuracy: 0.5714 - val_loss: 2.3334\n",
      "Epoch 176/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0629 - val_accuracy: 0.5714 - val_loss: 2.3368\n",
      "Epoch 177/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0627 - val_accuracy: 0.5714 - val_loss: 2.3423\n",
      "Epoch 178/500\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.9630 - loss: 0.0627 - val_accuracy: 0.5714 - val_loss: 2.3468\n",
      "Epoch 179/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0624 - val_accuracy: 0.5714 - val_loss: 2.3555\n",
      "Epoch 180/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0625 - val_accuracy: 0.5714 - val_loss: 2.3651\n",
      "Epoch 181/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0626 - val_accuracy: 0.5714 - val_loss: 2.3718\n",
      "Epoch 182/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0636 - val_accuracy: 0.5714 - val_loss: 2.3697\n",
      "Epoch 183/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0625 - val_accuracy: 0.5714 - val_loss: 2.3624\n",
      "Epoch 184/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0624 - val_accuracy: 0.5714 - val_loss: 2.3582\n",
      "Epoch 185/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0616 - val_accuracy: 0.5714 - val_loss: 2.3590\n",
      "Epoch 186/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0623 - val_accuracy: 0.5714 - val_loss: 2.3698\n",
      "Epoch 187/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0627 - val_accuracy: 0.5714 - val_loss: 2.3809\n",
      "Epoch 188/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0629 - val_accuracy: 0.5714 - val_loss: 2.3912\n",
      "Epoch 189/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0648 - val_accuracy: 0.5714 - val_loss: 2.4002\n",
      "Epoch 190/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0638 - val_accuracy: 0.5714 - val_loss: 2.4122\n",
      "Epoch 191/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0619 - val_accuracy: 0.5714 - val_loss: 2.4216\n",
      "Epoch 192/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0630 - val_accuracy: 0.5714 - val_loss: 2.4274\n",
      "Epoch 193/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0606 - val_accuracy: 0.5714 - val_loss: 2.4212\n",
      "Epoch 194/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0614 - val_accuracy: 0.5714 - val_loss: 2.4141\n",
      "Epoch 195/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0618 - val_accuracy: 0.5714 - val_loss: 2.3991\n",
      "Epoch 196/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0620 - val_accuracy: 0.5714 - val_loss: 2.3893\n",
      "Epoch 197/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0612 - val_accuracy: 0.5714 - val_loss: 2.3780\n",
      "Epoch 198/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0607 - val_accuracy: 0.5714 - val_loss: 2.3755\n",
      "Epoch 199/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0600 - val_accuracy: 0.5714 - val_loss: 2.3826\n",
      "Epoch 200/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0599 - val_accuracy: 0.5714 - val_loss: 2.3918\n",
      "Epoch 201/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0639 - val_accuracy: 0.5714 - val_loss: 2.3961\n",
      "Epoch 202/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0611 - val_accuracy: 0.5714 - val_loss: 2.4009\n",
      "Epoch 203/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0604 - val_accuracy: 0.5714 - val_loss: 2.4100\n",
      "Epoch 204/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9815 - loss: 0.0599 - val_accuracy: 0.5714 - val_loss: 2.4153\n",
      "Epoch 205/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0598 - val_accuracy: 0.5714 - val_loss: 2.4166\n",
      "Epoch 206/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0606 - val_accuracy: 0.5714 - val_loss: 2.4215\n",
      "Epoch 207/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0600 - val_accuracy: 0.5714 - val_loss: 2.4254\n",
      "Epoch 208/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0604 - val_accuracy: 0.5714 - val_loss: 2.4301\n",
      "Epoch 209/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0598 - val_accuracy: 0.5714 - val_loss: 2.4340\n",
      "Epoch 210/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0601 - val_accuracy: 0.5714 - val_loss: 2.4291\n",
      "Epoch 211/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0591 - val_accuracy: 0.5714 - val_loss: 2.4289\n",
      "Epoch 212/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0608 - val_accuracy: 0.5714 - val_loss: 2.4328\n",
      "Epoch 213/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0590 - val_accuracy: 0.5714 - val_loss: 2.4320\n",
      "Epoch 214/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0590 - val_accuracy: 0.5714 - val_loss: 2.4345\n",
      "Epoch 215/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0593 - val_accuracy: 0.5714 - val_loss: 2.4412\n",
      "Epoch 216/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0597 - val_accuracy: 0.5714 - val_loss: 2.4457\n",
      "Epoch 217/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0590 - val_accuracy: 0.5714 - val_loss: 2.4530\n",
      "Epoch 218/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0587 - val_accuracy: 0.5714 - val_loss: 2.4551\n",
      "Epoch 219/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9815 - loss: 0.0586 - val_accuracy: 0.5714 - val_loss: 2.4536\n",
      "Epoch 220/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0586 - val_accuracy: 0.5714 - val_loss: 2.4503\n",
      "Epoch 221/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0589 - val_accuracy: 0.5714 - val_loss: 2.4482\n",
      "Epoch 222/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0591 - val_accuracy: 0.5714 - val_loss: 2.4423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0590 - val_accuracy: 0.5714 - val_loss: 2.4415\n",
      "Epoch 224/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0586 - val_accuracy: 0.5714 - val_loss: 2.4407\n",
      "Epoch 225/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0579 - val_accuracy: 0.5714 - val_loss: 2.4399\n",
      "Epoch 226/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0581 - val_accuracy: 0.5714 - val_loss: 2.4418\n",
      "Epoch 227/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0592 - val_accuracy: 0.5714 - val_loss: 2.4529\n",
      "Epoch 228/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0588 - val_accuracy: 0.5714 - val_loss: 2.4611\n",
      "Epoch 229/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0591 - val_accuracy: 0.5714 - val_loss: 2.4695\n",
      "Epoch 230/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0589 - val_accuracy: 0.5714 - val_loss: 2.4792\n",
      "Epoch 231/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0613 - val_accuracy: 0.5714 - val_loss: 2.4877\n",
      "Epoch 232/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9444 - loss: 0.0586 - val_accuracy: 0.5714 - val_loss: 2.4912\n",
      "Epoch 233/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0581 - val_accuracy: 0.5714 - val_loss: 2.4880\n",
      "Epoch 234/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0579 - val_accuracy: 0.5714 - val_loss: 2.4841\n",
      "Epoch 235/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0580 - val_accuracy: 0.5714 - val_loss: 2.4808\n",
      "Epoch 236/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0577 - val_accuracy: 0.5714 - val_loss: 2.4806\n",
      "Epoch 237/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0575 - val_accuracy: 0.5714 - val_loss: 2.4837\n",
      "Epoch 238/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0576 - val_accuracy: 0.5714 - val_loss: 2.4865\n",
      "Epoch 239/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0577 - val_accuracy: 0.5714 - val_loss: 2.4876\n",
      "Epoch 240/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0576 - val_accuracy: 0.5714 - val_loss: 2.4859\n",
      "Epoch 241/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0577 - val_accuracy: 0.5714 - val_loss: 2.4819\n",
      "Epoch 242/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0581 - val_accuracy: 0.5714 - val_loss: 2.4798\n",
      "Epoch 243/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0572 - val_accuracy: 0.5714 - val_loss: 2.4830\n",
      "Epoch 244/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0571 - val_accuracy: 0.5714 - val_loss: 2.4878\n",
      "Epoch 245/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0571 - val_accuracy: 0.5714 - val_loss: 2.4929\n",
      "Epoch 246/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0570 - val_accuracy: 0.5714 - val_loss: 2.4994\n",
      "Epoch 247/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0574 - val_accuracy: 0.5714 - val_loss: 2.5055\n",
      "Epoch 248/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0578 - val_accuracy: 0.5714 - val_loss: 2.5114\n",
      "Epoch 249/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0569 - val_accuracy: 0.5714 - val_loss: 2.5114\n",
      "Epoch 250/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.5714 - val_loss: 2.5092\n",
      "Epoch 251/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9444 - loss: 0.0577 - val_accuracy: 0.5714 - val_loss: 2.5065\n",
      "Epoch 252/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0568 - val_accuracy: 0.5714 - val_loss: 2.5104\n",
      "Epoch 253/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.5714 - val_loss: 2.5111\n",
      "Epoch 254/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0576 - val_accuracy: 0.5714 - val_loss: 2.5117\n",
      "Epoch 255/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0572 - val_accuracy: 0.5714 - val_loss: 2.5071\n",
      "Epoch 256/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0567 - val_accuracy: 0.5714 - val_loss: 2.5038\n",
      "Epoch 257/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9444 - loss: 0.0573 - val_accuracy: 0.5714 - val_loss: 2.5030\n",
      "Epoch 258/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0571 - val_accuracy: 0.5714 - val_loss: 2.5099\n",
      "Epoch 259/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0568 - val_accuracy: 0.5714 - val_loss: 2.5142\n",
      "Epoch 260/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0566 - val_accuracy: 0.5714 - val_loss: 2.5171\n",
      "Epoch 261/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0564 - val_accuracy: 0.5714 - val_loss: 2.5194\n",
      "Epoch 262/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0574 - val_accuracy: 0.5714 - val_loss: 2.5249\n",
      "Epoch 263/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.5714 - val_loss: 2.5332\n",
      "Epoch 264/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0569 - val_accuracy: 0.5714 - val_loss: 2.5372\n",
      "Epoch 265/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.5714 - val_loss: 2.5411\n",
      "Epoch 266/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0564 - val_accuracy: 0.5714 - val_loss: 2.5385\n",
      "Epoch 267/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9444 - loss: 0.0566 - val_accuracy: 0.5714 - val_loss: 2.5351\n",
      "Epoch 268/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0563 - val_accuracy: 0.5714 - val_loss: 2.5408\n",
      "Epoch 269/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.9630 - loss: 0.0563 - val_accuracy: 0.5714 - val_loss: 2.5422\n",
      "Epoch 270/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0582 - val_accuracy: 0.5714 - val_loss: 2.5399\n",
      "Epoch 271/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0574 - val_accuracy: 0.5714 - val_loss: 2.5291\n",
      "Epoch 272/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.5714 - val_loss: 2.5267\n",
      "Epoch 273/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.9630 - loss: 0.0563 - val_accuracy: 0.5714 - val_loss: 2.5310\n",
      "Epoch 274/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.5714 - val_loss: 2.5401\n",
      "Epoch 275/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.5714 - val_loss: 2.5535\n",
      "Epoch 276/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0567 - val_accuracy: 0.5714 - val_loss: 2.5672\n",
      "Epoch 277/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.5714 - val_loss: 2.5777\n",
      "Epoch 278/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0568 - val_accuracy: 0.5714 - val_loss: 2.5776\n",
      "Epoch 279/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.5714 - val_loss: 2.5713\n",
      "Epoch 280/500\n",
      "2/2 - 0s - 47ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.5714 - val_loss: 2.5658\n",
      "Epoch 281/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.5714 - val_loss: 2.5614\n",
      "Epoch 282/500\n",
      "2/2 - 0s - 55ms/step - accuracy: 0.9630 - loss: 0.0557 - val_accuracy: 0.5714 - val_loss: 2.5579\n",
      "Epoch 283/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0564 - val_accuracy: 0.5714 - val_loss: 2.5548\n",
      "Epoch 284/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0560 - val_accuracy: 0.5714 - val_loss: 2.5567\n",
      "Epoch 285/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9444 - loss: 0.0565 - val_accuracy: 0.5714 - val_loss: 2.5596\n",
      "Epoch 286/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.5714 - val_loss: 2.5571\n",
      "Epoch 287/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0561 - val_accuracy: 0.5714 - val_loss: 2.5557\n",
      "Epoch 288/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0559 - val_accuracy: 0.5714 - val_loss: 2.5570\n",
      "Epoch 289/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.5714 - val_loss: 2.5583\n",
      "Epoch 290/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0581 - val_accuracy: 0.5714 - val_loss: 2.5578\n",
      "Epoch 291/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0566 - val_accuracy: 0.5714 - val_loss: 2.5512\n",
      "Epoch 292/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.5714 - val_loss: 2.5457\n",
      "Epoch 293/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.5714 - val_loss: 2.5488\n",
      "Epoch 294/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.5714 - val_loss: 2.5579\n",
      "Epoch 295/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.5714 - val_loss: 2.5677\n",
      "Epoch 296/500\n",
      "2/2 - 0s - 25ms/step - accuracy: 0.9630 - loss: 0.0595 - val_accuracy: 0.5714 - val_loss: 2.5745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0567 - val_accuracy: 0.5714 - val_loss: 2.5872\n",
      "Epoch 298/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.5714 - val_loss: 2.5963\n",
      "Epoch 299/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.5000 - val_loss: 2.5993\n",
      "Epoch 300/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0556 - val_accuracy: 0.5000 - val_loss: 2.5985\n",
      "Epoch 301/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.5000 - val_loss: 2.5892\n",
      "Epoch 302/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0565 - val_accuracy: 0.5000 - val_loss: 2.5769\n",
      "Epoch 303/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0571 - val_accuracy: 0.5714 - val_loss: 2.5666\n",
      "Epoch 304/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0565 - val_accuracy: 0.5714 - val_loss: 2.5553\n",
      "Epoch 305/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.5714 - val_loss: 2.5451\n",
      "Epoch 306/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.5714 - val_loss: 2.5444\n",
      "Epoch 307/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.5714 - val_loss: 2.5522\n",
      "Epoch 308/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0568 - val_accuracy: 0.5714 - val_loss: 2.5624\n",
      "Epoch 309/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.5714 - val_loss: 2.5749\n",
      "Epoch 310/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.5714 - val_loss: 2.5876\n",
      "Epoch 311/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0563 - val_accuracy: 0.5714 - val_loss: 2.5979\n",
      "Epoch 312/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.5714 - val_loss: 2.6063\n",
      "Epoch 313/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.5714 - val_loss: 2.6103\n",
      "Epoch 314/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.5714 - val_loss: 2.6068\n",
      "Epoch 315/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0570 - val_accuracy: 0.5714 - val_loss: 2.5981\n",
      "Epoch 316/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.5714 - val_loss: 2.5868\n",
      "Epoch 317/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.5714 - val_loss: 2.5802\n",
      "Epoch 318/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.5714 - val_loss: 2.5801\n",
      "Epoch 319/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.5714 - val_loss: 2.5866\n",
      "Epoch 320/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.5714 - val_loss: 2.5920\n",
      "Epoch 321/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.5714 - val_loss: 2.5976\n",
      "Epoch 322/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.5714 - val_loss: 2.6014\n",
      "Epoch 323/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.5714 - val_loss: 2.6019\n",
      "Epoch 324/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9444 - loss: 0.0553 - val_accuracy: 0.5714 - val_loss: 2.5986\n",
      "Epoch 325/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5714 - val_loss: 2.5948\n",
      "Epoch 326/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.5714 - val_loss: 2.5914\n",
      "Epoch 327/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5714 - val_loss: 2.5925\n",
      "Epoch 328/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5714 - val_loss: 2.5942\n",
      "Epoch 329/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9444 - loss: 0.0552 - val_accuracy: 0.5714 - val_loss: 2.5964\n",
      "Epoch 330/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0549 - val_accuracy: 0.5714 - val_loss: 2.5957\n",
      "Epoch 331/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5714 - val_loss: 2.5937\n",
      "Epoch 332/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.5714 - val_loss: 2.5945\n",
      "Epoch 333/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.5714 - val_loss: 2.5964\n",
      "Epoch 334/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.5714 - val_loss: 2.6023\n",
      "Epoch 335/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.5714 - val_loss: 2.6110\n",
      "Epoch 336/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.5714 - val_loss: 2.6188\n",
      "Epoch 337/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0556 - val_accuracy: 0.5000 - val_loss: 2.6230\n",
      "Epoch 338/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5000 - val_loss: 2.6196\n",
      "Epoch 339/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.5000 - val_loss: 2.6154\n",
      "Epoch 340/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.5000 - val_loss: 2.6117\n",
      "Epoch 341/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.5714 - val_loss: 2.6114\n",
      "Epoch 342/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.5714 - val_loss: 2.6079\n",
      "Epoch 343/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.5714 - val_loss: 2.6027\n",
      "Epoch 344/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.5714 - val_loss: 2.6008\n",
      "Epoch 345/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.5714 - val_loss: 2.6035\n",
      "Epoch 346/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.5714 - val_loss: 2.6084\n",
      "Epoch 347/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.5714 - val_loss: 2.6159\n",
      "Epoch 348/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.5714 - val_loss: 2.6224\n",
      "Epoch 349/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.5714 - val_loss: 2.6283\n",
      "Epoch 350/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.5714 - val_loss: 2.6324\n",
      "Epoch 351/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0543 - val_accuracy: 0.5000 - val_loss: 2.6339\n",
      "Epoch 352/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.5000 - val_loss: 2.6323\n",
      "Epoch 353/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0580 - val_accuracy: 0.5000 - val_loss: 2.6285\n",
      "Epoch 354/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5000 - val_loss: 2.6266\n",
      "Epoch 355/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5714 - val_loss: 2.6250\n",
      "Epoch 356/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0556 - val_accuracy: 0.5714 - val_loss: 2.6248\n",
      "Epoch 357/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.5714 - val_loss: 2.6300\n",
      "Epoch 358/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0556 - val_accuracy: 0.5714 - val_loss: 2.6411\n",
      "Epoch 359/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.5714 - val_loss: 2.6527\n",
      "Epoch 360/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.5000 - val_loss: 2.6630\n",
      "Epoch 361/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.5000 - val_loss: 2.6710\n",
      "Epoch 362/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0543 - val_accuracy: 0.5000 - val_loss: 2.6759\n",
      "Epoch 363/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0547 - val_accuracy: 0.5000 - val_loss: 2.6796\n",
      "Epoch 364/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.5000 - val_loss: 2.6792\n",
      "Epoch 365/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5000 - val_loss: 2.6764\n",
      "Epoch 366/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0542 - val_accuracy: 0.5000 - val_loss: 2.6753\n",
      "Epoch 367/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.5000 - val_loss: 2.6746\n",
      "Epoch 368/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0543 - val_accuracy: 0.5000 - val_loss: 2.6692\n",
      "Epoch 369/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.5000 - val_loss: 2.6626\n",
      "Epoch 370/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0540 - val_accuracy: 0.5000 - val_loss: 2.6539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0573 - val_accuracy: 0.5714 - val_loss: 2.6470\n",
      "Epoch 372/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5714 - val_loss: 2.6476\n",
      "Epoch 373/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0542 - val_accuracy: 0.5000 - val_loss: 2.6522\n",
      "Epoch 374/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.5000 - val_loss: 2.6558\n",
      "Epoch 375/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.5000 - val_loss: 2.6605\n",
      "Epoch 376/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.5000 - val_loss: 2.6616\n",
      "Epoch 377/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.5000 - val_loss: 2.6532\n",
      "Epoch 378/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.5000 - val_loss: 2.6436\n",
      "Epoch 379/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.5000 - val_loss: 2.6363\n",
      "Epoch 380/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0540 - val_accuracy: 0.5714 - val_loss: 2.6372\n",
      "Epoch 381/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0540 - val_accuracy: 0.5714 - val_loss: 2.6420\n",
      "Epoch 382/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0552 - val_accuracy: 0.5714 - val_loss: 2.6484\n",
      "Epoch 383/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9815 - loss: 0.0539 - val_accuracy: 0.5714 - val_loss: 2.6517\n",
      "Epoch 384/500\n",
      "2/2 - 0s - 106ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5714 - val_loss: 2.6577\n",
      "Epoch 385/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.5714 - val_loss: 2.6627\n",
      "Epoch 386/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0542 - val_accuracy: 0.5000 - val_loss: 2.6699\n",
      "Epoch 387/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.5000 - val_loss: 2.6741\n",
      "Epoch 388/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5000 - val_loss: 2.6755\n",
      "Epoch 389/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5000 - val_loss: 2.6758\n",
      "Epoch 390/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.5000 - val_loss: 2.6729\n",
      "Epoch 391/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.5000 - val_loss: 2.6645\n",
      "Epoch 392/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.5000 - val_loss: 2.6575\n",
      "Epoch 393/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5000 - val_loss: 2.6575\n",
      "Epoch 394/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5714 - val_loss: 2.6593\n",
      "Epoch 395/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5714 - val_loss: 2.6633\n",
      "Epoch 396/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5714 - val_loss: 2.6693\n",
      "Epoch 397/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.5000 - val_loss: 2.6774\n",
      "Epoch 398/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5000 - val_loss: 2.6879\n",
      "Epoch 399/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.5000 - val_loss: 2.6934\n",
      "Epoch 400/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5000 - val_loss: 2.6946\n",
      "Epoch 401/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5000 - val_loss: 2.6942\n",
      "Epoch 402/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0540 - val_accuracy: 0.5000 - val_loss: 2.6917\n",
      "Epoch 403/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5000 - val_loss: 2.6885\n",
      "Epoch 404/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5000 - val_loss: 2.6878\n",
      "Epoch 405/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.5000 - val_loss: 2.6891\n",
      "Epoch 406/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.5000 - val_loss: 2.6889\n",
      "Epoch 407/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0538 - val_accuracy: 0.5714 - val_loss: 2.6910\n",
      "Epoch 408/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5714 - val_loss: 2.6970\n",
      "Epoch 409/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.5000 - val_loss: 2.7032\n",
      "Epoch 410/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.5000 - val_loss: 2.7090\n",
      "Epoch 411/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0538 - val_accuracy: 0.5000 - val_loss: 2.7095\n",
      "Epoch 412/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.5000 - val_loss: 2.7115\n",
      "Epoch 413/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.5000 - val_loss: 2.7124\n",
      "Epoch 414/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.5000 - val_loss: 2.7117\n",
      "Epoch 415/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5000 - val_loss: 2.7084\n",
      "Epoch 416/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0542 - val_accuracy: 0.5000 - val_loss: 2.7043\n",
      "Epoch 417/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0543 - val_accuracy: 0.5000 - val_loss: 2.6971\n",
      "Epoch 418/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5000 - val_loss: 2.6941\n",
      "Epoch 419/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0542 - val_accuracy: 0.5000 - val_loss: 2.6943\n",
      "Epoch 420/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.5714 - val_loss: 2.6965\n",
      "Epoch 421/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9444 - loss: 0.0534 - val_accuracy: 0.5714 - val_loss: 2.7011\n",
      "Epoch 422/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.5714 - val_loss: 2.7042\n",
      "Epoch 423/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.5714 - val_loss: 2.7071\n",
      "Epoch 424/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5714 - val_loss: 2.7124\n",
      "Epoch 425/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.5000 - val_loss: 2.7165\n",
      "Epoch 426/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.5000 - val_loss: 2.7184\n",
      "Epoch 427/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.5000 - val_loss: 2.7198\n",
      "Epoch 428/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.5000 - val_loss: 2.7169\n",
      "Epoch 429/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.5000 - val_loss: 2.7154\n",
      "Epoch 430/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.5000 - val_loss: 2.7126\n",
      "Epoch 431/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0557 - val_accuracy: 0.5000 - val_loss: 2.7120\n",
      "Epoch 432/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5000 - val_loss: 2.7168\n",
      "Epoch 433/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.5000 - val_loss: 2.7198\n",
      "Epoch 434/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.5000 - val_loss: 2.7231\n",
      "Epoch 435/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9815 - loss: 0.0532 - val_accuracy: 0.5714 - val_loss: 2.7254\n",
      "Epoch 436/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.5714 - val_loss: 2.7269\n",
      "Epoch 437/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.5714 - val_loss: 2.7296\n",
      "Epoch 438/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.5714 - val_loss: 2.7314\n",
      "Epoch 439/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.5000 - val_loss: 2.7339\n",
      "Epoch 440/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.5000 - val_loss: 2.7340\n",
      "Epoch 441/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.5000 - val_loss: 2.7323\n",
      "Epoch 442/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0532 - val_accuracy: 0.5000 - val_loss: 2.7298\n",
      "Epoch 443/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.5000 - val_loss: 2.7282\n",
      "Epoch 444/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.5000 - val_loss: 2.7249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.5000 - val_loss: 2.7213\n",
      "Epoch 446/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.5000 - val_loss: 2.7218\n",
      "Epoch 447/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.5000 - val_loss: 2.7233\n",
      "Epoch 448/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.5000 - val_loss: 2.7243\n",
      "Epoch 449/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0541 - val_accuracy: 0.5714 - val_loss: 2.7271\n",
      "Epoch 450/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.5714 - val_loss: 2.7319\n",
      "Epoch 451/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.5714 - val_loss: 2.7392\n",
      "Epoch 452/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0532 - val_accuracy: 0.5000 - val_loss: 2.7459\n",
      "Epoch 453/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.5000 - val_loss: 2.7490\n",
      "Epoch 454/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0526 - val_accuracy: 0.5000 - val_loss: 2.7499\n",
      "Epoch 455/500\n",
      "2/2 - 0s - 48ms/step - accuracy: 0.9630 - loss: 0.0532 - val_accuracy: 0.5000 - val_loss: 2.7450\n",
      "Epoch 456/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.5000 - val_loss: 2.7385\n",
      "Epoch 457/500\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.9630 - loss: 0.0556 - val_accuracy: 0.5000 - val_loss: 2.7262\n",
      "Epoch 458/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.5000 - val_loss: 2.7186\n",
      "Epoch 459/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.5000 - val_loss: 2.7127\n",
      "Epoch 460/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.5714 - val_loss: 2.7147\n",
      "Epoch 461/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0532 - val_accuracy: 0.5714 - val_loss: 2.7212\n",
      "Epoch 462/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.5714 - val_loss: 2.7297\n",
      "Epoch 463/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0543 - val_accuracy: 0.5714 - val_loss: 2.7370\n",
      "Epoch 464/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.5000 - val_loss: 2.7425\n",
      "Epoch 465/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0538 - val_accuracy: 0.5000 - val_loss: 2.7490\n",
      "Epoch 466/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.5000 - val_loss: 2.7567\n",
      "Epoch 467/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5000 - val_loss: 2.7612\n",
      "Epoch 468/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.5000 - val_loss: 2.7643\n",
      "Epoch 469/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9259 - loss: 0.0562 - val_accuracy: 0.5000 - val_loss: 2.7660\n",
      "Epoch 470/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0532 - val_accuracy: 0.5000 - val_loss: 2.7635\n",
      "Epoch 471/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0532 - val_accuracy: 0.5000 - val_loss: 2.7591\n",
      "Epoch 472/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.5000 - val_loss: 2.7524\n",
      "Epoch 473/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.5000 - val_loss: 2.7476\n",
      "Epoch 474/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0531 - val_accuracy: 0.5000 - val_loss: 2.7443\n",
      "Epoch 475/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0530 - val_accuracy: 0.5000 - val_loss: 2.7464\n",
      "Epoch 476/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0540 - val_accuracy: 0.5000 - val_loss: 2.7521\n",
      "Epoch 477/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.5000 - val_loss: 2.7599\n",
      "Epoch 478/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.5000 - val_loss: 2.7677\n",
      "Epoch 479/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0530 - val_accuracy: 0.5000 - val_loss: 2.7722\n",
      "Epoch 480/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0527 - val_accuracy: 0.5000 - val_loss: 2.7723\n",
      "Epoch 481/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0531 - val_accuracy: 0.5000 - val_loss: 2.7689\n",
      "Epoch 482/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.5000 - val_loss: 2.7644\n",
      "Epoch 483/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.5000 - val_loss: 2.7552\n",
      "Epoch 484/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.5000 - val_loss: 2.7471\n",
      "Epoch 485/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0541 - val_accuracy: 0.5000 - val_loss: 2.7462\n",
      "Epoch 486/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0530 - val_accuracy: 0.5000 - val_loss: 2.7487\n",
      "Epoch 487/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0532 - val_accuracy: 0.5000 - val_loss: 2.7541\n",
      "Epoch 488/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.5000 - val_loss: 2.7610\n",
      "Epoch 489/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.5000 - val_loss: 2.7665\n",
      "Epoch 490/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.5000 - val_loss: 2.7711\n",
      "Epoch 491/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.5000 - val_loss: 2.7759\n",
      "Epoch 492/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0540 - val_accuracy: 0.5000 - val_loss: 2.7791\n",
      "Epoch 493/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.5000 - val_loss: 2.7822\n",
      "Epoch 494/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.5000 - val_loss: 2.7838\n",
      "Epoch 495/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0529 - val_accuracy: 0.5000 - val_loss: 2.7869\n",
      "Epoch 496/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0531 - val_accuracy: 0.5000 - val_loss: 2.7881\n",
      "Epoch 497/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.5000 - val_loss: 2.7843\n",
      "Epoch 498/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5000 - val_loss: 2.7766\n",
      "Epoch 499/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.5000 - val_loss: 2.7700\n",
      "Epoch 500/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5000 - val_loss: 2.7661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as RNN_chat_model.h5\n",
      "Training model: BRNN\n",
      "Training model: BRNN\n",
      "Epoch 1/500\n",
      "2/2 - 4s - 2s/step - accuracy: 0.1481 - loss: 2.7050 - val_accuracy: 0.0714 - val_loss: 2.6981\n",
      "Epoch 2/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.2037 - loss: 2.6944 - val_accuracy: 0.0714 - val_loss: 2.6927\n",
      "Epoch 3/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.2037 - loss: 2.6866 - val_accuracy: 0.0714 - val_loss: 2.6867\n",
      "Epoch 4/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.2037 - loss: 2.6763 - val_accuracy: 0.0714 - val_loss: 2.6788\n",
      "Epoch 5/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.2037 - loss: 2.6611 - val_accuracy: 0.0714 - val_loss: 2.6699\n",
      "Epoch 6/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.2037 - loss: 2.6451 - val_accuracy: 0.0714 - val_loss: 2.6608\n",
      "Epoch 7/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.2037 - loss: 2.6226 - val_accuracy: 0.0714 - val_loss: 2.6499\n",
      "Epoch 8/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.2037 - loss: 2.6039 - val_accuracy: 0.0714 - val_loss: 2.6393\n",
      "Epoch 9/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.2037 - loss: 2.5775 - val_accuracy: 0.0714 - val_loss: 2.6318\n",
      "Epoch 10/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.2037 - loss: 2.5543 - val_accuracy: 0.0714 - val_loss: 2.6286\n",
      "Epoch 11/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.2037 - loss: 2.5353 - val_accuracy: 0.0714 - val_loss: 2.6321\n",
      "Epoch 12/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.2037 - loss: 2.5111 - val_accuracy: 0.0714 - val_loss: 2.6317\n",
      "Epoch 13/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.2037 - loss: 2.4968 - val_accuracy: 0.0714 - val_loss: 2.6238\n",
      "Epoch 14/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.2037 - loss: 2.4850 - val_accuracy: 0.0714 - val_loss: 2.6254\n",
      "Epoch 15/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.2037 - loss: 2.4673 - val_accuracy: 0.0714 - val_loss: 2.6188\n",
      "Epoch 16/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.2037 - loss: 2.4475 - val_accuracy: 0.0714 - val_loss: 2.6089\n",
      "Epoch 17/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.2037 - loss: 2.4261 - val_accuracy: 0.0714 - val_loss: 2.5997\n",
      "Epoch 18/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.2037 - loss: 2.4059 - val_accuracy: 0.0714 - val_loss: 2.5962\n",
      "Epoch 19/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.2037 - loss: 2.3828 - val_accuracy: 0.0714 - val_loss: 2.5918\n",
      "Epoch 20/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.2037 - loss: 2.3554 - val_accuracy: 0.0714 - val_loss: 2.5895\n",
      "Epoch 21/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.2037 - loss: 2.3283 - val_accuracy: 0.0714 - val_loss: 2.5892\n",
      "Epoch 22/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.2222 - loss: 2.2928 - val_accuracy: 0.0714 - val_loss: 2.5816\n",
      "Epoch 23/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.2222 - loss: 2.2564 - val_accuracy: 0.0714 - val_loss: 2.5729\n",
      "Epoch 24/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.2222 - loss: 2.2190 - val_accuracy: 0.0714 - val_loss: 2.5692\n",
      "Epoch 25/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.2222 - loss: 2.1903 - val_accuracy: 0.0714 - val_loss: 2.5617\n",
      "Epoch 26/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.2222 - loss: 2.1419 - val_accuracy: 0.2143 - val_loss: 2.5442\n",
      "Epoch 27/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.2963 - loss: 2.1096 - val_accuracy: 0.2143 - val_loss: 2.5362\n",
      "Epoch 28/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.3333 - loss: 2.0728 - val_accuracy: 0.2143 - val_loss: 2.5229\n",
      "Epoch 29/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.3333 - loss: 2.0284 - val_accuracy: 0.2143 - val_loss: 2.5134\n",
      "Epoch 30/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.3148 - loss: 1.9952 - val_accuracy: 0.2143 - val_loss: 2.4949\n",
      "Epoch 31/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.3333 - loss: 1.9596 - val_accuracy: 0.2143 - val_loss: 2.4652\n",
      "Epoch 32/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.3519 - loss: 1.9163 - val_accuracy: 0.2143 - val_loss: 2.4275\n",
      "Epoch 33/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.3519 - loss: 1.8810 - val_accuracy: 0.2143 - val_loss: 2.3952\n",
      "Epoch 34/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.3704 - loss: 1.8531 - val_accuracy: 0.2143 - val_loss: 2.3548\n",
      "Epoch 35/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.3889 - loss: 1.8063 - val_accuracy: 0.2857 - val_loss: 2.3184\n",
      "Epoch 36/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.3889 - loss: 1.7724 - val_accuracy: 0.2143 - val_loss: 2.2856\n",
      "Epoch 37/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.4074 - loss: 1.7232 - val_accuracy: 0.2857 - val_loss: 2.2709\n",
      "Epoch 38/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.4630 - loss: 1.6821 - val_accuracy: 0.2857 - val_loss: 2.2324\n",
      "Epoch 39/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.4259 - loss: 1.6482 - val_accuracy: 0.2857 - val_loss: 2.2348\n",
      "Epoch 40/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.5556 - loss: 1.6177 - val_accuracy: 0.2857 - val_loss: 2.1928\n",
      "Epoch 41/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.5370 - loss: 1.5724 - val_accuracy: 0.2857 - val_loss: 2.1479\n",
      "Epoch 42/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.5926 - loss: 1.5257 - val_accuracy: 0.2857 - val_loss: 2.1873\n",
      "Epoch 43/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.6111 - loss: 1.4916 - val_accuracy: 0.2857 - val_loss: 2.2027\n",
      "Epoch 44/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.6111 - loss: 1.4473 - val_accuracy: 0.2857 - val_loss: 2.2195\n",
      "Epoch 45/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.6296 - loss: 1.4116 - val_accuracy: 0.2857 - val_loss: 2.2769\n",
      "Epoch 46/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.6481 - loss: 1.3656 - val_accuracy: 0.2857 - val_loss: 2.2510\n",
      "Epoch 47/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.6296 - loss: 1.3190 - val_accuracy: 0.2857 - val_loss: 2.2396\n",
      "Epoch 48/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.6296 - loss: 1.2737 - val_accuracy: 0.2857 - val_loss: 2.2877\n",
      "Epoch 49/500\n",
      "2/2 - 0s - 48ms/step - accuracy: 0.6111 - loss: 1.2366 - val_accuracy: 0.2857 - val_loss: 2.3025\n",
      "Epoch 50/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.6481 - loss: 1.1931 - val_accuracy: 0.3571 - val_loss: 2.4290\n",
      "Epoch 51/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.6852 - loss: 1.1318 - val_accuracy: 0.2857 - val_loss: 2.4529\n",
      "Epoch 52/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.6481 - loss: 1.0825 - val_accuracy: 0.2143 - val_loss: 2.5603\n",
      "Epoch 53/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7407 - loss: 1.0444 - val_accuracy: 0.2857 - val_loss: 2.4941\n",
      "Epoch 54/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.6852 - loss: 0.9856 - val_accuracy: 0.2857 - val_loss: 2.4787\n",
      "Epoch 55/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.7037 - loss: 0.9424 - val_accuracy: 0.2143 - val_loss: 2.6507\n",
      "Epoch 56/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.7037 - loss: 0.9174 - val_accuracy: 0.2143 - val_loss: 2.5183\n",
      "Epoch 57/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.7407 - loss: 0.8459 - val_accuracy: 0.2857 - val_loss: 2.4794\n",
      "Epoch 58/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.7593 - loss: 0.8202 - val_accuracy: 0.2857 - val_loss: 2.6089\n",
      "Epoch 59/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.8148 - loss: 0.7770 - val_accuracy: 0.2143 - val_loss: 2.7929\n",
      "Epoch 60/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.7963 - loss: 0.7447 - val_accuracy: 0.3571 - val_loss: 2.6022\n",
      "Epoch 61/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.7778 - loss: 0.7346 - val_accuracy: 0.3571 - val_loss: 2.6294\n",
      "Epoch 62/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.8519 - loss: 0.6641 - val_accuracy: 0.2857 - val_loss: 2.9835\n",
      "Epoch 63/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.8704 - loss: 0.6521 - val_accuracy: 0.2857 - val_loss: 2.8294\n",
      "Epoch 64/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.8889 - loss: 0.5870 - val_accuracy: 0.3571 - val_loss: 2.6698\n",
      "Epoch 65/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8889 - loss: 0.5737 - val_accuracy: 0.4286 - val_loss: 2.6731\n",
      "Epoch 66/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9074 - loss: 0.5239 - val_accuracy: 0.2857 - val_loss: 2.8611\n",
      "Epoch 67/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.5013 - val_accuracy: 0.3571 - val_loss: 2.9764\n",
      "Epoch 68/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.4673 - val_accuracy: 0.3571 - val_loss: 2.8673\n",
      "Epoch 69/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9074 - loss: 0.4358 - val_accuracy: 0.4286 - val_loss: 2.8061\n",
      "Epoch 70/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.4234 - val_accuracy: 0.2857 - val_loss: 2.9221\n",
      "Epoch 71/500\n",
      "2/2 - 0s - 57ms/step - accuracy: 0.9259 - loss: 0.3885 - val_accuracy: 0.3571 - val_loss: 3.0880\n",
      "Epoch 72/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9444 - loss: 0.3723 - val_accuracy: 0.3571 - val_loss: 3.0682\n",
      "Epoch 73/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.3485 - val_accuracy: 0.2857 - val_loss: 2.9562\n",
      "Epoch 74/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.3169 - val_accuracy: 0.3571 - val_loss: 2.8084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.3148 - val_accuracy: 0.5000 - val_loss: 2.8601\n",
      "Epoch 76/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9444 - loss: 0.2780 - val_accuracy: 0.3571 - val_loss: 2.8869\n",
      "Epoch 77/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9074 - loss: 0.2940 - val_accuracy: 0.3571 - val_loss: 2.5892\n",
      "Epoch 78/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.2856 - val_accuracy: 0.4286 - val_loss: 3.2457\n",
      "Epoch 79/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.2727 - val_accuracy: 0.4286 - val_loss: 3.1733\n",
      "Epoch 80/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.8704 - loss: 0.3630 - val_accuracy: 0.4286 - val_loss: 2.8285\n",
      "Epoch 81/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.2977 - val_accuracy: 0.5000 - val_loss: 2.7229\n",
      "Epoch 82/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.2736 - val_accuracy: 0.4286 - val_loss: 3.0384\n",
      "Epoch 83/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.2337 - val_accuracy: 0.3571 - val_loss: 3.2330\n",
      "Epoch 84/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.2394 - val_accuracy: 0.3571 - val_loss: 3.1959\n",
      "Epoch 85/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.2193 - val_accuracy: 0.2857 - val_loss: 3.0188\n",
      "Epoch 86/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.1782 - val_accuracy: 0.3571 - val_loss: 2.8954\n",
      "Epoch 87/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.1950 - val_accuracy: 0.4286 - val_loss: 2.8845\n",
      "Epoch 88/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.1754 - val_accuracy: 0.5000 - val_loss: 3.0107\n",
      "Epoch 89/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.1676 - val_accuracy: 0.4286 - val_loss: 3.1580\n",
      "Epoch 90/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.1602 - val_accuracy: 0.5000 - val_loss: 3.2121\n",
      "Epoch 91/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.1530 - val_accuracy: 0.5000 - val_loss: 3.2140\n",
      "Epoch 92/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.1470 - val_accuracy: 0.5000 - val_loss: 3.0962\n",
      "Epoch 93/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.1356 - val_accuracy: 0.3571 - val_loss: 3.1051\n",
      "Epoch 94/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.1427 - val_accuracy: 0.3571 - val_loss: 3.1022\n",
      "Epoch 95/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.1391 - val_accuracy: 0.4286 - val_loss: 3.0411\n",
      "Epoch 96/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.1269 - val_accuracy: 0.4286 - val_loss: 3.0967\n",
      "Epoch 97/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.1260 - val_accuracy: 0.4286 - val_loss: 3.1537\n",
      "Epoch 98/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.1209 - val_accuracy: 0.5000 - val_loss: 3.1501\n",
      "Epoch 99/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.1146 - val_accuracy: 0.5000 - val_loss: 3.1193\n",
      "Epoch 100/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.1136 - val_accuracy: 0.5000 - val_loss: 3.1081\n",
      "Epoch 101/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.1125 - val_accuracy: 0.5714 - val_loss: 3.0928\n",
      "Epoch 102/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.1103 - val_accuracy: 0.5714 - val_loss: 3.0818\n",
      "Epoch 103/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.1033 - val_accuracy: 0.5714 - val_loss: 3.1444\n",
      "Epoch 104/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.1067 - val_accuracy: 0.5000 - val_loss: 3.2213\n",
      "Epoch 105/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.1012 - val_accuracy: 0.4286 - val_loss: 3.2693\n",
      "Epoch 106/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0993 - val_accuracy: 0.4286 - val_loss: 3.2931\n",
      "Epoch 107/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9444 - loss: 0.0963 - val_accuracy: 0.4286 - val_loss: 3.3206\n",
      "Epoch 108/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0947 - val_accuracy: 0.4286 - val_loss: 3.3194\n",
      "Epoch 109/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0982 - val_accuracy: 0.4286 - val_loss: 3.3076\n",
      "Epoch 110/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0917 - val_accuracy: 0.4286 - val_loss: 3.2831\n",
      "Epoch 111/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0916 - val_accuracy: 0.4286 - val_loss: 3.2877\n",
      "Epoch 112/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0907 - val_accuracy: 0.4286 - val_loss: 3.3172\n",
      "Epoch 113/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0880 - val_accuracy: 0.5000 - val_loss: 3.3596\n",
      "Epoch 114/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0882 - val_accuracy: 0.5000 - val_loss: 3.3989\n",
      "Epoch 115/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0886 - val_accuracy: 0.4286 - val_loss: 3.4275\n",
      "Epoch 116/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9444 - loss: 0.0885 - val_accuracy: 0.5000 - val_loss: 3.3671\n",
      "Epoch 117/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0856 - val_accuracy: 0.5000 - val_loss: 3.3464\n",
      "Epoch 118/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.9444 - loss: 0.0838 - val_accuracy: 0.5000 - val_loss: 3.3569\n",
      "Epoch 119/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0823 - val_accuracy: 0.5000 - val_loss: 3.3804\n",
      "Epoch 120/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0834 - val_accuracy: 0.5000 - val_loss: 3.4252\n",
      "Epoch 121/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.0902 - val_accuracy: 0.5000 - val_loss: 3.4367\n",
      "Epoch 122/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0811 - val_accuracy: 0.5000 - val_loss: 3.4848\n",
      "Epoch 123/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0786 - val_accuracy: 0.5000 - val_loss: 3.5368\n",
      "Epoch 124/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0901 - val_accuracy: 0.4286 - val_loss: 3.5606\n",
      "Epoch 125/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0799 - val_accuracy: 0.4286 - val_loss: 3.5125\n",
      "Epoch 126/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0781 - val_accuracy: 0.4286 - val_loss: 3.4922\n",
      "Epoch 127/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0814 - val_accuracy: 0.4286 - val_loss: 3.4659\n",
      "Epoch 128/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0798 - val_accuracy: 0.4286 - val_loss: 3.5022\n",
      "Epoch 129/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9444 - loss: 0.0800 - val_accuracy: 0.4286 - val_loss: 3.5680\n",
      "Epoch 130/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0767 - val_accuracy: 0.5000 - val_loss: 3.5571\n",
      "Epoch 131/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9259 - loss: 0.0833 - val_accuracy: 0.5000 - val_loss: 3.5658\n",
      "Epoch 132/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0751 - val_accuracy: 0.5000 - val_loss: 3.5868\n",
      "Epoch 133/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0840 - val_accuracy: 0.5000 - val_loss: 3.5899\n",
      "Epoch 134/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0757 - val_accuracy: 0.5000 - val_loss: 3.5491\n",
      "Epoch 135/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0780 - val_accuracy: 0.4286 - val_loss: 3.5115\n",
      "Epoch 136/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0745 - val_accuracy: 0.4286 - val_loss: 3.5068\n",
      "Epoch 137/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0724 - val_accuracy: 0.4286 - val_loss: 3.5510\n",
      "Epoch 138/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0797 - val_accuracy: 0.4286 - val_loss: 3.6260\n",
      "Epoch 139/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0751 - val_accuracy: 0.4286 - val_loss: 3.6161\n",
      "Epoch 140/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0726 - val_accuracy: 0.4286 - val_loss: 3.6264\n",
      "Epoch 141/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0726 - val_accuracy: 0.4286 - val_loss: 3.6508\n",
      "Epoch 142/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0701 - val_accuracy: 0.4286 - val_loss: 3.6414\n",
      "Epoch 143/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9444 - loss: 0.0711 - val_accuracy: 0.5000 - val_loss: 3.6311\n",
      "Epoch 144/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0713 - val_accuracy: 0.5000 - val_loss: 3.6078\n",
      "Epoch 145/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0710 - val_accuracy: 0.5000 - val_loss: 3.6099\n",
      "Epoch 146/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9815 - loss: 0.0687 - val_accuracy: 0.5000 - val_loss: 3.6057\n",
      "Epoch 147/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0684 - val_accuracy: 0.5000 - val_loss: 3.6040\n",
      "Epoch 148/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.0730 - val_accuracy: 0.5000 - val_loss: 3.6165\n",
      "Epoch 149/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - 39ms/step - accuracy: 0.9444 - loss: 0.0712 - val_accuracy: 0.5000 - val_loss: 3.6087\n",
      "Epoch 150/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0699 - val_accuracy: 0.5000 - val_loss: 3.6374\n",
      "Epoch 151/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.0727 - val_accuracy: 0.5000 - val_loss: 3.6608\n",
      "Epoch 152/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0670 - val_accuracy: 0.5000 - val_loss: 3.6659\n",
      "Epoch 153/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0700 - val_accuracy: 0.5000 - val_loss: 3.6699\n",
      "Epoch 154/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0735 - val_accuracy: 0.5000 - val_loss: 3.6972\n",
      "Epoch 155/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.9630 - loss: 0.0678 - val_accuracy: 0.5000 - val_loss: 3.7117\n",
      "Epoch 156/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9444 - loss: 0.0686 - val_accuracy: 0.5000 - val_loss: 3.7513\n",
      "Epoch 157/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0671 - val_accuracy: 0.5000 - val_loss: 3.7661\n",
      "Epoch 158/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9444 - loss: 0.0679 - val_accuracy: 0.5000 - val_loss: 3.7665\n",
      "Epoch 159/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0663 - val_accuracy: 0.5000 - val_loss: 3.7743\n",
      "Epoch 160/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0650 - val_accuracy: 0.5000 - val_loss: 3.7839\n",
      "Epoch 161/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0655 - val_accuracy: 0.4286 - val_loss: 3.7942\n",
      "Epoch 162/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0676 - val_accuracy: 0.4286 - val_loss: 3.7798\n",
      "Epoch 163/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0656 - val_accuracy: 0.5000 - val_loss: 3.7460\n",
      "Epoch 164/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.9630 - loss: 0.0644 - val_accuracy: 0.5000 - val_loss: 3.7112\n",
      "Epoch 165/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0696 - val_accuracy: 0.4286 - val_loss: 3.6974\n",
      "Epoch 166/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0690 - val_accuracy: 0.5000 - val_loss: 3.7262\n",
      "Epoch 167/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0643 - val_accuracy: 0.4286 - val_loss: 3.8221\n",
      "Epoch 168/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0696 - val_accuracy: 0.4286 - val_loss: 3.8903\n",
      "Epoch 169/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0704 - val_accuracy: 0.4286 - val_loss: 3.8543\n",
      "Epoch 170/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0677 - val_accuracy: 0.5000 - val_loss: 3.8175\n",
      "Epoch 171/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0631 - val_accuracy: 0.4286 - val_loss: 3.8160\n",
      "Epoch 172/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0655 - val_accuracy: 0.4286 - val_loss: 3.8142\n",
      "Epoch 173/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0637 - val_accuracy: 0.5000 - val_loss: 3.8151\n",
      "Epoch 174/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0631 - val_accuracy: 0.4286 - val_loss: 3.8178\n",
      "Epoch 175/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0652 - val_accuracy: 0.4286 - val_loss: 3.8211\n",
      "Epoch 176/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0625 - val_accuracy: 0.5000 - val_loss: 3.7914\n",
      "Epoch 177/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9815 - loss: 0.0613 - val_accuracy: 0.5000 - val_loss: 3.7681\n",
      "Epoch 178/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0633 - val_accuracy: 0.5000 - val_loss: 3.7642\n",
      "Epoch 179/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0655 - val_accuracy: 0.5000 - val_loss: 3.7869\n",
      "Epoch 180/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0641 - val_accuracy: 0.5000 - val_loss: 3.8429\n",
      "Epoch 181/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0655 - val_accuracy: 0.4286 - val_loss: 3.8958\n",
      "Epoch 182/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0624 - val_accuracy: 0.4286 - val_loss: 3.8756\n",
      "Epoch 183/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0615 - val_accuracy: 0.5000 - val_loss: 3.8571\n",
      "Epoch 184/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0615 - val_accuracy: 0.5000 - val_loss: 3.8538\n",
      "Epoch 185/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0630 - val_accuracy: 0.5000 - val_loss: 3.8541\n",
      "Epoch 186/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0614 - val_accuracy: 0.5000 - val_loss: 3.8596\n",
      "Epoch 187/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0624 - val_accuracy: 0.5000 - val_loss: 3.8731\n",
      "Epoch 188/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0624 - val_accuracy: 0.5000 - val_loss: 3.8828\n",
      "Epoch 189/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0608 - val_accuracy: 0.5000 - val_loss: 3.9104\n",
      "Epoch 190/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0611 - val_accuracy: 0.5000 - val_loss: 3.9371\n",
      "Epoch 191/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0611 - val_accuracy: 0.4286 - val_loss: 3.9711\n",
      "Epoch 192/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0611 - val_accuracy: 0.5000 - val_loss: 3.9600\n",
      "Epoch 193/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0620 - val_accuracy: 0.5000 - val_loss: 3.9405\n",
      "Epoch 194/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0615 - val_accuracy: 0.5000 - val_loss: 3.9320\n",
      "Epoch 195/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0625 - val_accuracy: 0.5000 - val_loss: 3.9119\n",
      "Epoch 196/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0618 - val_accuracy: 0.5000 - val_loss: 3.9187\n",
      "Epoch 197/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9444 - loss: 0.0613 - val_accuracy: 0.5000 - val_loss: 3.9188\n",
      "Epoch 198/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0604 - val_accuracy: 0.5000 - val_loss: 3.9477\n",
      "Epoch 199/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0624 - val_accuracy: 0.4286 - val_loss: 4.0028\n",
      "Epoch 200/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0614 - val_accuracy: 0.4286 - val_loss: 3.9970\n",
      "Epoch 201/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0616 - val_accuracy: 0.5000 - val_loss: 3.9938\n",
      "Epoch 202/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0596 - val_accuracy: 0.5000 - val_loss: 3.9551\n",
      "Epoch 203/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0627 - val_accuracy: 0.5000 - val_loss: 3.9429\n",
      "Epoch 204/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0600 - val_accuracy: 0.5000 - val_loss: 3.9619\n",
      "Epoch 205/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9815 - loss: 0.0593 - val_accuracy: 0.4286 - val_loss: 3.9900\n",
      "Epoch 206/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0593 - val_accuracy: 0.4286 - val_loss: 3.9993\n",
      "Epoch 207/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0609 - val_accuracy: 0.4286 - val_loss: 3.9940\n",
      "Epoch 208/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0594 - val_accuracy: 0.5000 - val_loss: 3.9568\n",
      "Epoch 209/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9815 - loss: 0.0590 - val_accuracy: 0.5000 - val_loss: 3.9290\n",
      "Epoch 210/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0603 - val_accuracy: 0.5000 - val_loss: 3.9418\n",
      "Epoch 211/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0651 - val_accuracy: 0.5000 - val_loss: 3.9601\n",
      "Epoch 212/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0638 - val_accuracy: 0.4286 - val_loss: 4.0504\n",
      "Epoch 213/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0599 - val_accuracy: 0.4286 - val_loss: 4.0920\n",
      "Epoch 214/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0643 - val_accuracy: 0.4286 - val_loss: 4.0638\n",
      "Epoch 215/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0612 - val_accuracy: 0.4286 - val_loss: 4.0607\n",
      "Epoch 216/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0594 - val_accuracy: 0.5000 - val_loss: 4.0323\n",
      "Epoch 217/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0588 - val_accuracy: 0.5000 - val_loss: 4.0095\n",
      "Epoch 218/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0601 - val_accuracy: 0.5000 - val_loss: 3.9873\n",
      "Epoch 219/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0604 - val_accuracy: 0.5000 - val_loss: 3.9894\n",
      "Epoch 220/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0587 - val_accuracy: 0.5000 - val_loss: 4.0226\n",
      "Epoch 221/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9444 - loss: 0.0604 - val_accuracy: 0.4286 - val_loss: 4.0833\n",
      "Epoch 222/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0596 - val_accuracy: 0.4286 - val_loss: 4.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0602 - val_accuracy: 0.4286 - val_loss: 4.1172\n",
      "Epoch 224/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0605 - val_accuracy: 0.5000 - val_loss: 4.0896\n",
      "Epoch 225/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0593 - val_accuracy: 0.5000 - val_loss: 4.0855\n",
      "Epoch 226/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.9630 - loss: 0.0595 - val_accuracy: 0.5000 - val_loss: 4.1044\n",
      "Epoch 227/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0588 - val_accuracy: 0.4286 - val_loss: 4.1013\n",
      "Epoch 228/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0632 - val_accuracy: 0.5000 - val_loss: 4.0799\n",
      "Epoch 229/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0579 - val_accuracy: 0.4286 - val_loss: 4.0948\n",
      "Epoch 230/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0577 - val_accuracy: 0.4286 - val_loss: 4.1074\n",
      "Epoch 231/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0586 - val_accuracy: 0.4286 - val_loss: 4.1042\n",
      "Epoch 232/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0581 - val_accuracy: 0.4286 - val_loss: 4.0790\n",
      "Epoch 233/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9815 - loss: 0.0576 - val_accuracy: 0.5000 - val_loss: 4.0544\n",
      "Epoch 234/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0595 - val_accuracy: 0.5000 - val_loss: 4.0406\n",
      "Epoch 235/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0617 - val_accuracy: 0.5000 - val_loss: 4.0589\n",
      "Epoch 236/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9444 - loss: 0.0606 - val_accuracy: 0.4286 - val_loss: 4.1278\n",
      "Epoch 237/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0581 - val_accuracy: 0.4286 - val_loss: 4.1483\n",
      "Epoch 238/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0605 - val_accuracy: 0.4286 - val_loss: 4.1564\n",
      "Epoch 239/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0604 - val_accuracy: 0.5000 - val_loss: 4.1110\n",
      "Epoch 240/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0628 - val_accuracy: 0.5000 - val_loss: 4.0943\n",
      "Epoch 241/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0593 - val_accuracy: 0.5000 - val_loss: 4.1226\n",
      "Epoch 242/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0576 - val_accuracy: 0.5000 - val_loss: 4.1279\n",
      "Epoch 243/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9259 - loss: 0.0595 - val_accuracy: 0.4286 - val_loss: 4.1340\n",
      "Epoch 244/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.4286 - val_loss: 4.1612\n",
      "Epoch 245/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0636 - val_accuracy: 0.4286 - val_loss: 4.1701\n",
      "Epoch 246/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0574 - val_accuracy: 0.5000 - val_loss: 4.1226\n",
      "Epoch 247/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0605 - val_accuracy: 0.5000 - val_loss: 4.0931\n",
      "Epoch 248/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0587 - val_accuracy: 0.5000 - val_loss: 4.0997\n",
      "Epoch 249/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0581 - val_accuracy: 0.5000 - val_loss: 4.1277\n",
      "Epoch 250/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0592 - val_accuracy: 0.4286 - val_loss: 4.1785\n",
      "Epoch 251/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0585 - val_accuracy: 0.4286 - val_loss: 4.2047\n",
      "Epoch 252/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0574 - val_accuracy: 0.4286 - val_loss: 4.1877\n",
      "Epoch 253/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0581 - val_accuracy: 0.5000 - val_loss: 4.1695\n",
      "Epoch 254/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0564 - val_accuracy: 0.5000 - val_loss: 4.1724\n",
      "Epoch 255/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9444 - loss: 0.0573 - val_accuracy: 0.5000 - val_loss: 4.1839\n",
      "Epoch 256/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0577 - val_accuracy: 0.5000 - val_loss: 4.1767\n",
      "Epoch 257/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0564 - val_accuracy: 0.5000 - val_loss: 4.1814\n",
      "Epoch 258/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9444 - loss: 0.0563 - val_accuracy: 0.5000 - val_loss: 4.1841\n",
      "Epoch 259/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0567 - val_accuracy: 0.5000 - val_loss: 4.1893\n",
      "Epoch 260/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0582 - val_accuracy: 0.4286 - val_loss: 4.2110\n",
      "Epoch 261/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0575 - val_accuracy: 0.5000 - val_loss: 4.2007\n",
      "Epoch 262/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.5000 - val_loss: 4.2008\n",
      "Epoch 263/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.0601 - val_accuracy: 0.5000 - val_loss: 4.1890\n",
      "Epoch 264/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9444 - loss: 0.0581 - val_accuracy: 0.4286 - val_loss: 4.2103\n",
      "Epoch 265/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.5000 - val_loss: 4.2034\n",
      "Epoch 266/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.5000 - val_loss: 4.1959\n",
      "Epoch 267/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0565 - val_accuracy: 0.5000 - val_loss: 4.1932\n",
      "Epoch 268/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.5000 - val_loss: 4.1791\n",
      "Epoch 269/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0563 - val_accuracy: 0.5000 - val_loss: 4.1631\n",
      "Epoch 270/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0580 - val_accuracy: 0.5000 - val_loss: 4.1633\n",
      "Epoch 271/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0568 - val_accuracy: 0.5000 - val_loss: 4.1853\n",
      "Epoch 272/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0556 - val_accuracy: 0.4286 - val_loss: 4.2215\n",
      "Epoch 273/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.4286 - val_loss: 4.2718\n",
      "Epoch 274/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0596 - val_accuracy: 0.4286 - val_loss: 4.2862\n",
      "Epoch 275/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0609 - val_accuracy: 0.4286 - val_loss: 4.2500\n",
      "Epoch 276/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0612 - val_accuracy: 0.5000 - val_loss: 4.1949\n",
      "Epoch 277/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0585 - val_accuracy: 0.5000 - val_loss: 4.1863\n",
      "Epoch 278/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0571 - val_accuracy: 0.5000 - val_loss: 4.2030\n",
      "Epoch 279/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0568 - val_accuracy: 0.5000 - val_loss: 4.2164\n",
      "Epoch 280/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.5000 - val_loss: 4.2287\n",
      "Epoch 281/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0567 - val_accuracy: 0.5000 - val_loss: 4.2503\n",
      "Epoch 282/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0566 - val_accuracy: 0.5000 - val_loss: 4.2579\n",
      "Epoch 283/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0556 - val_accuracy: 0.5000 - val_loss: 4.2786\n",
      "Epoch 284/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0558 - val_accuracy: 0.4286 - val_loss: 4.2919\n",
      "Epoch 285/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.4286 - val_loss: 4.3104\n",
      "Epoch 286/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.4286 - val_loss: 4.3033\n",
      "Epoch 287/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.4286 - val_loss: 4.2911\n",
      "Epoch 288/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0563 - val_accuracy: 0.4286 - val_loss: 4.2691\n",
      "Epoch 289/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0574 - val_accuracy: 0.5000 - val_loss: 4.2324\n",
      "Epoch 290/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.5000 - val_loss: 4.2216\n",
      "Epoch 291/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0565 - val_accuracy: 0.5000 - val_loss: 4.2239\n",
      "Epoch 292/500\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.5000 - val_loss: 4.2469\n",
      "Epoch 293/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.4286 - val_loss: 4.2715\n",
      "Epoch 294/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0557 - val_accuracy: 0.4286 - val_loss: 4.2848\n",
      "Epoch 295/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0570 - val_accuracy: 0.4286 - val_loss: 4.3033\n",
      "Epoch 296/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0599 - val_accuracy: 0.4286 - val_loss: 4.2817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/500\n",
      "2/2 - 0s - 47ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.4286 - val_loss: 4.2885\n",
      "Epoch 298/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0566 - val_accuracy: 0.4286 - val_loss: 4.2961\n",
      "Epoch 299/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9444 - loss: 0.0567 - val_accuracy: 0.5000 - val_loss: 4.2729\n",
      "Epoch 300/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.5000 - val_loss: 4.2729\n",
      "Epoch 301/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.5000 - val_loss: 4.2881\n",
      "Epoch 302/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0574 - val_accuracy: 0.4286 - val_loss: 4.2911\n",
      "Epoch 303/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.4286 - val_loss: 4.3214\n",
      "Epoch 304/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.4286 - val_loss: 4.3348\n",
      "Epoch 305/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0564 - val_accuracy: 0.4286 - val_loss: 4.2974\n",
      "Epoch 306/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.5000 - val_loss: 4.2598\n",
      "Epoch 307/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5000 - val_loss: 4.2490\n",
      "Epoch 308/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.5000 - val_loss: 4.2407\n",
      "Epoch 309/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0616 - val_accuracy: 0.5000 - val_loss: 4.2492\n",
      "Epoch 310/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.5000 - val_loss: 4.3167\n",
      "Epoch 311/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.4286 - val_loss: 4.3837\n",
      "Epoch 312/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.4286 - val_loss: 4.4147\n",
      "Epoch 313/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0566 - val_accuracy: 0.4286 - val_loss: 4.4064\n",
      "Epoch 314/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0580 - val_accuracy: 0.4286 - val_loss: 4.3743\n",
      "Epoch 315/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9259 - loss: 0.0627 - val_accuracy: 0.5000 - val_loss: 4.3014\n",
      "Epoch 316/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0557 - val_accuracy: 0.5000 - val_loss: 4.2909\n",
      "Epoch 317/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.5000 - val_loss: 4.2876\n",
      "Epoch 318/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0597 - val_accuracy: 0.5000 - val_loss: 4.2819\n",
      "Epoch 319/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.4286 - val_loss: 4.3311\n",
      "Epoch 320/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.4286 - val_loss: 4.3793\n",
      "Epoch 321/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.4286 - val_loss: 4.3898\n",
      "Epoch 322/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0572 - val_accuracy: 0.4286 - val_loss: 4.3992\n",
      "Epoch 323/500\n",
      "2/2 - 0s - 60ms/step - accuracy: 0.9630 - loss: 0.0577 - val_accuracy: 0.4286 - val_loss: 4.3557\n",
      "Epoch 324/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.4286 - val_loss: 4.3335\n",
      "Epoch 325/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.5000 - val_loss: 4.3146\n",
      "Epoch 326/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5000 - val_loss: 4.3095\n",
      "Epoch 327/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.5000 - val_loss: 4.3203\n",
      "Epoch 328/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.5000 - val_loss: 4.3265\n",
      "Epoch 329/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0567 - val_accuracy: 0.5000 - val_loss: 4.3659\n",
      "Epoch 330/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9259 - loss: 0.0585 - val_accuracy: 0.4286 - val_loss: 4.3942\n",
      "Epoch 331/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.4286 - val_loss: 4.3855\n",
      "Epoch 332/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.5000 - val_loss: 4.3796\n",
      "Epoch 333/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5000 - val_loss: 4.3795\n",
      "Epoch 334/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.4286 - val_loss: 4.3972\n",
      "Epoch 335/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0551 - val_accuracy: 0.4286 - val_loss: 4.4025\n",
      "Epoch 336/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.5000 - val_loss: 4.3963\n",
      "Epoch 337/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.4286 - val_loss: 4.4060\n",
      "Epoch 338/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.4286 - val_loss: 4.4139\n",
      "Epoch 339/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.5000 - val_loss: 4.4058\n",
      "Epoch 340/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0583 - val_accuracy: 0.5000 - val_loss: 4.4009\n",
      "Epoch 341/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.4286 - val_loss: 4.4264\n",
      "Epoch 342/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.4286 - val_loss: 4.4602\n",
      "Epoch 343/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.4286 - val_loss: 4.4783\n",
      "Epoch 344/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0589 - val_accuracy: 0.4286 - val_loss: 4.4779\n",
      "Epoch 345/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0591 - val_accuracy: 0.4286 - val_loss: 4.4142\n",
      "Epoch 346/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.4286 - val_loss: 4.3680\n",
      "Epoch 347/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0542 - val_accuracy: 0.5000 - val_loss: 4.3381\n",
      "Epoch 348/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.5000 - val_loss: 4.3285\n",
      "Epoch 349/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0564 - val_accuracy: 0.5000 - val_loss: 4.3421\n",
      "Epoch 350/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.4286 - val_loss: 4.3839\n",
      "Epoch 351/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0538 - val_accuracy: 0.4286 - val_loss: 4.4231\n",
      "Epoch 352/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0569 - val_accuracy: 0.4286 - val_loss: 4.4604\n",
      "Epoch 353/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.4286 - val_loss: 4.4480\n",
      "Epoch 354/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.4286 - val_loss: 4.4335\n",
      "Epoch 355/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.4286 - val_loss: 4.4251\n",
      "Epoch 356/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.4286 - val_loss: 4.4298\n",
      "Epoch 357/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.4286 - val_loss: 4.4264\n",
      "Epoch 358/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.4286 - val_loss: 4.4224\n",
      "Epoch 359/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0540 - val_accuracy: 0.5000 - val_loss: 4.4003\n",
      "Epoch 360/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.5000 - val_loss: 4.3909\n",
      "Epoch 361/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.5000 - val_loss: 4.3813\n",
      "Epoch 362/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.4286 - val_loss: 4.3979\n",
      "Epoch 363/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.4286 - val_loss: 4.4316\n",
      "Epoch 364/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0542 - val_accuracy: 0.4286 - val_loss: 4.4725\n",
      "Epoch 365/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.4286 - val_loss: 4.4849\n",
      "Epoch 366/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.4286 - val_loss: 4.4773\n",
      "Epoch 367/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.4286 - val_loss: 4.4354\n",
      "Epoch 368/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0559 - val_accuracy: 0.5000 - val_loss: 4.4024\n",
      "Epoch 369/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0542 - val_accuracy: 0.5000 - val_loss: 4.4031\n",
      "Epoch 370/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0542 - val_accuracy: 0.5000 - val_loss: 4.4170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.4286 - val_loss: 4.4287\n",
      "Epoch 372/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0538 - val_accuracy: 0.4286 - val_loss: 4.4555\n",
      "Epoch 373/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.4286 - val_loss: 4.4700\n",
      "Epoch 374/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0543 - val_accuracy: 0.4286 - val_loss: 4.4806\n",
      "Epoch 375/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.4286 - val_loss: 4.4773\n",
      "Epoch 376/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.4286 - val_loss: 4.4746\n",
      "Epoch 377/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.4286 - val_loss: 4.4525\n",
      "Epoch 378/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0557 - val_accuracy: 0.4286 - val_loss: 4.4184\n",
      "Epoch 379/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5000 - val_loss: 4.4086\n",
      "Epoch 380/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.5000 - val_loss: 4.4084\n",
      "Epoch 381/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.4286 - val_loss: 4.4295\n",
      "Epoch 382/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.4286 - val_loss: 4.4535\n",
      "Epoch 383/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0540 - val_accuracy: 0.4286 - val_loss: 4.4686\n",
      "Epoch 384/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.4286 - val_loss: 4.4832\n",
      "Epoch 385/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0557 - val_accuracy: 0.4286 - val_loss: 4.4894\n",
      "Epoch 386/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.4286 - val_loss: 4.5106\n",
      "Epoch 387/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.4286 - val_loss: 4.5038\n",
      "Epoch 388/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.4286 - val_loss: 4.4684\n",
      "Epoch 389/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.4286 - val_loss: 4.4369\n",
      "Epoch 390/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0530 - val_accuracy: 0.5000 - val_loss: 4.4174\n",
      "Epoch 391/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0611 - val_accuracy: 0.5000 - val_loss: 4.4173\n",
      "Epoch 392/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.5000 - val_loss: 4.4764\n",
      "Epoch 393/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0561 - val_accuracy: 0.4286 - val_loss: 4.5389\n",
      "Epoch 394/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.4286 - val_loss: 4.5726\n",
      "Epoch 395/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.4286 - val_loss: 4.5819\n",
      "Epoch 396/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.4286 - val_loss: 4.5773\n",
      "Epoch 397/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.4286 - val_loss: 4.5552\n",
      "Epoch 398/500\n",
      "2/2 - 0s - 47ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.4286 - val_loss: 4.5329\n",
      "Epoch 399/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9259 - loss: 0.0559 - val_accuracy: 0.4286 - val_loss: 4.5346\n",
      "Epoch 400/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.4286 - val_loss: 4.5240\n",
      "Epoch 401/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.5000 - val_loss: 4.5083\n",
      "Epoch 402/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.5000 - val_loss: 4.5007\n",
      "Epoch 403/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0564 - val_accuracy: 0.5000 - val_loss: 4.5087\n",
      "Epoch 404/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0575 - val_accuracy: 0.4286 - val_loss: 4.5544\n",
      "Epoch 405/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9444 - loss: 0.0556 - val_accuracy: 0.4286 - val_loss: 4.5990\n",
      "Epoch 406/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.4286 - val_loss: 4.6070\n",
      "Epoch 407/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.4286 - val_loss: 4.5794\n",
      "Epoch 408/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.4286 - val_loss: 4.5735\n",
      "Epoch 409/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.4286 - val_loss: 4.5613\n",
      "Epoch 410/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.4286 - val_loss: 4.5564\n",
      "Epoch 411/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5000 - val_loss: 4.5524\n",
      "Epoch 412/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0538 - val_accuracy: 0.5000 - val_loss: 4.5459\n",
      "Epoch 413/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.5000 - val_loss: 4.5454\n",
      "Epoch 414/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.5000 - val_loss: 4.5388\n",
      "Epoch 415/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0542 - val_accuracy: 0.5000 - val_loss: 4.5382\n",
      "Epoch 416/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.5000 - val_loss: 4.5422\n",
      "Epoch 417/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.4286 - val_loss: 4.5705\n",
      "Epoch 418/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9815 - loss: 0.0535 - val_accuracy: 0.4286 - val_loss: 4.6029\n",
      "Epoch 419/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9259 - loss: 0.0554 - val_accuracy: 0.4286 - val_loss: 4.6137\n",
      "Epoch 420/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.4286 - val_loss: 4.6474\n",
      "Epoch 421/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.4286 - val_loss: 4.6360\n",
      "Epoch 422/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.4286 - val_loss: 4.6180\n",
      "Epoch 423/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.4286 - val_loss: 4.6114\n",
      "Epoch 424/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.4286 - val_loss: 4.5876\n",
      "Epoch 425/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.5000 - val_loss: 4.5703\n",
      "Epoch 426/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.5000 - val_loss: 4.5657\n",
      "Epoch 427/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.5000 - val_loss: 4.5543\n",
      "Epoch 428/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5000 - val_loss: 4.5580\n",
      "Epoch 429/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.4286 - val_loss: 4.5714\n",
      "Epoch 430/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.4286 - val_loss: 4.5658\n",
      "Epoch 431/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.4286 - val_loss: 4.5603\n",
      "Epoch 432/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.5000 - val_loss: 4.5481\n",
      "Epoch 433/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.5000 - val_loss: 4.5494\n",
      "Epoch 434/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0543 - val_accuracy: 0.4286 - val_loss: 4.5630\n",
      "Epoch 435/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.0584 - val_accuracy: 0.4286 - val_loss: 4.6082\n",
      "Epoch 436/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9444 - loss: 0.0540 - val_accuracy: 0.4286 - val_loss: 4.6018\n",
      "Epoch 437/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0531 - val_accuracy: 0.4286 - val_loss: 4.6103\n",
      "Epoch 438/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0532 - val_accuracy: 0.4286 - val_loss: 4.6111\n",
      "Epoch 439/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9259 - loss: 0.0562 - val_accuracy: 0.4286 - val_loss: 4.5994\n",
      "Epoch 440/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.4286 - val_loss: 4.6190\n",
      "Epoch 441/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.4286 - val_loss: 4.6142\n",
      "Epoch 442/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.4286 - val_loss: 4.6116\n",
      "Epoch 443/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0525 - val_accuracy: 0.4286 - val_loss: 4.5938\n",
      "Epoch 444/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.5000 - val_loss: 4.5789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.5000 - val_loss: 4.5744\n",
      "Epoch 446/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.5000 - val_loss: 4.5812\n",
      "Epoch 447/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.4286 - val_loss: 4.6145\n",
      "Epoch 448/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9444 - loss: 0.0558 - val_accuracy: 0.4286 - val_loss: 4.6795\n",
      "Epoch 449/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0538 - val_accuracy: 0.4286 - val_loss: 4.7072\n",
      "Epoch 450/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.4286 - val_loss: 4.7022\n",
      "Epoch 451/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0569 - val_accuracy: 0.4286 - val_loss: 4.6761\n",
      "Epoch 452/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.4286 - val_loss: 4.6042\n",
      "Epoch 453/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.4286 - val_loss: 4.5539\n",
      "Epoch 454/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0596 - val_accuracy: 0.5000 - val_loss: 4.5344\n",
      "Epoch 455/500\n",
      "2/2 - 0s - 48ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.4286 - val_loss: 4.5608\n",
      "Epoch 456/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0534 - val_accuracy: 0.4286 - val_loss: 4.6018\n",
      "Epoch 457/500\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.9630 - loss: 0.0530 - val_accuracy: 0.4286 - val_loss: 4.6426\n",
      "Epoch 458/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0539 - val_accuracy: 0.4286 - val_loss: 4.6612\n",
      "Epoch 459/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.4286 - val_loss: 4.6533\n",
      "Epoch 460/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0543 - val_accuracy: 0.4286 - val_loss: 4.6298\n",
      "Epoch 461/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0584 - val_accuracy: 0.4286 - val_loss: 4.5807\n",
      "Epoch 462/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.4286 - val_loss: 4.5762\n",
      "Epoch 463/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0532 - val_accuracy: 0.4286 - val_loss: 4.5680\n",
      "Epoch 464/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.4286 - val_loss: 4.5748\n",
      "Epoch 465/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.4286 - val_loss: 4.5815\n",
      "Epoch 466/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.4286 - val_loss: 4.6091\n",
      "Epoch 467/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0530 - val_accuracy: 0.4286 - val_loss: 4.6190\n",
      "Epoch 468/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9444 - loss: 0.0560 - val_accuracy: 0.4286 - val_loss: 4.6273\n",
      "Epoch 469/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0529 - val_accuracy: 0.4286 - val_loss: 4.6051\n",
      "Epoch 470/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0526 - val_accuracy: 0.4286 - val_loss: 4.5792\n",
      "Epoch 471/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.5000 - val_loss: 4.5608\n",
      "Epoch 472/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.5000 - val_loss: 4.5689\n",
      "Epoch 473/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.5000 - val_loss: 4.5946\n",
      "Epoch 474/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.4286 - val_loss: 4.6270\n",
      "Epoch 475/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0533 - val_accuracy: 0.4286 - val_loss: 4.6751\n",
      "Epoch 476/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0529 - val_accuracy: 0.4286 - val_loss: 4.7101\n",
      "Epoch 477/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.4286 - val_loss: 4.7254\n",
      "Epoch 478/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.4286 - val_loss: 4.7090\n",
      "Epoch 479/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0565 - val_accuracy: 0.4286 - val_loss: 4.6965\n",
      "Epoch 480/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0586 - val_accuracy: 0.4286 - val_loss: 4.6432\n",
      "Epoch 481/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0532 - val_accuracy: 0.4286 - val_loss: 4.6299\n",
      "Epoch 482/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0531 - val_accuracy: 0.4286 - val_loss: 4.6154\n",
      "Epoch 483/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.5000 - val_loss: 4.6026\n",
      "Epoch 484/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.4286 - val_loss: 4.6179\n",
      "Epoch 485/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0540 - val_accuracy: 0.4286 - val_loss: 4.6413\n",
      "Epoch 486/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0535 - val_accuracy: 0.4286 - val_loss: 4.6510\n",
      "Epoch 487/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0528 - val_accuracy: 0.4286 - val_loss: 4.6741\n",
      "Epoch 488/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0541 - val_accuracy: 0.4286 - val_loss: 4.6916\n",
      "Epoch 489/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9444 - loss: 0.0559 - val_accuracy: 0.4286 - val_loss: 4.6801\n",
      "Epoch 490/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0540 - val_accuracy: 0.4286 - val_loss: 4.6903\n",
      "Epoch 491/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0536 - val_accuracy: 0.4286 - val_loss: 4.6823\n",
      "Epoch 492/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0545 - val_accuracy: 0.4286 - val_loss: 4.6561\n",
      "Epoch 493/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.4286 - val_loss: 4.6437\n",
      "Epoch 494/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0530 - val_accuracy: 0.4286 - val_loss: 4.6549\n",
      "Epoch 495/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0528 - val_accuracy: 0.4286 - val_loss: 4.6800\n",
      "Epoch 496/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.4286 - val_loss: 4.6972\n",
      "Epoch 497/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0537 - val_accuracy: 0.4286 - val_loss: 4.6866\n",
      "Epoch 498/500\n",
      "2/2 - 0s - 47ms/step - accuracy: 0.9630 - loss: 0.0531 - val_accuracy: 0.4286 - val_loss: 4.6732\n",
      "Epoch 499/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0543 - val_accuracy: 0.4286 - val_loss: 4.6526\n",
      "Epoch 500/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0531 - val_accuracy: 0.4286 - val_loss: 4.6520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as BRNN_chat_model.h5\n",
      "Training model: Encoder-Decoder\n",
      "Training model: Encoder-Decoder\n",
      "Epoch 1/500\n",
      "2/2 - 3s - 2s/step - accuracy: 0.1296 - loss: 2.7043 - val_accuracy: 0.0714 - val_loss: 2.7033\n",
      "Epoch 2/500\n",
      "2/2 - 0s - 52ms/step - accuracy: 0.2037 - loss: 2.6909 - val_accuracy: 0.0714 - val_loss: 2.6942\n",
      "Epoch 3/500\n",
      "2/2 - 0s - 48ms/step - accuracy: 0.2037 - loss: 2.6741 - val_accuracy: 0.0714 - val_loss: 2.6836\n",
      "Epoch 4/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.2037 - loss: 2.6537 - val_accuracy: 0.0714 - val_loss: 2.6714\n",
      "Epoch 5/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.2037 - loss: 2.6235 - val_accuracy: 0.0714 - val_loss: 2.6558\n",
      "Epoch 6/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.2037 - loss: 2.5810 - val_accuracy: 0.0714 - val_loss: 2.6421\n",
      "Epoch 7/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.2037 - loss: 2.5300 - val_accuracy: 0.0714 - val_loss: 2.6441\n",
      "Epoch 8/500\n",
      "2/2 - 0s - 54ms/step - accuracy: 0.2037 - loss: 2.5176 - val_accuracy: 0.0714 - val_loss: 2.6799\n",
      "Epoch 9/500\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.2037 - loss: 2.5215 - val_accuracy: 0.0714 - val_loss: 2.6836\n",
      "Epoch 10/500\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.2037 - loss: 2.5170 - val_accuracy: 0.0714 - val_loss: 2.6396\n",
      "Epoch 11/500\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.2037 - loss: 2.4996 - val_accuracy: 0.0714 - val_loss: 2.5987\n",
      "Epoch 12/500\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.2037 - loss: 2.4889 - val_accuracy: 0.0714 - val_loss: 2.5735\n",
      "Epoch 13/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.2037 - loss: 2.4903 - val_accuracy: 0.0714 - val_loss: 2.5675\n",
      "Epoch 14/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.2222 - loss: 2.4821 - val_accuracy: 0.0714 - val_loss: 2.5694\n",
      "Epoch 15/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.2222 - loss: 2.4733 - val_accuracy: 0.0714 - val_loss: 2.5740\n",
      "Epoch 16/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.2222 - loss: 2.4584 - val_accuracy: 0.0714 - val_loss: 2.5763\n",
      "Epoch 17/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.2222 - loss: 2.4492 - val_accuracy: 0.0714 - val_loss: 2.5850\n",
      "Epoch 18/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.2222 - loss: 2.4231 - val_accuracy: 0.0714 - val_loss: 2.5860\n",
      "Epoch 19/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.2222 - loss: 2.3983 - val_accuracy: 0.0714 - val_loss: 2.5781\n",
      "Epoch 20/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.2407 - loss: 2.3524 - val_accuracy: 0.0714 - val_loss: 2.5555\n",
      "Epoch 21/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.2407 - loss: 2.2928 - val_accuracy: 0.0714 - val_loss: 2.5348\n",
      "Epoch 22/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.2407 - loss: 2.2209 - val_accuracy: 0.0714 - val_loss: 2.5175\n",
      "Epoch 23/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.2593 - loss: 2.1359 - val_accuracy: 0.1429 - val_loss: 2.5273\n",
      "Epoch 24/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.3519 - loss: 2.0647 - val_accuracy: 0.2143 - val_loss: 2.5496\n",
      "Epoch 25/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.3519 - loss: 2.0070 - val_accuracy: 0.2143 - val_loss: 2.5505\n",
      "Epoch 26/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.3519 - loss: 1.9293 - val_accuracy: 0.2143 - val_loss: 2.5182\n",
      "Epoch 27/500\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.3889 - loss: 1.8296 - val_accuracy: 0.2143 - val_loss: 2.4532\n",
      "Epoch 28/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.3889 - loss: 1.7728 - val_accuracy: 0.2143 - val_loss: 2.4080\n",
      "Epoch 29/500\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.4074 - loss: 1.7288 - val_accuracy: 0.2143 - val_loss: 2.3878\n",
      "Epoch 30/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.3889 - loss: 1.6843 - val_accuracy: 0.2857 - val_loss: 2.3967\n",
      "Epoch 31/500\n",
      "2/2 - 0s - 47ms/step - accuracy: 0.4259 - loss: 1.6566 - val_accuracy: 0.2857 - val_loss: 2.4110\n",
      "Epoch 32/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.3704 - loss: 1.6255 - val_accuracy: 0.2857 - val_loss: 2.3372\n",
      "Epoch 33/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.3704 - loss: 1.5901 - val_accuracy: 0.2143 - val_loss: 2.3081\n",
      "Epoch 34/500\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.3704 - loss: 1.5544 - val_accuracy: 0.2143 - val_loss: 2.3418\n",
      "Epoch 35/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.3889 - loss: 1.5247 - val_accuracy: 0.2143 - val_loss: 2.3246\n",
      "Epoch 36/500\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.4630 - loss: 1.4903 - val_accuracy: 0.2143 - val_loss: 2.3039\n",
      "Epoch 37/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.4259 - loss: 1.4584 - val_accuracy: 0.2143 - val_loss: 2.3572\n",
      "Epoch 38/500\n",
      "2/2 - 0s - 54ms/step - accuracy: 0.4444 - loss: 1.4120 - val_accuracy: 0.1429 - val_loss: 2.4041\n",
      "Epoch 39/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.4815 - loss: 1.3659 - val_accuracy: 0.2143 - val_loss: 2.4308\n",
      "Epoch 40/500\n",
      "2/2 - 0s - 47ms/step - accuracy: 0.4444 - loss: 1.3281 - val_accuracy: 0.1429 - val_loss: 2.4727\n",
      "Epoch 41/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.5185 - loss: 1.2840 - val_accuracy: 0.0714 - val_loss: 2.4843\n",
      "Epoch 42/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.4815 - loss: 1.3002 - val_accuracy: 0.2143 - val_loss: 2.4773\n",
      "Epoch 43/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.5000 - loss: 1.2816 - val_accuracy: 0.0714 - val_loss: 2.4775\n",
      "Epoch 44/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.5185 - loss: 1.2041 - val_accuracy: 0.1429 - val_loss: 2.5219\n",
      "Epoch 45/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.5185 - loss: 1.2140 - val_accuracy: 0.1429 - val_loss: 2.5305\n",
      "Epoch 46/500\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.5741 - loss: 1.1904 - val_accuracy: 0.1429 - val_loss: 2.6424\n",
      "Epoch 47/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.5741 - loss: 1.1854 - val_accuracy: 0.1429 - val_loss: 2.6374\n",
      "Epoch 48/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.5370 - loss: 1.1272 - val_accuracy: 0.1429 - val_loss: 2.8145\n",
      "Epoch 49/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.5556 - loss: 1.0958 - val_accuracy: 0.0714 - val_loss: 2.8507\n",
      "Epoch 50/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.6296 - loss: 1.0364 - val_accuracy: 0.0714 - val_loss: 2.8156\n",
      "Epoch 51/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.6296 - loss: 1.0490 - val_accuracy: 0.0714 - val_loss: 2.8370\n",
      "Epoch 52/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.6852 - loss: 1.0109 - val_accuracy: 0.0714 - val_loss: 2.7269\n",
      "Epoch 53/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.6852 - loss: 1.0106 - val_accuracy: 0.0714 - val_loss: 2.7497\n",
      "Epoch 54/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.7222 - loss: 0.9859 - val_accuracy: 0.0714 - val_loss: 2.8691\n",
      "Epoch 55/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.7407 - loss: 0.9597 - val_accuracy: 0.0714 - val_loss: 2.9018\n",
      "Epoch 56/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.7407 - loss: 0.9209 - val_accuracy: 0.0714 - val_loss: 2.9325\n",
      "Epoch 57/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.6852 - loss: 0.8812 - val_accuracy: 0.0714 - val_loss: 3.0189\n",
      "Epoch 58/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.7593 - loss: 0.8474 - val_accuracy: 0.0714 - val_loss: 3.1070\n",
      "Epoch 59/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.7963 - loss: 0.8150 - val_accuracy: 0.0714 - val_loss: 2.9955\n",
      "Epoch 60/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.7963 - loss: 0.7806 - val_accuracy: 0.0714 - val_loss: 2.9981\n",
      "Epoch 61/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.7963 - loss: 0.7469 - val_accuracy: 0.0714 - val_loss: 3.0256\n",
      "Epoch 62/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.8333 - loss: 0.7095 - val_accuracy: 0.0714 - val_loss: 3.0431\n",
      "Epoch 63/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.8519 - loss: 0.6831 - val_accuracy: 0.0714 - val_loss: 3.1009\n",
      "Epoch 64/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.8333 - loss: 0.6470 - val_accuracy: 0.1429 - val_loss: 3.1291\n",
      "Epoch 65/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.8333 - loss: 0.6370 - val_accuracy: 0.1429 - val_loss: 3.0478\n",
      "Epoch 66/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.8519 - loss: 0.6076 - val_accuracy: 0.0714 - val_loss: 2.9668\n",
      "Epoch 67/500\n",
      "2/2 - 0s - 48ms/step - accuracy: 0.8519 - loss: 0.5817 - val_accuracy: 0.1429 - val_loss: 3.0523\n",
      "Epoch 68/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.8333 - loss: 0.5486 - val_accuracy: 0.1429 - val_loss: 3.2576\n",
      "Epoch 69/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.8519 - loss: 0.5367 - val_accuracy: 0.1429 - val_loss: 3.0994\n",
      "Epoch 70/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8889 - loss: 0.5054 - val_accuracy: 0.1429 - val_loss: 3.0541\n",
      "Epoch 71/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.8889 - loss: 0.4851 - val_accuracy: 0.1429 - val_loss: 3.2656\n",
      "Epoch 72/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.8889 - loss: 0.4726 - val_accuracy: 0.1429 - val_loss: 3.2371\n",
      "Epoch 73/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.8889 - loss: 0.4472 - val_accuracy: 0.1429 - val_loss: 3.1754\n",
      "Epoch 74/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9074 - loss: 0.4340 - val_accuracy: 0.1429 - val_loss: 3.2463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9444 - loss: 0.4232 - val_accuracy: 0.1429 - val_loss: 3.1329\n",
      "Epoch 76/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.4274 - val_accuracy: 0.1429 - val_loss: 3.4144\n",
      "Epoch 77/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9259 - loss: 0.4317 - val_accuracy: 0.1429 - val_loss: 3.2391\n",
      "Epoch 78/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.8889 - loss: 0.4940 - val_accuracy: 0.1429 - val_loss: 2.9378\n",
      "Epoch 79/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9074 - loss: 0.4243 - val_accuracy: 0.1429 - val_loss: 3.6118\n",
      "Epoch 80/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.7407 - loss: 0.6500 - val_accuracy: 0.1429 - val_loss: 3.2022\n",
      "Epoch 81/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.8519 - loss: 0.5225 - val_accuracy: 0.0714 - val_loss: 3.0929\n",
      "Epoch 82/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.7407 - loss: 0.5469 - val_accuracy: 0.1429 - val_loss: 3.3385\n",
      "Epoch 83/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.7593 - loss: 0.4811 - val_accuracy: 0.1429 - val_loss: 3.3966\n",
      "Epoch 84/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.8519 - loss: 0.3861 - val_accuracy: 0.1429 - val_loss: 3.3225\n",
      "Epoch 85/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.7778 - loss: 0.4730 - val_accuracy: 0.1429 - val_loss: 3.2493\n",
      "Epoch 86/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.3318 - val_accuracy: 0.1429 - val_loss: 3.3957\n",
      "Epoch 87/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.8704 - loss: 0.3842 - val_accuracy: 0.1429 - val_loss: 3.3346\n",
      "Epoch 88/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9259 - loss: 0.3497 - val_accuracy: 0.1429 - val_loss: 3.2952\n",
      "Epoch 89/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9074 - loss: 0.3768 - val_accuracy: 0.1429 - val_loss: 3.3328\n",
      "Epoch 90/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9074 - loss: 0.3061 - val_accuracy: 0.1429 - val_loss: 3.4335\n",
      "Epoch 91/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9259 - loss: 0.3099 - val_accuracy: 0.1429 - val_loss: 3.2930\n",
      "Epoch 92/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.2941 - val_accuracy: 0.2143 - val_loss: 3.2755\n",
      "Epoch 93/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9259 - loss: 0.2822 - val_accuracy: 0.2143 - val_loss: 3.4204\n",
      "Epoch 94/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9074 - loss: 0.2708 - val_accuracy: 0.1429 - val_loss: 3.5799\n",
      "Epoch 95/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.2560 - val_accuracy: 0.1429 - val_loss: 3.5892\n",
      "Epoch 96/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.2409 - val_accuracy: 0.1429 - val_loss: 3.4940\n",
      "Epoch 97/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.2342 - val_accuracy: 0.1429 - val_loss: 3.5238\n",
      "Epoch 98/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.2235 - val_accuracy: 0.1429 - val_loss: 3.5767\n",
      "Epoch 99/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.2161 - val_accuracy: 0.1429 - val_loss: 3.6495\n",
      "Epoch 100/500\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.9630 - loss: 0.2094 - val_accuracy: 0.1429 - val_loss: 3.7093\n",
      "Epoch 101/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.2058 - val_accuracy: 0.2143 - val_loss: 3.7278\n",
      "Epoch 102/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.2017 - val_accuracy: 0.2143 - val_loss: 3.7001\n",
      "Epoch 103/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.1951 - val_accuracy: 0.2143 - val_loss: 3.6723\n",
      "Epoch 104/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.1888 - val_accuracy: 0.2143 - val_loss: 3.6762\n",
      "Epoch 105/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.1842 - val_accuracy: 0.2143 - val_loss: 3.7018\n",
      "Epoch 106/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.1801 - val_accuracy: 0.2143 - val_loss: 3.7437\n",
      "Epoch 107/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.1762 - val_accuracy: 0.2143 - val_loss: 3.7935\n",
      "Epoch 108/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.1722 - val_accuracy: 0.2143 - val_loss: 3.8439\n",
      "Epoch 109/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.1686 - val_accuracy: 0.2143 - val_loss: 3.8958\n",
      "Epoch 110/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.1654 - val_accuracy: 0.2143 - val_loss: 3.9379\n",
      "Epoch 111/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.1615 - val_accuracy: 0.2143 - val_loss: 3.9726\n",
      "Epoch 112/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.1590 - val_accuracy: 0.2143 - val_loss: 3.9978\n",
      "Epoch 113/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.1557 - val_accuracy: 0.2143 - val_loss: 4.0102\n",
      "Epoch 114/500\n",
      "2/2 - 0s - 48ms/step - accuracy: 0.9630 - loss: 0.1525 - val_accuracy: 0.2143 - val_loss: 4.0062\n",
      "Epoch 115/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.1500 - val_accuracy: 0.2143 - val_loss: 3.9839\n",
      "Epoch 116/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.1468 - val_accuracy: 0.2143 - val_loss: 3.9708\n",
      "Epoch 117/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.1437 - val_accuracy: 0.2143 - val_loss: 3.9744\n",
      "Epoch 118/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.1419 - val_accuracy: 0.2143 - val_loss: 3.9802\n",
      "Epoch 119/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.1391 - val_accuracy: 0.2143 - val_loss: 3.9959\n",
      "Epoch 120/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.1374 - val_accuracy: 0.2143 - val_loss: 4.0164\n",
      "Epoch 121/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.1348 - val_accuracy: 0.2143 - val_loss: 4.0295\n",
      "Epoch 122/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.1336 - val_accuracy: 0.2143 - val_loss: 4.0459\n",
      "Epoch 123/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.1303 - val_accuracy: 0.2143 - val_loss: 4.0584\n",
      "Epoch 124/500\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.9630 - loss: 0.1281 - val_accuracy: 0.2143 - val_loss: 4.0668\n",
      "Epoch 125/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.1262 - val_accuracy: 0.2143 - val_loss: 4.0767\n",
      "Epoch 126/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.1249 - val_accuracy: 0.2143 - val_loss: 4.0873\n",
      "Epoch 127/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.1238 - val_accuracy: 0.2143 - val_loss: 4.1067\n",
      "Epoch 128/500\n",
      "2/2 - 0s - 47ms/step - accuracy: 0.9630 - loss: 0.1228 - val_accuracy: 0.2143 - val_loss: 4.1197\n",
      "Epoch 129/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.1212 - val_accuracy: 0.2143 - val_loss: 4.1415\n",
      "Epoch 130/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.1200 - val_accuracy: 0.2143 - val_loss: 4.1650\n",
      "Epoch 131/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.1173 - val_accuracy: 0.2143 - val_loss: 4.1965\n",
      "Epoch 132/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.9630 - loss: 0.1154 - val_accuracy: 0.2143 - val_loss: 4.2176\n",
      "Epoch 133/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.1175 - val_accuracy: 0.2143 - val_loss: 4.2426\n",
      "Epoch 134/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.1140 - val_accuracy: 0.2143 - val_loss: 4.2434\n",
      "Epoch 135/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.1124 - val_accuracy: 0.2143 - val_loss: 4.2353\n",
      "Epoch 136/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.1112 - val_accuracy: 0.2143 - val_loss: 4.2273\n",
      "Epoch 137/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.1101 - val_accuracy: 0.2143 - val_loss: 4.2222\n",
      "Epoch 138/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.1094 - val_accuracy: 0.2143 - val_loss: 4.2202\n",
      "Epoch 139/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.1073 - val_accuracy: 0.2143 - val_loss: 4.2309\n",
      "Epoch 140/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.1063 - val_accuracy: 0.2143 - val_loss: 4.2383\n",
      "Epoch 141/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.1050 - val_accuracy: 0.2143 - val_loss: 4.2384\n",
      "Epoch 142/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.1039 - val_accuracy: 0.2143 - val_loss: 4.2400\n",
      "Epoch 143/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9444 - loss: 0.1072 - val_accuracy: 0.2143 - val_loss: 4.2385\n",
      "Epoch 144/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.1019 - val_accuracy: 0.2143 - val_loss: 4.2788\n",
      "Epoch 145/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.1005 - val_accuracy: 0.2143 - val_loss: 4.3192\n",
      "Epoch 146/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.1005 - val_accuracy: 0.2143 - val_loss: 4.3482\n",
      "Epoch 147/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0995 - val_accuracy: 0.2143 - val_loss: 4.3755\n",
      "Epoch 148/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0995 - val_accuracy: 0.2143 - val_loss: 4.3795\n",
      "Epoch 149/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0990 - val_accuracy: 0.2143 - val_loss: 4.3630\n",
      "Epoch 150/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0986 - val_accuracy: 0.2143 - val_loss: 4.3429\n",
      "Epoch 151/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0963 - val_accuracy: 0.2143 - val_loss: 4.3342\n",
      "Epoch 152/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0945 - val_accuracy: 0.2143 - val_loss: 4.3389\n",
      "Epoch 153/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0947 - val_accuracy: 0.2143 - val_loss: 4.3384\n",
      "Epoch 154/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0924 - val_accuracy: 0.2143 - val_loss: 4.3296\n",
      "Epoch 155/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0928 - val_accuracy: 0.2143 - val_loss: 4.3383\n",
      "Epoch 156/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0910 - val_accuracy: 0.2143 - val_loss: 4.3532\n",
      "Epoch 157/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.9630 - loss: 0.0902 - val_accuracy: 0.2143 - val_loss: 4.4006\n",
      "Epoch 158/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9444 - loss: 0.0923 - val_accuracy: 0.2143 - val_loss: 4.4727\n",
      "Epoch 159/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.9630 - loss: 0.0888 - val_accuracy: 0.2143 - val_loss: 4.5878\n",
      "Epoch 160/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0919 - val_accuracy: 0.2143 - val_loss: 4.6037\n",
      "Epoch 161/500\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.9630 - loss: 0.0891 - val_accuracy: 0.2143 - val_loss: 4.5423\n",
      "Epoch 162/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0860 - val_accuracy: 0.2143 - val_loss: 4.4364\n",
      "Epoch 163/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0897 - val_accuracy: 0.2143 - val_loss: 4.3891\n",
      "Epoch 164/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0912 - val_accuracy: 0.2143 - val_loss: 4.3857\n",
      "Epoch 165/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0885 - val_accuracy: 0.2143 - val_loss: 4.4073\n",
      "Epoch 166/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0876 - val_accuracy: 0.2143 - val_loss: 4.4555\n",
      "Epoch 167/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0857 - val_accuracy: 0.2143 - val_loss: 4.4574\n",
      "Epoch 168/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.9630 - loss: 0.0839 - val_accuracy: 0.2143 - val_loss: 4.4672\n",
      "Epoch 169/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0836 - val_accuracy: 0.2143 - val_loss: 4.4759\n",
      "Epoch 170/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0835 - val_accuracy: 0.2143 - val_loss: 4.4757\n",
      "Epoch 171/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0814 - val_accuracy: 0.2143 - val_loss: 4.4804\n",
      "Epoch 172/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.9630 - loss: 0.0818 - val_accuracy: 0.2143 - val_loss: 4.4836\n",
      "Epoch 173/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0826 - val_accuracy: 0.2143 - val_loss: 4.5206\n",
      "Epoch 174/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0799 - val_accuracy: 0.2143 - val_loss: 4.5110\n",
      "Epoch 175/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0792 - val_accuracy: 0.2143 - val_loss: 4.5153\n",
      "Epoch 176/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0803 - val_accuracy: 0.2143 - val_loss: 4.5180\n",
      "Epoch 177/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9444 - loss: 0.0815 - val_accuracy: 0.2143 - val_loss: 4.5710\n",
      "Epoch 178/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0795 - val_accuracy: 0.2143 - val_loss: 4.5702\n",
      "Epoch 179/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0774 - val_accuracy: 0.2143 - val_loss: 4.6061\n",
      "Epoch 180/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0809 - val_accuracy: 0.2143 - val_loss: 4.6567\n",
      "Epoch 181/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0796 - val_accuracy: 0.2143 - val_loss: 4.6145\n",
      "Epoch 182/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0764 - val_accuracy: 0.2143 - val_loss: 4.6144\n",
      "Epoch 183/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0761 - val_accuracy: 0.2143 - val_loss: 4.6130\n",
      "Epoch 184/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0797 - val_accuracy: 0.2143 - val_loss: 4.6021\n",
      "Epoch 185/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0774 - val_accuracy: 0.2143 - val_loss: 4.6308\n",
      "Epoch 186/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0792 - val_accuracy: 0.2143 - val_loss: 4.6490\n",
      "Epoch 187/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0749 - val_accuracy: 0.2143 - val_loss: 4.6245\n",
      "Epoch 188/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0742 - val_accuracy: 0.2143 - val_loss: 4.6084\n",
      "Epoch 189/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0743 - val_accuracy: 0.2143 - val_loss: 4.6093\n",
      "Epoch 190/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0759 - val_accuracy: 0.2143 - val_loss: 4.6097\n",
      "Epoch 191/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0760 - val_accuracy: 0.2143 - val_loss: 4.5939\n",
      "Epoch 192/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0751 - val_accuracy: 0.2143 - val_loss: 4.6381\n",
      "Epoch 193/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0749 - val_accuracy: 0.2143 - val_loss: 4.7311\n",
      "Epoch 194/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9259 - loss: 0.0771 - val_accuracy: 0.2143 - val_loss: 4.7923\n",
      "Epoch 195/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9444 - loss: 0.0738 - val_accuracy: 0.2143 - val_loss: 4.7226\n",
      "Epoch 196/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0747 - val_accuracy: 0.2143 - val_loss: 4.7269\n",
      "Epoch 197/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0719 - val_accuracy: 0.2143 - val_loss: 4.6938\n",
      "Epoch 198/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0722 - val_accuracy: 0.2143 - val_loss: 4.6802\n",
      "Epoch 199/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0720 - val_accuracy: 0.2143 - val_loss: 4.6779\n",
      "Epoch 200/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0723 - val_accuracy: 0.2143 - val_loss: 4.6871\n",
      "Epoch 201/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0710 - val_accuracy: 0.2143 - val_loss: 4.6922\n",
      "Epoch 202/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9444 - loss: 0.0737 - val_accuracy: 0.2143 - val_loss: 4.7056\n",
      "Epoch 203/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0713 - val_accuracy: 0.2143 - val_loss: 4.7046\n",
      "Epoch 204/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0705 - val_accuracy: 0.2143 - val_loss: 4.7112\n",
      "Epoch 205/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0696 - val_accuracy: 0.2143 - val_loss: 4.7247\n",
      "Epoch 206/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9444 - loss: 0.0740 - val_accuracy: 0.2143 - val_loss: 4.7513\n",
      "Epoch 207/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0693 - val_accuracy: 0.2143 - val_loss: 4.7530\n",
      "Epoch 208/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0691 - val_accuracy: 0.2143 - val_loss: 4.7576\n",
      "Epoch 209/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0689 - val_accuracy: 0.2143 - val_loss: 4.7657\n",
      "Epoch 210/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9444 - loss: 0.0694 - val_accuracy: 0.2143 - val_loss: 4.7738\n",
      "Epoch 211/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0687 - val_accuracy: 0.2143 - val_loss: 4.7787\n",
      "Epoch 212/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0686 - val_accuracy: 0.2143 - val_loss: 4.7837\n",
      "Epoch 213/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0683 - val_accuracy: 0.2143 - val_loss: 4.7888\n",
      "Epoch 214/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0681 - val_accuracy: 0.2143 - val_loss: 4.7939\n",
      "Epoch 215/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0676 - val_accuracy: 0.2143 - val_loss: 4.8108\n",
      "Epoch 216/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0687 - val_accuracy: 0.2143 - val_loss: 4.8343\n",
      "Epoch 217/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0681 - val_accuracy: 0.2143 - val_loss: 4.8305\n",
      "Epoch 218/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0674 - val_accuracy: 0.2143 - val_loss: 4.8176\n",
      "Epoch 219/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0668 - val_accuracy: 0.2143 - val_loss: 4.8194\n",
      "Epoch 220/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0664 - val_accuracy: 0.2143 - val_loss: 4.8233\n",
      "Epoch 221/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0674 - val_accuracy: 0.2143 - val_loss: 4.8267\n",
      "Epoch 222/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0684 - val_accuracy: 0.2143 - val_loss: 4.8257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0683 - val_accuracy: 0.2143 - val_loss: 4.8327\n",
      "Epoch 224/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0677 - val_accuracy: 0.2143 - val_loss: 4.8390\n",
      "Epoch 225/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.9630 - loss: 0.0658 - val_accuracy: 0.2143 - val_loss: 4.8781\n",
      "Epoch 226/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0658 - val_accuracy: 0.2143 - val_loss: 4.9811\n",
      "Epoch 227/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0671 - val_accuracy: 0.2143 - val_loss: 5.0400\n",
      "Epoch 228/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0671 - val_accuracy: 0.2143 - val_loss: 5.0293\n",
      "Epoch 229/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0667 - val_accuracy: 0.2143 - val_loss: 4.9663\n",
      "Epoch 230/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0661 - val_accuracy: 0.2143 - val_loss: 4.9018\n",
      "Epoch 231/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0654 - val_accuracy: 0.2143 - val_loss: 4.8891\n",
      "Epoch 232/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0651 - val_accuracy: 0.2143 - val_loss: 4.8954\n",
      "Epoch 233/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0659 - val_accuracy: 0.2143 - val_loss: 4.9011\n",
      "Epoch 234/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0655 - val_accuracy: 0.2143 - val_loss: 4.9013\n",
      "Epoch 235/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0658 - val_accuracy: 0.2143 - val_loss: 4.9009\n",
      "Epoch 236/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0653 - val_accuracy: 0.2143 - val_loss: 4.8975\n",
      "Epoch 237/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0644 - val_accuracy: 0.2143 - val_loss: 4.8936\n",
      "Epoch 238/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0641 - val_accuracy: 0.2143 - val_loss: 4.8885\n",
      "Epoch 239/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0645 - val_accuracy: 0.2143 - val_loss: 4.8890\n",
      "Epoch 240/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0641 - val_accuracy: 0.2143 - val_loss: 4.8929\n",
      "Epoch 241/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0639 - val_accuracy: 0.2143 - val_loss: 4.8944\n",
      "Epoch 242/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0636 - val_accuracy: 0.2143 - val_loss: 4.8933\n",
      "Epoch 243/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9444 - loss: 0.0639 - val_accuracy: 0.2143 - val_loss: 4.8979\n",
      "Epoch 244/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0637 - val_accuracy: 0.2143 - val_loss: 4.9052\n",
      "Epoch 245/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0635 - val_accuracy: 0.2143 - val_loss: 4.9083\n",
      "Epoch 246/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0630 - val_accuracy: 0.2143 - val_loss: 4.9126\n",
      "Epoch 247/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.9630 - loss: 0.0632 - val_accuracy: 0.2143 - val_loss: 4.9172\n",
      "Epoch 248/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0634 - val_accuracy: 0.2143 - val_loss: 4.9185\n",
      "Epoch 249/500\n",
      "2/2 - 0s - 48ms/step - accuracy: 0.9630 - loss: 0.0627 - val_accuracy: 0.2143 - val_loss: 4.9162\n",
      "Epoch 250/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0626 - val_accuracy: 0.2143 - val_loss: 4.9185\n",
      "Epoch 251/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0631 - val_accuracy: 0.2143 - val_loss: 4.9222\n",
      "Epoch 252/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0628 - val_accuracy: 0.2143 - val_loss: 4.9247\n",
      "Epoch 253/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0626 - val_accuracy: 0.2143 - val_loss: 4.9288\n",
      "Epoch 254/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0625 - val_accuracy: 0.2143 - val_loss: 4.9315\n",
      "Epoch 255/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0622 - val_accuracy: 0.2143 - val_loss: 4.9373\n",
      "Epoch 256/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0621 - val_accuracy: 0.2143 - val_loss: 4.9436\n",
      "Epoch 257/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0619 - val_accuracy: 0.2143 - val_loss: 4.9518\n",
      "Epoch 258/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0618 - val_accuracy: 0.2143 - val_loss: 4.9606\n",
      "Epoch 259/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0618 - val_accuracy: 0.2143 - val_loss: 4.9651\n",
      "Epoch 260/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0617 - val_accuracy: 0.2143 - val_loss: 4.9679\n",
      "Epoch 261/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0617 - val_accuracy: 0.2143 - val_loss: 4.9674\n",
      "Epoch 262/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0618 - val_accuracy: 0.2143 - val_loss: 4.9680\n",
      "Epoch 263/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0616 - val_accuracy: 0.2143 - val_loss: 4.9644\n",
      "Epoch 264/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0616 - val_accuracy: 0.2143 - val_loss: 4.9614\n",
      "Epoch 265/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0610 - val_accuracy: 0.2143 - val_loss: 4.9628\n",
      "Epoch 266/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0612 - val_accuracy: 0.2143 - val_loss: 4.9710\n",
      "Epoch 267/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0611 - val_accuracy: 0.2143 - val_loss: 4.9751\n",
      "Epoch 268/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0612 - val_accuracy: 0.2143 - val_loss: 4.9749\n",
      "Epoch 269/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0618 - val_accuracy: 0.2143 - val_loss: 4.9706\n",
      "Epoch 270/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0618 - val_accuracy: 0.2143 - val_loss: 4.9647\n",
      "Epoch 271/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0613 - val_accuracy: 0.2143 - val_loss: 4.9739\n",
      "Epoch 272/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0611 - val_accuracy: 0.2143 - val_loss: 4.9870\n",
      "Epoch 273/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0607 - val_accuracy: 0.2143 - val_loss: 5.0013\n",
      "Epoch 274/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0611 - val_accuracy: 0.2143 - val_loss: 5.0164\n",
      "Epoch 275/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0605 - val_accuracy: 0.2143 - val_loss: 5.0261\n",
      "Epoch 276/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0608 - val_accuracy: 0.2143 - val_loss: 5.0343\n",
      "Epoch 277/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0606 - val_accuracy: 0.2143 - val_loss: 5.0388\n",
      "Epoch 278/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0606 - val_accuracy: 0.2143 - val_loss: 5.0360\n",
      "Epoch 279/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0608 - val_accuracy: 0.2143 - val_loss: 5.0340\n",
      "Epoch 280/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0602 - val_accuracy: 0.2143 - val_loss: 5.0267\n",
      "Epoch 281/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0605 - val_accuracy: 0.2143 - val_loss: 5.0186\n",
      "Epoch 282/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0603 - val_accuracy: 0.2143 - val_loss: 5.0159\n",
      "Epoch 283/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0600 - val_accuracy: 0.2143 - val_loss: 5.0163\n",
      "Epoch 284/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0601 - val_accuracy: 0.2143 - val_loss: 5.0168\n",
      "Epoch 285/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0601 - val_accuracy: 0.2143 - val_loss: 5.0221\n",
      "Epoch 286/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0599 - val_accuracy: 0.2143 - val_loss: 5.0273\n",
      "Epoch 287/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0598 - val_accuracy: 0.2143 - val_loss: 5.0344\n",
      "Epoch 288/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0596 - val_accuracy: 0.2143 - val_loss: 5.0441\n",
      "Epoch 289/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.9630 - loss: 0.0596 - val_accuracy: 0.2143 - val_loss: 5.0500\n",
      "Epoch 290/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0595 - val_accuracy: 0.2143 - val_loss: 5.0571\n",
      "Epoch 291/500\n",
      "2/2 - 0s - 56ms/step - accuracy: 0.9630 - loss: 0.0598 - val_accuracy: 0.2143 - val_loss: 5.0629\n",
      "Epoch 292/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0596 - val_accuracy: 0.2143 - val_loss: 5.0614\n",
      "Epoch 293/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0595 - val_accuracy: 0.2143 - val_loss: 5.0607\n",
      "Epoch 294/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0594 - val_accuracy: 0.2143 - val_loss: 5.0618\n",
      "Epoch 295/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0594 - val_accuracy: 0.2143 - val_loss: 5.0618\n",
      "Epoch 296/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0593 - val_accuracy: 0.2143 - val_loss: 5.0643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0592 - val_accuracy: 0.2143 - val_loss: 5.0671\n",
      "Epoch 298/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0592 - val_accuracy: 0.2143 - val_loss: 5.0671\n",
      "Epoch 299/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0592 - val_accuracy: 0.2143 - val_loss: 5.0682\n",
      "Epoch 300/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0591 - val_accuracy: 0.2143 - val_loss: 5.0668\n",
      "Epoch 301/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0589 - val_accuracy: 0.2143 - val_loss: 5.0645\n",
      "Epoch 302/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9815 - loss: 0.0587 - val_accuracy: 0.2143 - val_loss: 5.0647\n",
      "Epoch 303/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0588 - val_accuracy: 0.2143 - val_loss: 5.0684\n",
      "Epoch 304/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0604 - val_accuracy: 0.2143 - val_loss: 5.0770\n",
      "Epoch 305/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0591 - val_accuracy: 0.2143 - val_loss: 5.0824\n",
      "Epoch 306/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0591 - val_accuracy: 0.2143 - val_loss: 5.1008\n",
      "Epoch 307/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0588 - val_accuracy: 0.2143 - val_loss: 5.1157\n",
      "Epoch 308/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0589 - val_accuracy: 0.2143 - val_loss: 5.1318\n",
      "Epoch 309/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0590 - val_accuracy: 0.2143 - val_loss: 5.1387\n",
      "Epoch 310/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0588 - val_accuracy: 0.2143 - val_loss: 5.1499\n",
      "Epoch 311/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0585 - val_accuracy: 0.2143 - val_loss: 5.1551\n",
      "Epoch 312/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0585 - val_accuracy: 0.2143 - val_loss: 5.1561\n",
      "Epoch 313/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0587 - val_accuracy: 0.2143 - val_loss: 5.1587\n",
      "Epoch 314/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0585 - val_accuracy: 0.2143 - val_loss: 5.1539\n",
      "Epoch 315/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0583 - val_accuracy: 0.2143 - val_loss: 5.1526\n",
      "Epoch 316/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0585 - val_accuracy: 0.2143 - val_loss: 5.1534\n",
      "Epoch 317/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0582 - val_accuracy: 0.2143 - val_loss: 5.1481\n",
      "Epoch 318/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0582 - val_accuracy: 0.2143 - val_loss: 5.1464\n",
      "Epoch 319/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9444 - loss: 0.0584 - val_accuracy: 0.2143 - val_loss: 5.1393\n",
      "Epoch 320/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0581 - val_accuracy: 0.2143 - val_loss: 5.1375\n",
      "Epoch 321/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0580 - val_accuracy: 0.2143 - val_loss: 5.1379\n",
      "Epoch 322/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0580 - val_accuracy: 0.2143 - val_loss: 5.1410\n",
      "Epoch 323/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0580 - val_accuracy: 0.2143 - val_loss: 5.1447\n",
      "Epoch 324/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0579 - val_accuracy: 0.2143 - val_loss: 5.1478\n",
      "Epoch 325/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0579 - val_accuracy: 0.2143 - val_loss: 5.1530\n",
      "Epoch 326/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9444 - loss: 0.0580 - val_accuracy: 0.2143 - val_loss: 5.1603\n",
      "Epoch 327/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0578 - val_accuracy: 0.2143 - val_loss: 5.1626\n",
      "Epoch 328/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0579 - val_accuracy: 0.2143 - val_loss: 5.1654\n",
      "Epoch 329/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0585 - val_accuracy: 0.2143 - val_loss: 5.1641\n",
      "Epoch 330/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0578 - val_accuracy: 0.2143 - val_loss: 5.1685\n",
      "Epoch 331/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0577 - val_accuracy: 0.2143 - val_loss: 5.1777\n",
      "Epoch 332/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0579 - val_accuracy: 0.2143 - val_loss: 5.1832\n",
      "Epoch 333/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0575 - val_accuracy: 0.2143 - val_loss: 5.1927\n",
      "Epoch 334/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0576 - val_accuracy: 0.2143 - val_loss: 5.2029\n",
      "Epoch 335/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0580 - val_accuracy: 0.2143 - val_loss: 5.2090\n",
      "Epoch 336/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0577 - val_accuracy: 0.2143 - val_loss: 5.2052\n",
      "Epoch 337/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0577 - val_accuracy: 0.2143 - val_loss: 5.1969\n",
      "Epoch 338/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0576 - val_accuracy: 0.2143 - val_loss: 5.1792\n",
      "Epoch 339/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0582 - val_accuracy: 0.2143 - val_loss: 5.1634\n",
      "Epoch 340/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0579 - val_accuracy: 0.2143 - val_loss: 5.1603\n",
      "Epoch 341/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0576 - val_accuracy: 0.2143 - val_loss: 5.1629\n",
      "Epoch 342/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.2143 - val_loss: 5.1717\n",
      "Epoch 343/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0577 - val_accuracy: 0.2143 - val_loss: 5.1859\n",
      "Epoch 344/500\n",
      "2/2 - 0s - 44ms/step - accuracy: 0.9630 - loss: 0.0574 - val_accuracy: 0.2143 - val_loss: 5.1971\n",
      "Epoch 345/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0576 - val_accuracy: 0.2143 - val_loss: 5.2062\n",
      "Epoch 346/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0574 - val_accuracy: 0.2143 - val_loss: 5.2087\n",
      "Epoch 347/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.2143 - val_loss: 5.2068\n",
      "Epoch 348/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0571 - val_accuracy: 0.2143 - val_loss: 5.2035\n",
      "Epoch 349/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0574 - val_accuracy: 0.2143 - val_loss: 5.1978\n",
      "Epoch 350/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0573 - val_accuracy: 0.2143 - val_loss: 5.1978\n",
      "Epoch 351/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0570 - val_accuracy: 0.2143 - val_loss: 5.2011\n",
      "Epoch 352/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0570 - val_accuracy: 0.2143 - val_loss: 5.2047\n",
      "Epoch 353/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0571 - val_accuracy: 0.2143 - val_loss: 5.2085\n",
      "Epoch 354/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0569 - val_accuracy: 0.2143 - val_loss: 5.2160\n",
      "Epoch 355/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0569 - val_accuracy: 0.2143 - val_loss: 5.2219\n",
      "Epoch 356/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0569 - val_accuracy: 0.2143 - val_loss: 5.2283\n",
      "Epoch 357/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0570 - val_accuracy: 0.2143 - val_loss: 5.2349\n",
      "Epoch 358/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0568 - val_accuracy: 0.2143 - val_loss: 5.2378\n",
      "Epoch 359/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0569 - val_accuracy: 0.2143 - val_loss: 5.2387\n",
      "Epoch 360/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0568 - val_accuracy: 0.2143 - val_loss: 5.2423\n",
      "Epoch 361/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0568 - val_accuracy: 0.2143 - val_loss: 5.2473\n",
      "Epoch 362/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0569 - val_accuracy: 0.2143 - val_loss: 5.2552\n",
      "Epoch 363/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0567 - val_accuracy: 0.2143 - val_loss: 5.2573\n",
      "Epoch 364/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0568 - val_accuracy: 0.2143 - val_loss: 5.2569\n",
      "Epoch 365/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0566 - val_accuracy: 0.2143 - val_loss: 5.2599\n",
      "Epoch 366/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0566 - val_accuracy: 0.2143 - val_loss: 5.2614\n",
      "Epoch 367/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0567 - val_accuracy: 0.2143 - val_loss: 5.2641\n",
      "Epoch 368/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0566 - val_accuracy: 0.2143 - val_loss: 5.2606\n",
      "Epoch 369/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0566 - val_accuracy: 0.2143 - val_loss: 5.2605\n",
      "Epoch 370/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0565 - val_accuracy: 0.2143 - val_loss: 5.2560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0565 - val_accuracy: 0.2143 - val_loss: 5.2540\n",
      "Epoch 372/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0567 - val_accuracy: 0.2143 - val_loss: 5.2512\n",
      "Epoch 373/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0566 - val_accuracy: 0.2143 - val_loss: 5.2559\n",
      "Epoch 374/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0565 - val_accuracy: 0.2143 - val_loss: 5.2639\n",
      "Epoch 375/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0564 - val_accuracy: 0.2143 - val_loss: 5.2757\n",
      "Epoch 376/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0563 - val_accuracy: 0.2143 - val_loss: 5.2858\n",
      "Epoch 377/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9444 - loss: 0.0563 - val_accuracy: 0.2143 - val_loss: 5.2979\n",
      "Epoch 378/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0563 - val_accuracy: 0.2143 - val_loss: 5.3058\n",
      "Epoch 379/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0565 - val_accuracy: 0.2143 - val_loss: 5.3132\n",
      "Epoch 380/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0564 - val_accuracy: 0.2143 - val_loss: 5.3143\n",
      "Epoch 381/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0563 - val_accuracy: 0.2143 - val_loss: 5.3114\n",
      "Epoch 382/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.2143 - val_loss: 5.3032\n",
      "Epoch 383/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0565 - val_accuracy: 0.2143 - val_loss: 5.2944\n",
      "Epoch 384/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.2143 - val_loss: 5.2921\n",
      "Epoch 385/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.2143 - val_loss: 5.2918\n",
      "Epoch 386/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.2143 - val_loss: 5.2956\n",
      "Epoch 387/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.2143 - val_loss: 5.2972\n",
      "Epoch 388/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0563 - val_accuracy: 0.2143 - val_loss: 5.2990\n",
      "Epoch 389/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.2143 - val_loss: 5.3044\n",
      "Epoch 390/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.2143 - val_loss: 5.3141\n",
      "Epoch 391/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0563 - val_accuracy: 0.2143 - val_loss: 5.3277\n",
      "Epoch 392/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.2143 - val_loss: 5.3339\n",
      "Epoch 393/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0562 - val_accuracy: 0.2143 - val_loss: 5.3438\n",
      "Epoch 394/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.2143 - val_loss: 5.3452\n",
      "Epoch 395/500\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.2143 - val_loss: 5.3505\n",
      "Epoch 396/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.2143 - val_loss: 5.3541\n",
      "Epoch 397/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0561 - val_accuracy: 0.2143 - val_loss: 5.3489\n",
      "Epoch 398/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.2143 - val_loss: 5.3481\n",
      "Epoch 399/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.2143 - val_loss: 5.3467\n",
      "Epoch 400/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.2143 - val_loss: 5.3380\n",
      "Epoch 401/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.2143 - val_loss: 5.3356\n",
      "Epoch 402/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.2143 - val_loss: 5.3339\n",
      "Epoch 403/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0557 - val_accuracy: 0.2143 - val_loss: 5.3347\n",
      "Epoch 404/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0562 - val_accuracy: 0.2143 - val_loss: 5.3393\n",
      "Epoch 405/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0560 - val_accuracy: 0.2143 - val_loss: 5.3325\n",
      "Epoch 406/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.2143 - val_loss: 5.3361\n",
      "Epoch 407/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0559 - val_accuracy: 0.2143 - val_loss: 5.3388\n",
      "Epoch 408/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0560 - val_accuracy: 0.2143 - val_loss: 5.3328\n",
      "Epoch 409/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0557 - val_accuracy: 0.2143 - val_loss: 5.3378\n",
      "Epoch 410/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0557 - val_accuracy: 0.2143 - val_loss: 5.3414\n",
      "Epoch 411/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0557 - val_accuracy: 0.2143 - val_loss: 5.3443\n",
      "Epoch 412/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.2143 - val_loss: 5.3482\n",
      "Epoch 413/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0559 - val_accuracy: 0.2143 - val_loss: 5.3589\n",
      "Epoch 414/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0558 - val_accuracy: 0.2143 - val_loss: 5.3651\n",
      "Epoch 415/500\n",
      "2/2 - 0s - 37ms/step - accuracy: 0.9630 - loss: 0.0556 - val_accuracy: 0.2143 - val_loss: 5.3740\n",
      "Epoch 416/500\n",
      "2/2 - 0s - 28ms/step - accuracy: 0.9630 - loss: 0.0556 - val_accuracy: 0.2143 - val_loss: 5.3837\n",
      "Epoch 417/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.2143 - val_loss: 5.3919\n",
      "Epoch 418/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0555 - val_accuracy: 0.2143 - val_loss: 5.3991\n",
      "Epoch 419/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0561 - val_accuracy: 0.2143 - val_loss: 5.4068\n",
      "Epoch 420/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.2143 - val_loss: 5.4052\n",
      "Epoch 421/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.2143 - val_loss: 5.4026\n",
      "Epoch 422/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0556 - val_accuracy: 0.2143 - val_loss: 5.3995\n",
      "Epoch 423/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.2143 - val_loss: 5.4020\n",
      "Epoch 424/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9444 - loss: 0.0559 - val_accuracy: 0.2143 - val_loss: 5.4079\n",
      "Epoch 425/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.2143 - val_loss: 5.4027\n",
      "Epoch 426/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.2143 - val_loss: 5.4016\n",
      "Epoch 427/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.2143 - val_loss: 5.3976\n",
      "Epoch 428/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.2143 - val_loss: 5.3925\n",
      "Epoch 429/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0562 - val_accuracy: 0.2143 - val_loss: 5.3839\n",
      "Epoch 430/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.2143 - val_loss: 5.3879\n",
      "Epoch 431/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.2143 - val_loss: 5.3949\n",
      "Epoch 432/500\n",
      "2/2 - 0s - 32ms/step - accuracy: 0.9630 - loss: 0.0554 - val_accuracy: 0.2143 - val_loss: 5.4022\n",
      "Epoch 433/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.2143 - val_loss: 5.4132\n",
      "Epoch 434/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.2143 - val_loss: 5.4225\n",
      "Epoch 435/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0554 - val_accuracy: 0.2143 - val_loss: 5.4319\n",
      "Epoch 436/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.2143 - val_loss: 5.4342\n",
      "Epoch 437/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.2143 - val_loss: 5.4401\n",
      "Epoch 438/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.2143 - val_loss: 5.4445\n",
      "Epoch 439/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.2143 - val_loss: 5.4467\n",
      "Epoch 440/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.2143 - val_loss: 5.4468\n",
      "Epoch 441/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9630 - loss: 0.0552 - val_accuracy: 0.2143 - val_loss: 5.4480\n",
      "Epoch 442/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.2143 - val_loss: 5.4536\n",
      "Epoch 443/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.2143 - val_loss: 5.4545\n",
      "Epoch 444/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.2143 - val_loss: 5.4486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.2143 - val_loss: 5.4437\n",
      "Epoch 446/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.2143 - val_loss: 5.4358\n",
      "Epoch 447/500\n",
      "2/2 - 0s - 40ms/step - accuracy: 0.9444 - loss: 0.0552 - val_accuracy: 0.2143 - val_loss: 5.4281\n",
      "Epoch 448/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.2143 - val_loss: 5.4265\n",
      "Epoch 449/500\n",
      "2/2 - 0s - 43ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.2143 - val_loss: 5.4307\n",
      "Epoch 450/500\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.9444 - loss: 0.0555 - val_accuracy: 0.2143 - val_loss: 5.4378\n",
      "Epoch 451/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9444 - loss: 0.0556 - val_accuracy: 0.2143 - val_loss: 5.4332\n",
      "Epoch 452/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.2143 - val_loss: 5.4395\n",
      "Epoch 453/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0552 - val_accuracy: 0.2143 - val_loss: 5.4509\n",
      "Epoch 454/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9444 - loss: 0.0551 - val_accuracy: 0.2143 - val_loss: 5.4583\n",
      "Epoch 455/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.2143 - val_loss: 5.4602\n",
      "Epoch 456/500\n",
      "2/2 - 0s - 45ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.2143 - val_loss: 5.4616\n",
      "Epoch 457/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.2143 - val_loss: 5.4667\n",
      "Epoch 458/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.2143 - val_loss: 5.4712\n",
      "Epoch 459/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.2143 - val_loss: 5.4732\n",
      "Epoch 460/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9444 - loss: 0.0548 - val_accuracy: 0.2143 - val_loss: 5.4792\n",
      "Epoch 461/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0550 - val_accuracy: 0.2143 - val_loss: 5.4844\n",
      "Epoch 462/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.2143 - val_loss: 5.4831\n",
      "Epoch 463/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.2143 - val_loss: 5.4812\n",
      "Epoch 464/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.2143 - val_loss: 5.4789\n",
      "Epoch 465/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9444 - loss: 0.0549 - val_accuracy: 0.2143 - val_loss: 5.4825\n",
      "Epoch 466/500\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.2143 - val_loss: 5.4808\n",
      "Epoch 467/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0549 - val_accuracy: 0.2143 - val_loss: 5.4786\n",
      "Epoch 468/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.2143 - val_loss: 5.4803\n",
      "Epoch 469/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.2143 - val_loss: 5.4876\n",
      "Epoch 470/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0553 - val_accuracy: 0.2143 - val_loss: 5.4957\n",
      "Epoch 471/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.2143 - val_loss: 5.4941\n",
      "Epoch 472/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9444 - loss: 0.0549 - val_accuracy: 0.2143 - val_loss: 5.4869\n",
      "Epoch 473/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9444 - loss: 0.0548 - val_accuracy: 0.2143 - val_loss: 5.4866\n",
      "Epoch 474/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.2143 - val_loss: 5.4894\n",
      "Epoch 475/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.2143 - val_loss: 5.4971\n",
      "Epoch 476/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9444 - loss: 0.0553 - val_accuracy: 0.2143 - val_loss: 5.5066\n",
      "Epoch 477/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0547 - val_accuracy: 0.2143 - val_loss: 5.5079\n",
      "Epoch 478/500\n",
      "2/2 - 0s - 33ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.2143 - val_loss: 5.5054\n",
      "Epoch 479/500\n",
      "2/2 - 0s - 42ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.2143 - val_loss: 5.5027\n",
      "Epoch 480/500\n",
      "2/2 - 0s - 31ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.2143 - val_loss: 5.4988\n",
      "Epoch 481/500\n",
      "2/2 - 0s - 46ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.2143 - val_loss: 5.4994\n",
      "Epoch 482/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.2143 - val_loss: 5.5019\n",
      "Epoch 483/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0551 - val_accuracy: 0.2143 - val_loss: 5.5067\n",
      "Epoch 484/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.2143 - val_loss: 5.5178\n",
      "Epoch 485/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.2143 - val_loss: 5.5293\n",
      "Epoch 486/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.2143 - val_loss: 5.5400\n",
      "Epoch 487/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.2143 - val_loss: 5.5479\n",
      "Epoch 488/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.2143 - val_loss: 5.5544\n",
      "Epoch 489/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0549 - val_accuracy: 0.2143 - val_loss: 5.5671\n",
      "Epoch 490/500\n",
      "2/2 - 0s - 36ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.2143 - val_loss: 5.5724\n",
      "Epoch 491/500\n",
      "2/2 - 0s - 29ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.2143 - val_loss: 5.5761\n",
      "Epoch 492/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.2143 - val_loss: 5.5722\n",
      "Epoch 493/500\n",
      "2/2 - 0s - 48ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.2143 - val_loss: 5.5663\n",
      "Epoch 494/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.2143 - val_loss: 5.5595\n",
      "Epoch 495/500\n",
      "2/2 - 0s - 41ms/step - accuracy: 0.9630 - loss: 0.0545 - val_accuracy: 0.2143 - val_loss: 5.5533\n",
      "Epoch 496/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.2143 - val_loss: 5.5434\n",
      "Epoch 497/500\n",
      "2/2 - 0s - 39ms/step - accuracy: 0.9630 - loss: 0.0544 - val_accuracy: 0.2143 - val_loss: 5.5355\n",
      "Epoch 498/500\n",
      "2/2 - 0s - 34ms/step - accuracy: 0.9444 - loss: 0.0551 - val_accuracy: 0.2143 - val_loss: 5.5267\n",
      "Epoch 499/500\n",
      "2/2 - 0s - 38ms/step - accuracy: 0.9630 - loss: 0.0548 - val_accuracy: 0.2143 - val_loss: 5.5267\n",
      "Epoch 500/500\n",
      "2/2 - 0s - 35ms/step - accuracy: 0.9630 - loss: 0.0546 - val_accuracy: 0.2143 - val_loss: 5.5372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Encoder-Decoder_chat_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = [\n",
    "    build_lstm_model(),\n",
    "    build_rnn_model(),\n",
    "    build_brnn_model(),\n",
    "    build_encoder_decoder_model()\n",
    "]\n",
    "\n",
    "model_names = ['LSTM', 'RNN', 'BRNN', 'Encoder-Decoder']\n",
    "\n",
    "# Train the models and collec\n",
    "history_dict = train_evaluate_and_save_multiple(models, model_names, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b84c0",
   "metadata": {},
   "source": [
    "### Plotting the Accuracy and Loss for All Models\n",
    "\n",
    "In this section of the code, we are visualizing the performance of all trained models in terms of accuracy and loss across different epochs. This helps in comparing the effectiveness of each model on the given task. The function `plot_metrics()` is defined to create these plots.\n",
    "\n",
    "#### Steps:\n",
    "1. **Function Definition - `plot_metrics()`**:\n",
    "   - The function takes **`history_dict`** as input, which contains the training history for each model. This history includes metrics like accuracy and loss for both training and validation datasets.\n",
    "   - The function generates two plots:\n",
    "     - **Accuracy Plot**: This shows the change in training and validation accuracy for each model over the epochs.\n",
    "     - **Loss Plot**: This shows the change in training and validation loss for each model over the epochs.\n",
    "\n",
    "2. **Accuracy Plot**:\n",
    "   - The first subplot in the figure compares the training and validation accuracy of each model.\n",
    "   - For each model in `history_dict`, the `accuracy` and `val_accuracy` values are extracted and plotted over the epochs.\n",
    "   - This helps in identifying how well each model is learning the task and generalizing to unseen data (validation accuracy).\n",
    "\n",
    "3. **Loss Plot**:\n",
    "   - The second subplot compares the training and validation loss of each model.\n",
    "   - The `loss` and `val_loss` values from the `history_dict` are plotted for each model over the epochs.\n",
    "   - This allows us to visualize the reduction in loss as the models learn and improve over time.\n",
    "\n",
    "4. **Plot Customization**:\n",
    "   - **Legends**: Labels are added to the plots to indicate which line corresponds to which model and whether it is for training or validation.\n",
    "   - **Titles and Labels**: Titles such as \"Accuracy Comparison\" and \"Loss Comparison\" are added, along with axis labels for clarity.\n",
    "   - **Layout**: The `tight_layout()` function ensures that the subplots are well-spaced and visible.\n",
    "\n",
    "5. **Plot Display**:\n",
    "   - The `plt.show()` function displays the generated plots.\n",
    "\n",
    "#### Summary:\n",
    "This code provides a visual comparison of the training and validation performance of all models (LSTM, RNN, BRNN, and Encoder-Decoder) in terms of both accuracy and loss. By comparing the accuracy and loss trends across models, we can identify which model performs best and whether it is overfitting or generalizing well. This visualization is useful for model selection and further fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c919405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAGoCAYAAABbkkSYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd5xU1fn48c+Zvr0vCwtIUaRtoUivohAbYBeNiJr4i9FoNLF3jZEoMUqiX5MYS4xKNFGjYgsqorECLgICovS2je2708/vjzszO7M7u2xfFp7368WLnTu3nDs7O3Of+5zzHKW1RgghhBBCCCFE+5m6uwFCCCGEEEIIcaSQAEsIIYQQQgghOogEWEIIIYQQQgjRQSTAEkIIIYQQQogOIgGWEEIIIYQQQnQQCbCEEEIIIYQQooNIgCWE6DBKqbeVUpd0dzuEEEIcmZRS/ZVS1Uopc3e3RYimSIAlehSl1EqlVJlSyt7dbeksSqlEpdQjSqldgS+R7wOP07u7bYeitT5Fa/1sd7dDCCF6AqXUDqXUSd107HFKqbeUUuVKqYNKqS+VUpd2R1taQ2u9S2sdr7X2dXdbhGiKBFiix1BKDQCmAhqY28XHtnTRcWzA+8AI4EdAIjAJKAXGdUUb2kIZ5PNECCF6AKXUROAD4CPgWCANuBI4pTvbdShd9V0sRHvJBZHoSRYCnwPPABHd0JRS/ZRSryilipVSpUqpP4U991Ol1CalVJVS6lul1OjAcq2UOjZsvWeUUr8J/DxDKbVHKXWTUuoA8LRSKkUp9WbgGGWBn/uGbZ+qlHpaKbUv8PxrgeUblFJnhK1nVUqVKKXymzjH/sCZWutvtdZ+rXWR1vo+rfVbge2HBTJ55UqpjUqpuWH7fkYp9Xigq161Uup/SqmsQAasTCm1WSk1Kmz9HUqpWwKvS1mg/Y7Ac4c635VKqfuVUv8DaoFBgWU/CTx/rFLqI6VUReB8/xm27SSl1FeB575SSk1qsN/7Am2vUkq91xOyd0II0VGUUvbA5/a+wL9Hgj03lFLpgc/jYObp4+ANrsB31t7AZ+cWpdSsJg7xEPCs1vp3WusSbVijtT4vrA0/DfSgOKiUel0p1SfsOa2U+rlSamvgWPcppQYrpT5TSlUqpV4K3DAM/z69NfBdsEMpdVHYvk5TSn0d2G63UurusOcGBI51uVJqF/BB2DJLYJ1FSqltgXZsD+5bKWVSSt2ulNqplCpSSv1dKZXUYL+XKKO3SIlS6raO+e0JIQGW6FkWAs8H/s1RSvUCUEY/7DeBncAAIBtYFnjuXODuwLaJGJmv0hYeLwtIBY4BrsD4e3k68Lg/UAf8KWz954BYjOxTJvCHwPK/Az8OW+9UYL/WuiDKMU8C3tFaV0drkFLKCrwBvBc4xi+A55VSx4etdh5wO5AOuIDPgLWBx/8CHm6w24uAOcBgYEhgW1pwvgAXY7w2CRivf7j7Au1MAfoCfwycQyqwHFiKcdf0YWC5UiotbNsLgUsD52gDfh3t9RBCiCPUbcAEIB/Iw+jBEPxs/hWwB8gAegG3AjrwPXA1cILWOgHjc31Hwx0rpWKBiRjfB1EppU4EHsD4PumN8fm+rMFqPwLGBNp5I/AXjO+TfsBIYEHYulkY30HZGDdI/xL2vVWD8R2dDJwGXKmUmt/gWNOBYYFzCm9nHMZ3ySmBc54EFASeXhT4NxMYBMTT+DtsCnA8MAu4Uyk1LPorIkTrSIAlegSl1BSMC/2XtNZrgB8wLsLB+OLpA9ygta7RWju11p8EnvsJ8KDW+qvAHbrvtdYNA4Gm+IG7tNYurXWd1rpUa/1vrXWt1roKuB/jQx+lVG+MrhU/01qXaa09WuuPAvv5B3CqUiox8PhijGAsmjRgfzNtmoDxJbFYa+3WWn+AEVyGf5G9GrgT6QReBZxa678H+qv/ExjVYJ9/0lrv1lofDJzTAoDmzjfMM1rrjVprr9ba0+A5D8bvrE+D38lpwFat9XOB7V4ENgNnhG37tNb6O611HfASxkWGEEIcLS4C7g30YCgG7sH47gDjs7U3cEzgu+ZjrbUGfIAdGK6Usmqtd2itf4iy7xSM67/mvmsuAp7SWq/VWruAW4CJyuiqH/Q7rXWl1nojsAF4T2u9TWtdAbxN4++aOwLfpx9h3GQ7D0BrvVJrvT7QY+Mb4EUaf9fcHfh+r4vSVj8wUikVo7XeH2hP8BweDrSpOnAOF6jIbob3BL7f1wHrMIJZIdpNAizRU1yC8eFdEnj8AvXdBPsBO7XW3ijb9cMIxtqiOBCkAMZdP6XUnwPdDSqBVUByIIPWDziotS5ruBOt9T7gf8DZSqlkjEDs+SaOWYrxxdmUPsBurbU/bNlOjLuCQYVhP9dFeRzfYJ+7G+yrDxzyfKNt29CNgAK+VEZXxsvCzqFhkNvwHA6E/Vwbpc1CCHEka/g5Gfpsxuje9z3wXqBr3M0AWuvvgV9i9NooUkotC+/WF6YMIyg51HdN6PiBAKWUtn/XlGmta6Kdj1JqvFLqQ2V0R68AfoaR7QoX9bsmsM/zA9vsV0otV0oNjXYOgZ8tGFm/IPmuEZ1CAixx2FNKxWDc6ZqulDqgjDFR1wF5Sqk8jA/e/ir64NfdGF3foqnF6NIXlNXged3g8a8wuhKM11onAtOCTQwcJzUQQEXzLEY3wXOBz7TWe5tYbwVG98e4Jp7fB/RTkQUl+gNN7a8l+jXY177Az82db1DD16j+Ca0PaK1/qrXuA/w/4HFljHnbh5HZCtfecxBCiCNJw8/J0Gez1rpKa/0rrfUgjMz/9cGxVlrrF7TWwR4fGvhdwx1rrWsxuo6f3dLjB76T0mj753RKg++18O+aF4DXgX5a6yTgCSK/Z6D575p3tdYnYwSMm4G/RjuHwDG9RAaCQnQKCbBETzAfo+vDcIyuYvkYfbE/xui3/SVGV4fFSqk4pZRDKTU5sO2TwK+VUmOU4VilVPADtwC4UCllVkr9iMZdEhpKwLgrVx4YR3RX8Amt9X6MLhGPK6M4hFUpNS1s29eA0cC1GGOymvIcRrD2b6XU0MAg3bTA4OBTgS8w+qvfGDjGDIwv2IZ941vjKqVU38A53YrRjbDZ820JpdS5qr4oRhnGF6QPeAsYopS6UCllUUqdj/G7fbMd5yCEED2VNfC9Ffxnwegmd7tSKkMZRX7uxOhujlLq9MB3mQIqMT5XfUqp45VSJyqjGIYT4/O7qVLmNwKLlFI3BMe/KqXylFLB75IXgEuVUvmB/f0W+EJrvaMd53mPUsqmlJoKnA68HFiegNEDxKmUGkd99/9DUkr1UkrNDQRvLqCa+nN+EbhOKTVQKRUfOId/NtHbRYgOJQGW6AkuwRiTsyuQFTmgtT6AMVj1Iow7XWdglJrdhTH493wArfXLGGOHXgCqMAKd1MB+rw1sVx7Yz2uHaMcjQAxQglHN8J0Gz1+M0Td+M1CE0VWDQDvqgH8DA4FXmjpAoK/7SYF9/Bfjy/NLjO4SX2it3RiFOk4JtONxYKHWevMh2t6cFzCKUWwL/PtNYPkjNH++h3IC8IVSqhrj7uS1WuvtWutSjC/XX2F0ObkROD2s+6cQQhxN3sIIhoL/7sb4HF4NfAOsxyhUFPxsPg6jt0M1Ribqca31SozxV4sxPrMPYBQJujXaAbXWnwInBv5tU0odxChS8Vbg+feBOzC+t/Zj9AS5oB3neADjRts+jC7yPwv73vo5cK9SqgojkHypFfs1YXyX7AMOYtwo/XnguacwblquArZjBJ2/aMc5CNFiyhgXKYTobEqpO4EhWusfH3LlLqKU2gH8RGu9orvbIoQQ4sgT6GnxD61130OsKsQRQyZsE6ILBLrYXU59FSghhBBCCHEEki6CQnQypdRPMcZVva21XtXd7RFCCCGEEJ1HuggKIYQQQgghRAeRDJYQQgghhBBCdJAeNwYrPT1dDxgwoLubIYQQogusWbOmRGud0d3taCn5jhJCiKNHU99RPS7AGjBgAKtXr+7uZgghhOgCSqmd3d2G1pDvKCGEOHo09R0lXQSFEEIIIYQQooNIgCWEEEIIIYQQHUQCLCGEEEIIIYToID1uDJYQQgjR0ZRSTwGnA0Va65GBZQ8BZwBu4AfgUq11eWv37fF42LNnD06nswNbLETncTgc9O3bF6vV2t1NEaJHkgBLCCGEgGeAPwF/D1v2X+AWrbVXKfU74BbgptbueM+ePSQkJDBgwACUUh3SWCE6i9aa0tJS9uzZw8CBA7u7OUL0SJ3WRVAp9ZRSqkgptaGJ55VSaqlS6nul1DdKqdGd1RYhhBCiOVrrVcDBBsve01p7Aw8/B/q2Zd9Op5O0tDQJrkSPoJQiLS1NMq5CtENnjsF6BvhRM8+fAhwX+HcF8H+d2BYhhBCiPS4D3o72hFLqCqXUaqXU6uLi4qgbS3AlehJ5vwrRPp0WYEW7G9jAPODv2vA5kKyU6t1Z7RFCCCHaQil1G+AFno/2vNb6L1rrsVrrsRkZPWZOZCGEEJ2kO6sIZgO7wx7vCSxrpCV3B4UQQoiOppS6BKP4xUVaa93d7Wmr+Pj4Rsu2bNnCjBkzyM/PZ9iwYVxxxRW8++675Ofnk5+fT3x8PMcffzz5+fksXLiQlStXopTib3/7W2gfX3/9NUoplixZErHv+++/P7Qfs9kc+nnp0qUtau9PfvITvv322xaf3zPPPMPVV1/d4vWFEKIzdWeRi2j556hfXlrrvwB/ARg7dmyP/YITQgjRcyilfoRR1GK61rq2u9vT0a655hquu+465s2bB8D69evJyclhzpw5AMyYMYMlS5YwduxYAFauXElOTg7//Oc/ufzyywFYtmwZeXl5jfZ92223cdtttwFGcFdQUBDxvNYarTUmU/T7vE8++WSHnKMQQnSH7sxg7QH6hT3uC+zrprYIIYQ4iimlXgQ+A45XSu1RSl2OUVUwAfivUqpAKfVEtzayg+3fv5++fevrduTk5Bxym/79++N0OiksLERrzTvvvMMpp5zSouPt2LGDYcOG8fOf/5zRo0eze/durrzySsaOHcuIESO46667QuvOmDGD1atXA0aAdtttt5GXl8eECRMoLCxs8Tk+/PDDjBw5kpEjR/LII48AUFNTw2mnnUZeXh4jR47kn//8JwA333wzw4cPJzc3l1//+tctPoYQQjTUnRms14GrlVLLgPFAhdZ6fze2RwghxFFKa70gyuK/RVnWLve8sZFv91V26D6H90nkrjNGtHq76667jhNPPJFJkyYxe/ZsLr30UpKTkw+53TnnnMPLL7/MqFGjGD16NHa7vcXH3LJlC08//TSPP/44YHQlTE1NxefzMWvWLL755htyc3MjtqmpqWHChAncf//93Hjjjfz1r3/l9ttvP+Sx1qxZw9NPP80XX3yB1prx48czffp0tm3bRp8+fVi+fDkAFRUVHDx4kFdffZXNmzejlKK8vLzF5ySEEA11Zpn2RncDlVI/U0r9LLDKW8A24Hvgr8DPO6stQgghhIh06aWXsmnTJs4991xWrlzJhAkTcLlch9zuvPPO4+WXX+bFF19kwYJocWnTjjnmGCZMmBB6/NJLLzF69GhGjRrFxo0bo467stlsnH766QCMGTOGHTt2tOhYn3zyCWeeeSZxcXHEx8dz1lln8fHHH5OTk8OKFSu46aab+Pjjj0lKSiIxMRGHw8FPfvITXnnlFWJjY1t1XkIIEa7TMlhN3A0Mf14DV3XW8YUQQojDTVsyTZ2pT58+XHbZZVx22WWMHDmSDRs2MGbMmGa3ycrKwmq18t///pdHH32UTz/9tMXHi4uLC/28fft2lixZwldffUVKSgqLFi2KOveS1WoNlQ03m814vd5G60TTVE2SIUOGsGbNGt566y1uueUWZs+ezZ133smXX37J+++/z7Jly/jTn/7EBx980OLzEkKIcN05Bkt0E7fPzTUfXMN3Zd91d1MAWPveTta+t7ND91ld5uKNPxbgrPa0e18f7PqA3//pObZ8cQCfx89b//cNJXuqGq1X46nh5yt+zu7K3VH2Um/f9+W89+QGtL9n1mup+eoAFW9v7+5mdJrP93/OjR/d2OTFWXvVVLh47Q9rqa10t2j9tYVrufGjG/Frf6e0Rxy93nnnHTwe4zPywIEDlJaWkp0dtZhvI/feey+/+93vMJvNbT5+ZWUlcXFxJCUlUVhYyNtvR51mrM2mTZvGa6+9Rm1tLTU1Nbz66qtMnTqVffv2ERsby49//GN+/etfs3btWqqrq6moqODUU0/lkUceaVSUQwjRw7mqYccn8MkjsOwieDQffO2/RmxKd47BEt1kY+lGPtz9ISV1Jbxw2gvd3Rw+e+UHAEbPPqbD9vn1ezvZtfEgmz7bz6iT+7drX9d+eC0/2/AoKzZ8S1JGDNvXlVBd5uK8W0+IWO+j3R/x8d6Pcax18PCMh5vc3/I/rcPt9DH5nOOIS2752IXDRdm/twKQdMrAbm5J57jivSvQaO6ceCfxtsalrdvr6//uYu+WcjZ/tp/Rcw79nr/q/auo9lTz6xN+TWZsZoe3RxwdamtrIwpaXH/99ezZs4drr70Wh8MBwEMPPURWVlaL9jdp0qR2tykvL49Ro0YxYsQIBg0axOTJk9u1v2eeeYbXXnst9Pjzzz9n0aJFjBs3DjBKv48aNYp3332XG264AZPJhNVq5f/+7/+oqqpi3rx5OJ1OtNb84Q9/aFdbhBDdwOeFom9h31oo/QEq90HlXuNfxR4I3qhMGQh9TwBnJcSldUpTJMA6CtV4aoCmu08cCTryzCw+W+hnj9Nn7D/Ka+fTvhbtL7hlTYWrRwZYR7o4axzVnmqKaos6JcBy1Rrdm+yxLfv41YF3THFdsQRYos38/ugZ0Icfbvpm0MqVKyMez5gxgxkzZjRa7+6772722NXV1QAMGDCADRs2RDz3zDPPHPLYwe3BKLBxzjnnNFp/0aJFLFq0qNHy66+/nuuvvz5i2Zw5c0Kl6MN9+eWXTZ2CEKK7+f3g94DWRqBUdxC2r4LdX0JNMVQdgMKN4K0z1jfbIbEPJGZDvwmQNxCyx0L2mE4LqsJJgHUUKq49PCdr9vn8mM0d1Gs1EMV43S0LepoT504K/Vxd3vQA8DJnWav2W1Pugo5L2nU5rXVoXMSRJNYaawRYdUUMSh7U4ft31RhdEqyO1nWtKqopYkTa4TV+RwghhOhwWsOBb2DTG7BnNZTvgord4IvStd6RZARRsWkw9jLIHg19RkHqIOjGaxQJsI5ChbXGHCK6Q/M87VdX6SY+xdEx+6o2/ghrmgmIWioiwCprPAA7qKi2CACnt+l1wtVUtGwMzuFEe+vvgmuPH2Vr+/iLw1W8NZ4iikK/z47mDARYPk/r/v6K6w7PGyNCCCFEu7lrYO9a2PIWbH7TCKqUCbJyIWskDD3NCKaUMpZb4+CYiZA5ApqYsLw7SYB1FApmsMpd5d3bEIgo9FBd7uqwACsYWLU3iKn11BIbFmCV7Da6qrhqGlexKqozLshL6kqa3af26Yg29iS+sMIM2uWDIzDAirMaVc46K8AKdhH0eVqWXfX5fZ3aHiGEEKJTuWuh5DvY9RnsKzDGRFXth6pCsNjBZIHqA8a6ZjsMmgFTf20EVXHp3dnyNpMAq4fz+7URzCuF1pqimiLMyozNE0tJTWnUbQqLSlFaYSoxsW2LUQ1OoUh1pFBFJX6fH5PZ2J/HFdlv32I1kZKQhMNsZ39pMZZYhbvWhz8QKCXaEvCZvMTGOvBqDxXlNaDAFmvGVePFHmfBWW1cYNqSrPg9fhyBDO7+HfvAXkWqI5V9xUX40dgcZpRNgcOMq6g+ILGb7dhNVpw+Fw5LDJVuY+LO5JR0ar3VOEtrAagpqmTn9zuw2M24nD6INWPyamwWFWoHAGaFLdWGyaLQ1V5cVcZzhf4SkmszcShwaijdXoZdQfVBJ87iGkqry3G5jaDDvddNv5p++LWH3Tt2Rrx2thgzfq/GVevF5PWjgKIfitm314qz2ovFasIWYyYtLp1i70GcxS6S4xOIscRQ5iwn0Z5Ataua+Ng43H43FmUh1hpDad1BaqpcWG0mLA4TymUlVsVS5anG5WscwDniLCSqZIqrS0MZzD7pmYHfoR+LzUy5uwy3s/7i3+YwG4GwAlVYH2Dt+m4XOr4+wLIoM/G2BMpd5VhsJkwmZezHbgK/Bo/Goswk2BIpM1WC20+iJZ6kpDj2FhWGft/R3neHolCkxKdSrivx44daHxaMY1W4Kkh2JFGjqvB5/Th0DD7tp84X6KdtNRn1VAPHTC5LoV9NPw5uP8g2W1i1xBgzFrsJkxncpUYWymRSWGPMoYBbxZixp1hwVXjRLj94o4zVq3JhVXCwrIzynfFUOCvxxQJOv/E6hXF73STWJOKxuzm4t5TdKTtRSkX8fgDMSRaSzXHUeTW1vhqji6wCaurXMyVYsILx3raawKqw2E0k++Ooqq7DZfEYy2u84DCDy4/ya+wJFvxejbvOR7wlLvTa2eMseJ0+zHYTPrcfX/BcbSYc8WaUV5OR0RuLRb5mhBDiqOKqgv3fwPaP4IcPYO+a+gITCX0guR/0GgnHngxep1HNL3UAZA6HgdPB3vHjn7ua6mmFDsaOHatXr17d3c04LGitefzKD8mZ2Zdp5w/h+U3PU/inZOy+mENu28vmY0Jsx2SL2sofeO+ZWtBH1qs1lhast8/tx6U1A+3mqNt8WeMlP8aMzdR4X6uqvMSY4IS4+gvCg14/hR7NsJjI/bW0PW05n/bu+3Dj0xpF5O/5cDrHaO1rq4NeP5V+HwNsVvxaN7lPrTU+aPH7yYUHO9Ymnw9uv9ftJ8YECWbFdpefIWHjvMKP4dMac4PjOf2ajXU+xsRZoj7fUn6t8SuNBRMxNxxPWlr7CnMopdZorce2ayddKNp31KZNmxg2bFg3tUiItpH3rWiR2oOwf139vwPfQOn3xnPKBH1GGxmpzGHQfwIk9W12dz1NU99RcmuxBwt2NVr/4R6mnT+ErWVbyfBNA8CnfPyQ8wljezW+Lqn92k5KtQ2tNVsG1IGCTaWbiKtOJaOmX8S69n5eTAnGXQftVji/j36R5zjezQHnfsqqKhh4MLfZdptiNJkORW+X8fbb6vRR7dfY+3tx7TKWec0uYtIt+Aot5MWasShFmfJTeIyTak8135d9H7HPjNh0hlX2wmKCOpMTvL2wKIXT6mdThR+FIj/WTN9jfNhKLOx0+Sm3+7AP8GDzKAbtjSHOBPGBzN16i4e+cYrEagv+TD8cNC6GvSaNxa+wKEW5V7Pd7cN6XB0Wq3Eha69JoHynkTmy9/ViSvTjKTTjLTWeP5ixnVk1x2FRilKvn11uP8oM2gd+RxVjTClYlKLI62ev+9BZnDprFTG+BPAD2bWwNxZX/xJ21G7j+NTjibHUB9ueA2a8B4127MvczOD0QZT/4Mbuikej2ZO8hX7lQwGw9vJhSfPhLTPh2R/5MZFkVgyyG/vZll2H22rkwtYVFQCQSR9SSowP0N5JkOUxtt+Z5eTzyq8Z6x7EYG8vAL521YHPis/kJSYL3PuMdW19vZgTW57F2lWyjdnVI0OPfUrz79gvQnNHpdVmk15rzO+zM2UjTnMNg5MH08uXRP9C40ZDYaqbL3zfUuupJcWRwjGJ9RVIMg9aSa2sf+8XWb2UZrlxbjEqTJrjNH0TIKHCQqrFWM+kFDt7O6mzR55H8P1mAXbpasxWD9neFAA2H1NrZJ4CTC7FkP0x2LGG3i9Q//sB6LffTpzL+H3EWD2kKqMyZWovP3V1sLOPi34H7MQ5zfi0ZqfFyyBf/bnU+jU7TWUMM6XS+xgflFhCwdU3Hg+mdB+eAxY8SdVss3wLwBBXHqoqsgKm41g3yS4LvUttmFCU9XORFtvz70IKIYTAKDxRvAUOrIddn8LOT6G21KjgF5Tc3xgzlXsB9M41SqHHpnZfm7uRBFg9WMMxPMV1xWQEfq61VtJrjJ2Lx5/RaLv3azbh+LoIF4qTrjRK1f797eep3WBjZtmFEeuec854eg1MBMBV6+HJ6z+O2pYrr5zN85v/wTOfP8flBx4MLbc4TNjtloixUAOGppOaFQNfGv1td7n9VPuhvz2DXe6DANQl1zBvzhTee3IjI2JMWJTClBHPST+bzrel33LHm3dHHP+q/Kuo+KqGAT+k4jfVTxyXeEwqu1YXA5rcBAvHWFPxUMNej5+kEZmc9JOR+Crd7P/tF1iUwqEUTg1xI/oyMDuOire309uWhAejtL0jI47S0iKSvPGU+/zs8Hj5+c/nhCbb3LG+hG8e+waAs88ZR9agJNa9v5tPXjbmjtpxwndM+2gAVm2lymxil9tH9vEp7N1SBn47YwLXo+U2za7qQ2eXvT4bmb1iObivhix7Bgfc1awc/DKbKzfx/rnvR5T1Xv32Dr74zzYA1o9dz//70ZU89OA/iN0WR5WtjOW9/80FRbcCcPLskQw5IYttBcW8/cT6iGMmm2FQ4Np6yhUnYrIbHyO/+edvOeg8yIKky6l6xwhmBh/bCzYZv9PxP57C7R/8Fv/OiQwuPQWN5htKSHZn4Yyr4ZwzpvLmH9cBcNZZJ9D72ORDnn/Qz9++ktkf1QdYtpQY3h20gn01+wAYfmAy08rPA+C5vi9Sa6vkX2f8i0HuvhQ+shaAYXNy+Vvxv/l478csHL6Qy0+oL+NcuXI3le/sCD2OG5xJ3sXDeOKqlQAMGp7BwGEpjSZgHn/xVCypkZlif52Xffd8BsAm6x7iUl1kF6VgirOG/h6D6qrdFN33OWalOOjV7HIb74npU4cxcprxGpe+sIm6b4xxfzGqfqBvliMJS28Hxy0aQemLm6lbV4zTD/YhWbCpvvtwlU/zZcIGhtVMC/19ACibiZqkBHw+Tamrmsz8GJ6t+gcA95tnsOuTmoi2XvH/TsL7fTmlzxlB2PHzxmOLiW34qxLdJD4+PqLcOcCWLVv4f//v/1FeXo7L5WLq1KmcffbZ3HTTTQB8//33ZGdnExMTQ25uLpdddhkzZ87kySef5PLLLwfg66+/ZvTo0Tz00EP8+te/Du175cqV3HLLLXz22WehZV6vl+zsbAoKCujdu3ejNq5cuZIlS5bw5ptvtmi5EKKT1ZXDrs9h5/9g63+heJOx3BoHA6YYGamUgdA7z/h3lAZT0UiA1YPVVDQIsMLKr9dZK+nXxJw5cUk2rCbwmOtvlWfEZPCtbVfjdZPr54CyxUR/uwTH22TEZuAxR7bJ5rAQk2CLCLDikmzY0+ozK87ADf6yA7WhZWa7Ii7JuIr3arAoMCcabQkWIQiXGZuJOUERox3EuOsvaC1J9XfZdYwFz/6awDE1fQLPqUA2xqLAYTKei0u2hY7nOVB/IWlOtFFb6SLJG28MmVH+UHBlvF72Rj/HJtW/hukpKXiUF6u2oh0WqPCQ0T/BCLC89VkFlWSFg4cugmHx2UgOBFg1xR7qLNVsrtyESZlIdUR+0MWFvRbp8cZzjkTjd1pnraTWVtFo3WjzdHnDuhUHgyuAZHsyB50HSU5IDNWnNMXXn7sp0UaKI4VSS+A4Ctwm4xyVVUe0r7Xzg6UkRJ6rOcFGemx6KMAKP7c6q3GRmRmbidlR3z5zoo30amMwbcP3mDnBFvHYlurAbDZhtpjwef1YHebQ+6W57QBUWLe9cnM19kCXVFNc478ve4wFP2Cm/u8EjHFx9e2uf61iwroRegtrsR9j3BwxB96DTq0j/vYI7LfQVgI1hP4+AJTNTFyyne3rjOAtNS0Rqozn0tIS2U1kgGW1m9Fhr4GKb3zu4vByzTXXcN111zFv3jwA1q9fT05OTmiOqBkzZrBkyRLGjjV6QqxcuZKcnBz++c9/hgKsZcuWkZeX12jf06ZNY8+ePezYsYMBAwYAsGLFCkaOHBk1uBJCdDO/3yhEsedLoxDFni/hwAZAg9kGfcfBab+HYyZD6mCwyGd8cw6/uoaixWrKIyvkBcuvA/hMPjJiMhpuAhgXzzEmhSdsHFJmbCa11opG68aEXzA1MSbD6jAuDDNjGgd0docFU4PxTnHJdmJ71d/ZDpaaqDpYX97c5rBEBHcA1pTARX+UACsjJgN7cuO75eYmLvicuj6IUDbjz8AIsIwMVmySHVOUC2ZTrDVUHMIZZfxieJAQGwwIw4KFjLj634k7MOdXYpoDR3xk18vYjMbn2JTkwGtZddCFy2Fc9KY50rCYIi/Yw1/PYGYrLtkIRn0mH25z/esfCrCSogVY0dthCmRP0hJS6peFvYYmmxmzMnMw9D5TuAMBucVuimhfeFDaEg0n4FU2EzZT/T5qbJWhn7UKFLOwJ6PCbhqYE22h95bdHHneDYMnR4YRpATnsrLZzVHfL8ra+CM2/O+ozFKJJ1YHn2i0rilsXrjw91vwby5a2yK2DwR45gTjfHwaYjMiM2pOrTngOBB1+/D3blZ6fSWn9LTkqOuHt8XVw8b3Ho32799P37714yFycnIOuU3//v1xOp0UFhaiteadd97hlFNOabSeyWTi3HPP5Z///Gdo2bJly1iwYAFffvklkyZNYtSoUUyaNIktW7a0qf0vvvgiOTk5jBw5MpR18/l8LFq0iJEjR5KTk8Mf/vAHAJYuXcrw4cPJzc3lggsuaNPxhDii+H1G8Yn/LYUXLoAHB8Lj4+H1X8D6lyEmBWbcDJe8CTfvgkuXwwk/McZSSXB1SJLB6sHCM1h1TicHnQcjns+IbSLASraDgoNhgY/NbKPG1jjAasnEv7ZABqjhRS4ELgQDF1r2WAuuWi8xCTbis+OpDVvPYjXh9YRV3XOYG13cB++8x1oaB1KZsZk4U8uAQHW3eCv+ag+msAtoS5IN/4Ea/Ao8uj7gUEqh7GYsLh8xCg76Nb2S7REXi5ZesXgLayOOWRdliFBMWKBkthivXXx4gBUW9HoCL21csp24ZDvO6vqujfGZiUDk77MpKVmB10ODP8YVej0aCn89k+xG6fmU1HjqggvDru9D2bfExmPumgqwgjKSUinBGB9kiRKglVrKQ4fzBII6q8OMI67+WMExbS2VZEtq8rlURyo17vJGyxveMAgPsOq8dZHPNTiPmEBQa3OYcVZ7sDoszQY6TSm1VNDL0XyxGRX4xURksOzhGSzjuNEKUwSfC29bXLIjYgY8tx/2xuwNPbb2jgtlssIDrD5Z9e+phJTohXTCM5a1HTiv3RHl7ZuNMQwdKSsHTlnc6s2uu+46TjzxRCZNmsTs2bO59NJLSU5OPuR255xzDi+//DKjRo1i9OjR2O3RM84LFizgiiuu4KabbsLlcvHWW2/xhz/8AbPZzKpVq7BYLKxYsYJbb72Vf//7361q+759+7jppptYs2YNKSkpzJ49m9dee41+/fqxd+9eNmzYAEB5eTkAixcvZvv27djt9tAyIY46fp8x19TW92DdMqgI9FxKHQzDzoD+E6HfOOPxYTi3VE8iAdZh4KDzIB/t/giNJis2C42OyEaF87vBW2xGexTVX9tJNtuo8Wuef/t1ji0ZHbFuhi0d5w/lOAYnRyy3281ok8Ld4GLMZYkMIFrKEsgARQvobA4z7jojRxUMsEwmha1B16nYZDuVxfUXtSYbWBrMsRSbZVz8hhduCMqMzaQizQQYd+LNiTb8YQELgC0tBidlocxd+P5NdjPpFhM2k8LpNzJ3EQFWiqNRgOWOEmioKNUJw7MxNnP9z8HX3xFvJS7JTume+vERllZ0kUvpVZ/tMsUbV+FmfxJ+v47IHkbrdpeWlMw+KhsttwYu4E1RAuzGM4BFykhKYxPGnE22KEFHMMDSEMqaOWJsTWZI2yvOGkeZde8h11NWM/FWYxBcjSey+1vD4Cm+j7FeMIi2xUTvIngoJdaD1NqSD9Ew4z8dZ4FKT+B49R/dwSyZ0w9xDeJSc4NusGC8DyJH4kCVrdxI4Xo11uz4+gArLLBMDMsQB29OmEwqNEUDgArrdrz6rR3MvnxEo79jcfi49NJLmTNnDu+88w7/+c9/+POf/8y6deuaDJiCzjvvPM4//3w2b97MggUL+PTTT6Oud8IJJ1BdXc2WLVvYtGkTEyZMICUlhd27d3PJJZewdetWlFJ4PJ6o2zfnq6++YsaMGWRkGN87F110EatWreKOO+5g27Zt/OIXv+C0005j9uzZAOTm5nLRRRcxf/585s+f3+rjCdEjBSfvPfAN7FkN2z6EujJAwaDpMOsOGDgNErK6u6VHHAmwDgN/3/h3/rbhby1ad9bWizmupL4y4CnJFip9mg/fTeckLgkt35z5OUlfTKXk4/Vk/DwPe//E0HMJcRYqgfQhyaFlU7On8tSGpwA4JieNwu2VxKc0/pLNGu3gwFrjojimn6ZutyJ4BRjsVlVz7F7ivjcG4FvtZo4dk0nRzi2M+dEAPvzHZnoNMtri15rSQDokvkGA1SvZ+NI0W0xsc/kZHmMmtrcRSIRfiA9LHcamg5tItidjy7JSzF5j/qNpfTm4bAv2QUnkn9SPghW7iemXgBOwZMRAqZu07PoKZ8puJilwcVjp1ySkOjDZLZjirPhrPMSOzsS5+SCxuRnU2r+DL43qa+ZR5Y1eo9hEGzEJjbMxx0/IYkhqPM+nPsbFJaczeHJvdi/bSlJGDGnZcezaWMp2l4+BdjO2eCue2Fqq/VX0SkmnusiDqV8dlh0pkQdTkNK7/sI3McX4+autdp75dAeXTRkYes4ea/y5r89axS+yzgVg8DH9WM9GNmd+DsDexO/oWz0k4hD2WAtJGTF4PX5cNR5S+8TB/mpix/SKWO/cIefywJcP0Dc5G4IBVowFN2AfYrT7nOPO4belvwXgOe3CZDNe8+T4BCAwPi+ucdbsUE7ofQKvp7zC3LIZAMSO7sX8hPmsLlzNT3J+wl2f3mWc7+hMYiwxDE0dGtrWNjAR925jcNGEPhNgDUzOnhyx//AABcDiiPzotNotxng0hxkCc1Q5hjY92Heny88xdhM1llpOOH4ifAbx46OPS9lnM9Pf7SM2M5ayyorA8erbY+1tvI+/c/nIizVjCktFWgNdGb/zeUgDdrv9jEyy4T4mEfdOI7Au8fnRSmPLTsC9sxLHkBRqVxcSPzkbcx/jb67c5MdsNhFvjWdQ0qBQ4DX2tAF8+cZ2RgQKboAxxqysxsv2dSV4XD4JsBpqQ6apM/Xp04fLLruMyy67jJEjR7JhwwbGjBnT7DZZWVlYrVb++9//8uijjzYZYAFccMEFLFu2jE2bNrFgwQIA7rjjDmbOnMmrr77Kjh07mDFjRqvb3dQUMykpKaxbt453332Xxx57jJdeeomnnnqK5cuXs2rVKl5//XXuu+8+Nm7cKHO0iSOPuxYKN8Km1+H7FVC8OWz+qd4w5BQ4dhYMPlEKUnQy+XQ5DOyr2UefuD5cnnM5931+HwB3TryTqdlTG63734d+oBKjG9io+b1g5UESzZF3/vNP6scVZ/0fFf8wKtf5KyPHasXYzFQCfXPqx1SMzRrL2ovXYr7YgqJ+ntKGRp2XxXzbmSgND/X+K1t3VwfWNnx98dcoFF+/t4svXtuOUorhU/owdFJvzGYTx0/MCnU7zL5/CtlAnoL3/rYx4jjBAOuKpdONL1KfxhzlQu3uSXczJGUISiniYuOx3jkBM2bMsVZictJRZhOTzo5n4pmDMZlNOI5NxhRr4WdEdn8MXkA7RqYxf8HQ0HNZN52A9vgxx1mJGZGGMpuYNux0vGd4uAQTFnPjNl2yeHKj1+7Kx2YYXRFNil9ddx9WrGSbYOjUbMxmExPnDyZ3Zj+eveV/rK/zMzfGypUPzqbcWU5mbAYevxeLMuP1+/C6/GiTn0pnFWkxqdgcFsxWEz6Pn5lDp4B+mt9v2s8PxZF5CqUUVz42Ay9TQpm07KxeXPQHO5eYx6GUwuvzkmBLjNjusiVTQ+8JMN4XDbNjAAuGLuDc48/FaqoPkKx2Mxm/nRJ6fN7x53HWkLO44Z/reW1dJXekz8K5r5KMZOO9uPCByMCmpUakjeC4Xx+HFSugUWYT85jHqYNOxWqycsbgMzD/2IxSipP5LCJIz/hp/bQCQ1OHsvbitRHnEHztsu+fgtbamHS5gWDRiT63jsfn8mKJaz6bVVDnY12djz9f9jj9hqSj7/dDlOwnwIEEGwU/VDJ0eCx7vw8EWGFFLiypDvr8ZhK9tAaPD7MyG/vy+THFGuexw+PlLF3Jj8ZnMc9hIeP/Gef8bdFGHnrnosDrkIO/zos5wUbMiHQwQaJS/CmxDo+CX3l8fHLBJyilMCmT8Z42Kcb86JiIzG2fOyeS5vRyjNPXpmBZdJ133nmHWbNmYbVaOXDgAKWlpWRnZx96Q+Dee++lqKgooshPNAsWLGDevHlUVFTwt78ZNxIrKipCx3nmmWfa1Pbx48dz7bXXUlJSQkpKCi+++CK/+MUvKCkpwWazcfbZZzN48GAWLVqE3+9n9+7dzJw5kylTpvDCCy9QXV3dou6QQhz2Cr+FgudhxydGpkr7wWQxMlNDTzdKpfcZBfHRh42IziEB1mGguLaYrLgsjks5LrTsuOTjyIprnLKNjd0TCrAGZPfCH2WcjsVuxmqyhrrrNLwg9LuMO+ymBnflwy8qm+qsFW+LRys/WkFqYjI06GwULKwQE3aBqZTCHGhLeFAT7F4FkYP2IayLmimQIWviOzzeGh9RzMEWNnmyChxLKRV6LYJV3RruLriuLTs+oo0mmxkCgV1wHZPJhM3UdBeahoEHRHa1C+8mGHxdlEmFMoYa44LdbrHRK94Y92IL/G5sZhO2wK8pLra+q6TNYabO4ycu2UFMRSoQvYupyWzCRuTFf3JMcv2DKNfDwfMJPytzlHNUSmFVkTuwOSwRF9/BdXQgwNGBi7PgeyHaa9dS9a9rWAYn8LqFv7fNDX77Dbt1NgyuQuuZVWg8VEPBgMdkMxvvmRbQQExsoAtfM2MdbTFWNJFdPG0N/l5MFrNRscgavry+HdUuLz4FcYHtguccH5sQKvqhLKbQ30d4V7+6QNMKK50ckxbWHTX499XgBo8yKRyxVhyxElwdTmprayMKWlx//fXs2bOHa6+9FkdgHOBDDz1EVlbLugpNmjSpResNHz6c2NhYxowZQ1yc8f658cYbueSSS3j44Yc58cQTW7Sf999/P6L9L7/8Mg888AAzZ85Ea82pp57KvHnzWLduHZdeeil+v/G+fuCBB/D5fPz4xz+moqICrTXXXXedBFeiZ6suMsZRrX0Odn8OZrsRSE39lTEP1TGTIS6tu1t5VJMA6zBQVFvE8LThEQUQohUpgMgLq9gYc6OxFFB/0R66FmwQYOlAgKUcrf/1B4sAKBSpCUnAnqjrhd9hbwlbwy5YUaqvRRNr7Zh5doKvSbDaWnez2lv3+lntZuqqPMQn2yneYwTgLm/LJ+rtLE29D7yB92SNy3tEfAjZ7G07C2sLtgu+huEBVnDcY0uV1xpjXOIaHC9aRc6mHKiIDLBEzxIMOBp6+OGHm9xm5cqVEY9nzJgRtTvf3Xff3eyx161bF/F44sSJfPfdd6HH9913X7P7nzFjBnV1dY2WT5w4kQsvjJy7MS8vj7Vr1zZa95NPPmm2jUIc1ty1xuS+P3wI21ZCoVHEhbRj4aR7YPRC6fJ3mDkSrm16NK01xXXFZMZmRhSJaKrEuiXswttuix5ghe4sm5rKYBllChpmsFoiWGAi1ZFKTGzTFcKCWaCm+sk3FLoQD/VPbFkmozUXiM0JviZtKVTQGRpmKA4lmAGMTbJRWGmMkQv+352sTWRzSqqMILDa6SO5C9vTWVp7QyHI1oLtgjcf4pIis8KtURx4vf0NPguiVeQM5w4L0gurDj0vmxBCiA7iroEN/zZKpu/6HHxuYz6q/hNg1l0waIbR9a+TCkSJ9pEAq5tVeaqo89aRGZsZMfeO1Ry9e40v7ILH5Ku/WAoUADOWBzNYwa5PDW5chjJYbRh8blIm4qxxZMZmtjjL1BLBgCIuyU5Necsv5BzmjikDHcpgtXL+pc7S6gygw4wyKWISbBRWGq9fUWX3XxBHq6oI9cFftct7ZARYbbhZAS0LpK2BioGtnXw53IGK4Ovti1gerSJnuKKq+iC9sKL7A3YhhDiiaW2Mo1r7HHzzT3BVQvoQGP//jICq/ySwdUzPHdG5JMDqBit3r2T5tuWMTB/JF/u/AJruEhhUtLOSr/+7i53rS0PL/GEXS8MdJr4JTMwUGu8TuLit+ngP1t5xuHZU4N5RifO7MqBxZbSWirMYAVaTA7Ug9FxL77TbwrpBtSbA6qjS3v5QF8HIAOuxD7/n232VHNcrnsJKJ5V1hypS3nIWs2JknyQKdpeHlg0P/H/dv9a16q5Uv9IaHBa45ZX17Cg1SmxvKazir6u2sX5vBb4ohRkOZUivBA5U1jV5zrE2M8dnJWAxKdbsKo/IjgTP44aX13HHGcMpqnTyzoYDlNa4Kap0sbfc6O6zv6KOvph5b+MB/lFTQd/UGDxe3eHZt3i7hb4pMWw+UMXA9Dgq6jzYLSaUgn3lzR8rp28SWw5URWRzggZXOLEDv1m+CXfDGunNCL4+17xU0OQ6MTYzA9PjKP6uiAxg8cqtDA48d9XzjbtANeerHcZYzX+v3YPT44u6TrR9VtTVl89e9tUuCnaXk98vmQ37KvAGbvAoBT+ZOoi1O8tYs7MsYvvFZ+eQ4JCxWEII0aTqIqPi3/518N07ULbDGFM1Yj6MvQz6jZcsVQ8kAVY3+Memf/DF/i94Z8c7WE1WhqcNJzfDqOr1qzG/iho0bPn8AN+vLgo9nnjWYLSr/sK3ny08wKovnADgLayl6I9foxwWY5tgpquNAdbcY+cyKGkQqb3j6D88lXFzBzVap9+wVLKHJDNhfuPnoulzXAoD89KZeOZgPvzHZo4d03zAuXjqYlYXrm5T+6NJv3QkNV/uR4XNL+T1+fn9e1vQgA7MC5qdHENMB5Sd1lrzQ3EN/ynYR4zVTHZg4taKPib6Vmm2FEXr/Nk0p82PVWveWb0bgEHpcWwrqeH+tzYBcGxmfHObN3Kwxs3y9fuB6Ofs8vrYfbB+TIRSMDij/hjOXoq4Os3ra/bwo5FZ3P7aBvYHMiBZiQ4GpcczvE8i3+0sp8Tn5yurh8IddSxfbwTXvRLtHXZh7vT42FNWF2pnw16rmQl2EmOiH+tAhTP0OgxKj2tUhKMoHYaWwoaqGnR1y78Aq3qb6F2t2VJYFfV5t9fProPGvGtDzFZGx1t45dsDjI4xk6TM7G5iu6akxNkorTGqiX70XTFZSfWZ35i4yVg9x7LFHX2fef2S6Z3o4Pviaj7YXBR6PYLvqR0lNSTHWnm9YB8mkyI9vj7T1pbAXgghjmiuatj5P2Ms1e4vYd9ao/KfJQaOmQRTroNhc2VMVQ8nAVY3KK4tDv2cl5HH0z96OvR40chFUbepqajP6hx3Qi9Gzz6G6i+NC51dbj/9rPUXd426CAZopxdLr9jQhLnK0rYufteOvjb08xnX5Eddx+awMP/60VGfiya1TxynXmkEmWf9uvk5WABOG3Qapw06rcX7PxTHsck4jk2OWFZS7cav4bjMeLYGAp6/LRrL0KzEKHtovZy73qXK5eXEoZk8dlHLX6umbCuu5p3ffwTA+Sf0Y83OMt77tpDUOBsrrp/eqn099cl27n3zWwCevvQEhvRKiHh+b3kdkxd/EHqcnRzT6Bj7K+p4/YEPKKx0cbCmfqqAJefmMeW4dBp6a/1+fh7Iojx4Th7Th3RMSdltxdWcGHhdjsuM57vCyOD1/jNzOHl4r2ibcuur63nhi10oBe9eNw1rM9X+OlJRpZNxv30fgB/NGMD1Jw9h+V3vslZ5OS0nkxVteL9c/Lcv+HhrCWfk9eaBs3LDnmn5e+PKf6zh7Q0HSIqxhn7fP3pkFTtLa6l0erlhzvFcNfPYVrdNCCGOaH6fMcnv18/D5uXgcxkBVfZomPprGD4PMoeBSeYNPFJIgNUNimrrM1HhhS2aE95tLtidLjhuyOnXKGXCDPioL3kdbfyLLTs+FGCJ5gW7qeX2TQ4FWL0SOmbMF0Bmop2qYi+ZiR1TubBXoiPi5+DjzDZURozYV5RzzoiP3Gf4+kHp8XaUggMNuvv1auJ8w5c3tU5bhLctJzu5UYDV3LGC555gt3RZcAWQFt/4tWjv+8VuMT43MtvxHg6+luGvWWaig2/2lEc8L4QQR73qYlj7DOz8FPZ9DXVlEJNiVPwbehr0nwhW+cw8UnXdFYMAoNZTS7Wn/gIvM6b5rnBBNeX1GYDgGKv6AMtYbgkmrprIYAHY+iU0WiaiCwZYef2SQsuSO3Bun/hAyeysDrooDS/B3SvREeoG1pY2h19AJ8Y0vg9ja5D9jBbEWc0m0uPtFDUIsDKbON/wi/OOek0g8nUJ/11GO25DWUnGebVnfq62CJ9nLPhatPf9Ehx71Z4gKBjcJYZ13+yVYA+Vge/IwFh0LLPZTH5+PiNHjuSMM86gvLwcgB07dqCU4o9//GNo3auvvjo0AfCiRYvIzs7G5TJu8pWUlDBgwICIfZeWlpKfn09+fj5ZWVlkZ2eHHrvdkRPdR7N69WquueaaVp3PgAEDKCkpadU2QnSJ8l3w1g3wSA58cL8RaA09Dc59Fn61BU5bAoNnSnB1hJMAq4sV1xndA4OTmbYkg6W1pqbChSPO2MbjNMZe+V0+lNWEJzCopHGA1Xhftr4SYLVUeAYrqKOKaoTrjLv+vRLtbcpc1W8fNmFzC865qexOr0Q7ByqdhI/ESWyicl54ZiWpiTFR7RX+uwxKj2/6dWoqGOxKDd8fbX2/VAXGbAaDxraIFtyFj+fqyMBYdKyYmBgKCgrYsGEDqampPPbYY6HnMjMzefTRR5sMhsxmM0899VST+05LS6OgoICCggJ+9rOfcd1114Ue22xG4SCvt+kCQWPHjmXp0qVtPDMhDhNFm+HVn8HSUbD6acg5G676Eq78BOY9ZhStsMhNqKOFBFhdLNg9MFg1sCVlxp3VHvw+TUpvozSn22ncidYuH8puDpVnrw+wmu4iaElvviyzqFdY6cJsUgzN6qSgNBC4tCcQakqvRAfp7dhva7uhNRWDZSU62F5SE1GBr6mALTwr1hmBLBhjsBoyN5OdOhwChlBA1c73S00gwGpPF8FgMBr+6wkPQg+HgFQc2sSJE9m7d2/ocUZGBrNmzeLZZ5+Nuv4vf/lL/vCHPzQbJEWzaNEirr/+embOnMlNN93El19+yaRJkxg1ahSTJk1iy5YtgDGh8emnnw4YkxZfdtllzJgxg0GDBrUq8Nq5cyezZs0iNzeXWbNmsWvXLgBefvllRo4cSV5eHtOmTQNg48aNjBs3jvz8fHJzc9m6dWurzk0ItDaCqv89Ck+dAo+Ph2//A+OugGsLjKAqY0h3t1J0ExmD1UXe2/EeS1Yv4ar8qwAYljqMvdV7ibMdeqLcYIGL9L4J7P++IjQGy+/yYbKbCX7lzUiw8mGlB3MzXQRVGydEPRys3VXGT59dHbVcdmdwen1kxNtxWDvnNeud6GAddEoZ6zi7JZQpakvGIzhepzlmkwpViWsqC9Qr0cGKTUVRn+sO4d0FWyIYzPRN6fobE7E2M7VuH2lxRgagve+X1FhjP2nxbZ/rLSHKeyo8CG0qOynq/e7L37H54OYO3efQ1KHcNO6mFq3r8/l4//33ufzyyyOW33zzzZxyyilcdtlljbbp378/U6ZM4bnnnuOMM85oVdu+++47VqxYgdlsprKyklWrVmGxWFixYgW33nor//73vxtts3nzZj788EOqqqo4/vjjufLKK7FaD/2+v/rqq1m4cCGXXHIJTz31FNdccw2vvfYa9957L++++y7Z2dmhrpFPPPEE1157LRdddBFutxufL/r0BUJEOLgNtq6Are8ZFQBdFcbyrByYeRuMvRzi0rq3jeKwIN+GXeSez+6h0l3JhpINANw24TbG9BrDKQNOOeS21WVGgHXcCb1IyYplyDij4pm/yo0p3saJl4/A9U/jTmBfm6m+i2AYa3Y88ZP7oJQi/fKRbZ4Dqztt3FdJaY2bBeP6E9NJQU9DYwekAPDkwrH0Se7Yi+zFZ+cw+bh0RmZ3TFVCgPeum8b2EmMerNH9U7h33gjm5We3aV9/XTi22cDi3V9OY/OBSoqrXJx/Qr+o61wyaQAOqxmbxURudtIhM2Mv/HQ8tk4oJhH+ujx72TiSY6y4vH78DWu2N5AWb+fBc3KZdlzHVDRsjTd/MYVv91eGxn+19/3ypwtHsXJLMb2T2v4+zu+XzH3zRjA3r/49NfnYNK6eeSyDMuI6LfMo2q+uro78/Hx27NjBmDFjOPnkkyOeHzhwIOPGjeOFF16Iuv2tt97K3LlzOe201lVvPffcczGbjc/riooKLrnkErZu3YpSCo/HE3Wb0047Dbvdjt1uJzMzk8LCQvr27XvIY3322We88sorAFx88cXceOONAEyePJlFixZx3nnncdZZZwFGFu/+++9nz549nHXWWRx33HGtOi9xlNn5GXx4P+z42HicOhhGnmVUARx8IiQd+v0pji4SYHWR4IXHt6XfEmOJIc2Rxo+H/7hF29ZWGP3i45Jt9B5c/0fsq3JjzYojMTuewsAylw6baDgs0ZN06kAcg5MBcByX0q5z6S7BLk53nD6MWFvXvnVPaqKMd3skx9q4eMIxHbrPIb0SQiXVlVIsnDigzftqqnR50LGZ8YecX2tIrwTuOH14s+uEmzS4cfn2jhD+urS2/Pt5Y6MHj51tUEY8g8LmFmvv+yUz0cF5TQTCLaWU4uIG76lYm4Vfzzm+Xfs9mrQ009TRgmOwKioqOP3003nssccaFZa49dZbOeecc0Ld6MIde+yx5Ofn89JLL7XquHFx9b007rjjDmbOnMmrr77Kjh07mDFjRtRt7Pb6GzFms7nVXRODgt+7TzzxBF988QXLly8nPz+fgoICLrzwQsaPH8/y5cuZM2cOTz75JCeeeGKbjiOOYLu+gJUPGCXW4zLhpHtg2BmQNvjQ24qjmgRYXWxj6Ub6JfRr1Z3eYBfBuAaD030VbhxDUiImDHb5dSiDpcPuzitrzx9uV+PyYlJ0WfZKCCGONElJSSxdupR58+Zx5ZVXRjw3dOhQhg8fzptvvsm4ceMabXvbbbe1OoMVrqKiguxsI/sZrFLYkSZNmsSyZcu4+OKLef7555kyZQoAP/zwA+PHj2f8+PG88cYb7N69m4qKCgYNGsQ111zDtm3b+OabbyTAOtppDXu+gt1fwP51xr+S7yA2DU6+D074Cdhiu7uVooeQAKuL+bSvxXNfBVWXu4hJsIbmtwLwu7xotw9zoi1iXJWmfh4s/OEBVs8PSqpdXuJsFumGJIQQ7TBq1Cjy8vJYtmwZU6dOjXjutttuY9SoUVG3GzFiBKNHj2bt2rVtOu6NN97IJZdcwsMPP9whwUxubi4mk/F9d95557F06VIuu+wyHnroITIyMnj66acBuOGGG9i6dStaa2bNmkVeXh6LFy/mH//4B1arlaysLO688852t0f0ULUHoeAFWPM0lH5vLEvMht55MPYyY96qFoyXFyKc0ocYg3C4GTt2rF69enV3N6PVxj0/jjpvHQCnDTqNxVMXt3jb5Y+to7rcxfm31d9R9BTVUvjwGlLPP56YvAz23voJAGtqvEy5+QTSsuMpf+MHqv+3D4Bevx6LtYdXELzxX+tY9V0Jn986q7ubIoToIkqpNVrrsd3djpaK9h21adMmhg0b1k0tEqJtjvj3rd9vBFUr7jGKVfQbD2MuhWNnQXzL5igVoqnvKMlgdYEaT00ouIKWTy4M4HX72LOljOwhxrgp7dd49lXj3l0FgCnRFlGOXRE2D1ZY7KwsPb+LYLXLS1wPLM4hhBBCiG7k84KnBsp2wI5PoGgT7FkNxZtg4DSY81ujEqAQHUQCrC4QnPsqqG9Cy6vNfP6fbXjdfhID2afaNYWU/bt+vg5LSmQJbqXqAyztP7LGYFW7fMS3ssy2EEIIIY5Sfj988094/x6o2l+/PDYdMofB5Ccg74KmJ3MUoo3karULBAOsxVMXkxaTxujM0S3etqKoFoDx8wYB4Ks0KgqmLRqBOc6KJdUIsDJ+nkfx4+uAsCqCR2CRi3iZZ0cIIYQQh7LrC3jnZti3FrLHwISfG2Ophp4OCR1fGViIcHK12gWCAdaItBEMSBrQqm2ry10cMzINe4zxq/K7fGAxETM0NWI9S7JRYVCh6rsIhpVpPxK6CNa4vKTFSQUfIYQQQjTh4Db44H7Y8C9I6A1n/hlyzgNTz78OEj2HBFhdoLiuGIDM2NYPmqypcJN5TP3EotrlxeSIMg4pkN5WgDmQwYroImjq+envapdXuggKIYQQIpLPC5vfhC//Cjs/AYsDpt0Ak38J9ubnaxSiM8jVahcoqi0i3hpPrLV12Refz09dlZu4JFtomd/lQ0Ur9KDq/zNZgkUuelaFyEOpcXmJkwBLCCGEEADOCljzLHzxZ6jcA8n94cQ7IP9CSOzT3a0TRzHJl3aBotqiVs99BVBb4QYNccn1Ewxrlw+TrXGAFcxQRVQR9B9ZAVa1BFhCCNEmZrOZ/Px8Ro4cyRlnnEF5eTkAO3bsQCnFH//4x9C6V199dWgi4EWLFpGdnY3LZUx4X1JSwoABAxrtf8aMGbz77rsRyx555BF+/vOfN9mmGTNmEG3alaaWCxFSsRfeuRUeHgH/vQNSB8IFL8I1BTDt1xJciW4nAVYn8vg9/H3j3/m29NtWlWYPqqkwvtDCAyy/s4kMVjDAUvVFLo6EBNYnW0t4ZMV3PPzf7/D4NAlS5EIIIVotJiaGgoICNmzYQGpqKo899ljouczMTB599FHcbnfUbc1mM0899VSz+1+wYAHLli2LWLZs2TIWLFjQ/sYLEVS4Ed67A/44Br78Mxx/ClzxESx6E4aeCiaZykUcHiTA6kQbSzby0OqH2Fu9l/zM/FZvX1MeCLCSwjJYbh+maEFG2Bgskymyi6Alo+dOMHzX6xt4ZMVWlr6/FbNJcXyvhO5ukhBC9GgTJ05k7969occZGRnMmjWLZ599Nur6v/zlL/nDH/6A1+ttcp/nnHMOb775ZijTtWPHDvbt28eUKVO48sorGTt2LCNGjOCuu+5qU5sPHjzI/Pnzyc3NZcKECXzzzTcAfPTRR+Tn55Ofn8+oUaOoqqpi//79TJs2LZSx+/jjj9t0THEYqdgL//4J/N8k+PSPRmD1i7Vw9l+hT353t06IRiQd0ImcPicAT815ihOyTmj19jXlxt3Ehl0EVXq0LoLG/xPPHFy/0K+xZMaSdf2YVh/7cFHp9HLBCf144CxjAkAlc1UIIXqwA7/9La5Nmzt0n/ZhQ8m69dYWrevz+Xj//fe5/PLLI5bffPPNnHLKKVx22WWNtunfvz9Tpkzhueee44wzzoi637S0NMaNG8c777zDvHnzWLZsGeeffz5KKe6//35SU1Px+XzMmjWLb775htzc3Fad41133cWoUaN47bXX+OCDD1i4cCEFBQUsWbKExx57jMmTJ1NdXY3D4eAvf/kLc+bM4bbbbsPn81FbW9uqY4nDiKsKPnsc/vcI+H0w9dcw8SqITT3kpkJ0J8lgdSK3zwiQ7Gb7IdaMrqbchcmkiIm3hpb5XV5MUYtcNB53pf31gVdPVROoHKiUkuBKCCHaqK6ujvz8fNLS0jh48CAnn3xyxPMDBw5k3LhxvPDCC1G3v/XWW3nooYfw+/1Rn4fIboLh3QNfeuklRo8ezahRo9i4cSPffvttq9v/ySefcPHFFwNw4oknUlpaSkVFBZMnT+b6669n6dKllJeXY7FYOOGEE3j66ae5++67Wb9+PQkJ0vOhx3FVwce/h0dyYOVv4biT4eqvYNYdElyJHkEyWJ3I4/cAYDPbDrFmdDUVLmKTbBEl1rXTh4pS5CI4BiuisIXWPXp2cr9fU+v2SWELIcQRo6WZpo4WHINVUVHB6aefzmOPPcY111wTsc6tt97KOeecw7Rp0xptf+yxx5Kfn89LL73U5DHmz5/P9ddfz9q1a6mrq2P06NFs376dJUuW8NVXX5GSksKiRYtwOp2tbr+OMqhYKcXNN9/MaaedxltvvcWECRNYsWIF06ZNY9WqVSxfvpyLL76YG264gYULF7b6mKIbeOrgs8fgsz9BXRkcNxum3wx9e25PHHF06uH5jcObx2cEWFaT9RBrRldT7orsHujXaI+/iXmwAuuEfwf5dX3g1QPVuI3+/jL3lRBCdIykpCSWLl3KkiVL8Hg8Ec8NHTqU4cOH8+abb0bd9rbbbmPJkiVN7js+Pp4ZM2Zw2WWXhbJXlZWVxMXFkZSURGFhIW+//Xab2j1t2jSef/55AFauXEl6ejqJiYn88MMP5OTkcNNNNzF27Fg2b97Mzp07yczM5Kc//SmXX345a9eubdMxRRfSGn74AJ6YAh/cB33HwU8/gIteluBK9Ehy5dqJ3H6ji6DN1MYMVrmLlN5xocfa7QOIWkVQKWUEWeFdBDU9OsCqdhkBlmSwhBCdTSn1FHA6UKS1HhlYlgr8ExgA7ADO01qXdVcbO8qoUaPIy8tj2bJlTJ06NeK52267jVGjRkXdbsSIEYwePbrZgGXBggWcddZZoa6CeXl5jBo1ihEjRjBo0CAmT57cojaedtppWK3GzcmJEyfy5z//mUsvvZTc3FxiY2NDBTkeeeQRPvzwQ8xmM8OHD+eUU05h2bJlPPTQQ1itVuLj4/n73//eomOKbuCqgoIXjAmCS7dCUj+4+DUYPLO7WyZEu8iVaycKZbDMbctgeSrcDHSY8JY7KXvl+9DyqGXaAUyKqo/3Yu0Vi/b4cX1Xhq1/1/Q9319Rx2/f2szvzs4h1tb2t9Xe8jpueHkdOdlJnDu2LwDxUppdCNH5ngH+BIRfjd8MvK+1XqyUujnw+KZuaFu7VVdXRzx+4403Qj9v2LAh9HNeXl7EOKvgfFhBr7zySrPHOfPMMxt152u4j6CVK1e2avl//vOfRsvC5+8KuuSSS7jkkkuabafoZj4vfLzEKGDhqoDssTD/CRgxH6w9t/KxEEFy5dqJghmstnQR1FozED/x5S7KX9+G67v6m6bm2Cb2pxR4/RxctqV+WRdlsB56ZwtvrNvHzOMzOGt03zbv58vtpXz6g/HvlJzeAMQ3FVAKIUQH0VqvUkoNaLB4HjAj8POzwEp6aIAlxGGj9iC8vAi2fwTDzoBJ10K/1ldaFuJwJgFWJwpmsNpS5MLv08FhVfgCEw4HmRKj70+ZoNEw4C4qcuENdE30+ds3u3FhZf25HqgwBkLHtSMjJoQQ7dBLa70fQGu9XykVdcZ4pdQVwBVglDQXQjTh4DZ4/lwo3w3zHodRF3V3i4ToFFLkohO1J4Pl89Z30fAWR87hYU5soux7lGCqq8q0Bw9dUedpfsVDCAZVAD8UG11aZAyWEOJwprX+i9Z6rNZ6bEZGRnc3R4jD0+6v4MmToLYUFv5HgitxRJMAqxO1K4Pl1dgCUYt2R847Yk5oImCL1h2wi7oI1gYKcBRWtr78briiqsYBllQRFEJ0k0KlVG+AwP9F3dweIXoevw/+9yg8cyrYE+En78MxE7u7VUJ0Krly7UQevweLsmBqQxrJ5/XjCNvMnGQPdRVU5uj7684ugkWBwOpApesQazavsNJFdnIMe8vr2FZcA0iRCyFEt3kduARYHPi/cZUFIUR0NaXGfFZb3obiTTD0dDhjKcSldXfLhOh0cuXaidw+d5srCPq8fhxhwZElM6bRWKxGonYR7JoA60AgwNpZWtPibXx+TZ3Hh91iwmo2Uef2caDCSU52UiDAkgyWEKJrKKVexChoka6U2gPchRFYvaSUuhzYBZzbfS0UogfZ8T948QKjDHufUTD//yBvQZfd9BWiu0kXwU7k9rvbPMlwtAzWIUULprrgs8zv1xRXGcHfN3sq+OuqbS3abtHTXzLyrneZtPgDPthcyPC73mFveR2DMuJIjrVS6fRiM5uwW+RtKoToXFrrBVrr3lprq9a6r9b6b1rrUq31LK31cYH/D3Z3O9vKbDaTn59PXl4eo0eP5tNPPwVgx44dxMTEkJ+fz/Dhw1m4cGFoAuKVK1eilIoo6X766aeHyqjPmDGDsWPHhp5bvXo1M2bMiDju+vXryc/PJz8/n9TUVAYOHEh+fj4nnXRSi9r9+uuvs3jx4lada3x8fKvWFx1Ia9i83ChkkZAFV30BV3wI+RdKcCWOKpIa6EQev6fNAZbX5cOsFL6BSaQOTyNmRBrxE3qjmukuF/Wzqws+0GrcXvwaLhrfn+e/2MX3RdWH3gjYEch2FVe5+PT7UrSGW08dyvz8bCYNTmfT/koGZ8YZkygLIYRos5iYGAoKCgB49913ueWWW/joo48AGDx4MAUFBfh8Pk4++WReeuklLrrIKEDQt29f7r//fs4444yo+y0qKuLtt9/mlFNOifp8Tk5O6LiLFi3i9NNP55xzzolYx+v1YrFE/26bO3cuc+fObe3piu5QVwYvLYTtqyBjGCx8zQiyhDgKSWqgE7l97jYVuADw1XqNH1IdJEzNxpLqwNY3AWt6MxPwdVMVwRqXUeBiRJ8kBmXEUe32tmg7t9ePLTCebFtJDQl2C1dMG0xmooMpx6Xz02mDOHFor05rtxBCHI0qKytJSUlptNxsNjNu3Dj27t0bWpaXl0dSUhL//e9/o+7rhhtu4De/+U2r2zBjxgxuvfVWpk+fzqOPPsobb7zB+PHjGTVqFCeddBKFhYWAMUnx1VdfDRgB2jXXXMOkSZMYNGgQ//rXv1p8vIKCAiZMmEBubi5nnnkmZWXG3JJLly5l+PDh5ObmcsEFFwDw0UcfhbJuo0aNoqqqqtXnd1TxOOHAevjHObDrczh1CfzsYwmuxFFNMlidyOP3tDnA8tcZQYpqzSS7XTTeqqFql9GdJM5uJt5uocbVsgDL49Mkx1opqnLxQ3E1mU2VnxdCiCPExy99R8nulmX5Wyq9XzxTzxvS7Dp1dXXk5+fjdDrZv38/H3zwQaN1nE4nX3zxBY8++mjE8ttvv53bb7+dk08+udE2EydO5NVXX+XDDz8kISGhVe0uLy8PZdHKysr4/PPPUUrx5JNP8uCDD/L73/++0Tb79+/nk08+YfPmzcydO7dRNqwpCxcu5I9//CPTp0/nzjvv5J577uGRRx5h8eLFbN++HbvdTnl5OQBLlizhscceY/LkyVRXV+NwOFp1XkeVqgPw1I+gbLtxR/fcZ2G4ZByFkAxWJ/L42t5F0O80ghSTo+UBVrSCFtofZcUOVh3IYMXbLcTbLVQ7W57BSo0zAtDdB2vJSpIvMSGE6AzBLoKbN2/mnXfeYeHChWht1J394YcfyM/PJy0tjf79+5Obmxux7dSpUwH4+OOPo+779ttvb1MW6/zzzw/9vGfPHubMmUNOTg4PPfQQGzdujLrN/PnzMZlMDB8+PJTlOpSKigrKy8uZPn06AJdccgmrVq0CIDc3l4suuoh//OMfoW6KkydP5vrrr2fp0qWUl5c32X3xqOesgFeugOpCmHUX/PxzCa6ECJBPjU7UriIXLh9mwNTeEuX+RoXbO1wwYxVvtxBnt3CwpvYQWxjcXj8psUaA5dfQK0ECLCHEke1QmaauMHHiREpKSiguLgbqx2Dt37+fGTNm8Prrrzca93Tbbbdx//33Rw02TjzxRO644w4+//zzVrUjLi4u9PMvfvELrr/+eubOncvKlSu5++67o25jt9f3dAgGiO2xfPlyVq1axeuvv859993Hxo0bufnmmznttNN46623mDBhAitWrGDo0KHtPtYRwVkBBzbAt/+BL/8CaKNL4LifdnfLhDisSIDViTy+tnURLNlTjbfagxkwtybAivZl08QX0JfbD1JS7cKkFMN6J7BxX2XE832SY3B7/ZRURy8Nb7eYmDYkg4Ld5Xy42Zh7My6QwSqsdPJDcTWDM5qu5KS1xu2rz2AB9JIMlhBCdLrNmzfj8/lIS0ujtrb+hljv3r1ZvHgxDzzwQKMAa/bs2dxxxx3s27cv6j5vu+02fvaznzFo0KA2tamiooLs7GwAnn322TbtoylJSUmkpKTw8ccfM3XqVJ577jmmT5+O3+9n9+7dzJw5kylTpvDCCy9QXV1NaWkpOTk55OTk8Nlnn7F582YJsAB2fQH/ugwq9xiP8y+CsZdD3zHd2y4hDkMSYHWitmSw3E4vLz/wFcP6xHEsresiGDW+ipLBKqpyct6fP2tVu6L5zfyR3P7ahtBjI4NlpqzWw6zff8SOxac1ua3HZ7QrJa7+9emVIGOwhBCiMwTHYIFxg+vZZ5/FbG78/TJ//nzuvvvuqN0Bb7vtNubNmxd1/6eeeioZGRltbt/dd9/NueeeS3Z2NhMmTGD79u1t3ldtbS19+/YNPb7++ut59tln+dnPfkZtbS2DBg3i6aefxufz8eMf/5iKigq01lx33XUkJydzxx138OGHH2I2mxk+fHiTFRKPGlrDB7+Bj38Pyf1h/hOQPRoyju/ulglx2JIAqxN5/B7ira2bj8Pj9OH3aVwVLjCBOaZtXQxDogRYZTVGUYrbTxvG0ve3Uun0ktcvmQfPNvrdv7fxAL//73cA3Dd/JOMGpEZsX+P2ctbjn/LF9sgpYeICXQRbwuMzBocFuwgC9EqUDJYQQnQGn88XdfmAAQPYsKH+RplSinXr1oUeh89rNXfu3IhuecH5sILWrFnTbBueeeaZJredN29e1OBt0aJFLFq0qNH2ANXV0YuF+P3RBx9H68L4ySefNFr2xz/+Mer2RyWt4f174JM/GBmrHz0AjqTubpUQhz0JsDqRx+fBam9dgOT1GF8MfpcPYsxY4trXRTBaBqs6MGbq2Mx4eifFUOmsYkBaLMdnGRWg9lfUhdYd1S85tLz+MBqH1cT6PeURy+PtFuJtLWuv22ucZ3KsdBEUQgghDjvaD8t/Bav/BmMuhdMeBpPURhOiJTr1L0Up9SOl1Bal1PdKqZujPJ+klHpDKbVOKbVRKXVpZ7anq7VlHiyvx7jLGAxTTDGtCbCiLItyIy+8KEWwNHpWWPYovJpftMp+SimyEh3sKI0sZuGwmohv4ZixYAbLYTURazO6qUgGSwghhDgMeN1QVQirn4LxV0pwJUQrdVoGSyllBh4DTgb2AF8ppV7XWn8bttpVwLda6zOUUhnAFqXU81prd2e1qyt5/K0v0+4LZLAsCrxaY7G1Yh6sqAFW44XBACvObsFhNfafGRbchFfzS42NHiBmBgIspeoTZ0op4lqYwXIFMlhWs4k4u4Vat49MGYMlhBBCdJ+6MmNuK58btA8WLYcBk7u7VUL0OJ15O2Ic8L3WelsgYFoGNOxgrYEEpZQC4oGDQMsmUeoB2lLkwusOD7DAbG3Fr6iVXQTj7RaCM2elx9cHUsmx9W02NTF5cTDb1LC0uies73tzJXTdgQyW3WIi3m4hPd6G1Sx3x4QQQogu5/NC5T4o22E8jkmG+EwJroRoo84cg5UN7A57vAcY32CdPwGvA/uABOB8rRtPjauUugK4AqB///6d0tiO8tm+z3h3x7sAlDvLW99F0O1liN1EhsVkBFjm6AFONFHDGV/zGawgS1jq34h3mxes+Ncr0c6BSmejfYMR7zW1q2AXQSODZSbG2opMnRBCCCE6hs8DxVvA7wFbAqQOBJMZ9rdsTkshRGOdGWBFu7RueLU/BygATgQGA/9VSn2stY6YlElr/RfgLwBjx47t/Jlz2+Hv3/6dz/d/Tqo9lUR7IqMyR7Vqe1+Nh2ExZjxas8ftZ2hrsjpRp8FqOoMVZzdz3clD2FFaw5Rj0yPWuWTiMREFKBqafFw6y9fvZ9awXkw9LoOKOqMy4Rl5ffjtW5uNc9EaU9S3QX2RC5vZxEnDekn2SgghhOhKfj/UFEHtQfB7IX0I2OIOvZ0Q4pA686p2D9Av7HFfjExVuEuBV7The2A70KNn86vx1DAmcwzvn/c+75/7PmcMPqNV2/tqjeBnfa2Pja3tLBmtS17ULoI+bGYTdouZYb0Tee+66STFRnZlvGfeSK47eUiTh5p5fCaf3TKLa2Ydx6/nHM9980cC0DsphhvmHB84dNOxcDCDZbOY+OVJQ7hq5rGHPD0hhBBtYzabyc/PJy8vj9GjR/Ppp58CsGPHDmJiYsjPz2f48OEsXLgQj8e4YbZy5UqUUrzxxhuh/Zx++umhEuszZsxg7NixoedWr14dUdY9aODAgWzZsiVi2S9/+UsefPDBJts7YMAASkpKWrxctILfB+W7oXgTVO03upqkDpLgSogO1JkB1lfAcUqpgUopG3ABRnfAcLuAWQBKqV7A8cC2TmxTp6v2VBNrjW3z9r46o4qgFzBbOuDX00SRizh753XJMwX6BTYxFQkQWeRCCCFE54qJiaGgoIB169bxwAMPcMstt4SeGzx4MAUFBaxfv549e/bw0ksvhZ7r27cv999/f5P7LSoq4u2332722BdccAHLli0LPfb7/fzrX//i/PPPb8cZiTar2AO1JUYZ9tRBkDkMHInd3SohjiiddnWrtfYCVwPvApuAl7TWG5VSP1NK/Syw2n3AJKXUeuB94CatdY++NVXrqSXO2va7QH6nkbbyajBbWj7+CmhxkQsjwOq83qHBmKm5DFaoi2BHBJFCCCFarLKykpSUlEbLzWYz48aNY+/evaFleXl5JCUl8d///jfqvm644QZ+85vfNHu8BQsWRARYq1atYsCAARxzzDHMnz+fMWPGMGLECP7yl7+06Xx27tzJrFmzyM3NZdasWezatQuAl19+mZEjR5KXl8e0adMA2LhxI+PGjSM/P5/c3Fy2bt3apmP2WJ46qDtoFLDIypFJg4XoJJ060bDW+i3grQbLngj7eR8wuzPb0NVqPDXtC7BcRgbLZ2pDBquFZdqrXV7iOzHACmWwmu0iaDxnkwyWEOIo8uEzf6FoZ8d21Mg8ZhAzF13R7Dp1dXXk5+fjdDrZv38/H3zwQaN1nE4nX3zxBY8++mjE8ttvv53bb7+dk08+udE2EydO5NVXX+XDDz8kISGh0fMAubm5mEwm1q1bR15eHsuWLWPBggUAPPXUU6SmplJXV8cJJ5zA2WefTVpaWktPHYCrr76ahQsXcskll/DUU09xzTXX8Nprr3Hvvffy7rvvkp2dTXl5OQBPPPEE1157LRdddBFutxufz9eqY/VoWhvZK2WCuF7d3RohjmhyddvB2htg6UCA5UhyYGplgBUtnmlckxFq3J0bYKkWdBGUDJYQQnSdYBfBzZs3884777Bw4cJQEaQffviB/Px80tLS6N+/P7m5uRHbTp06FYCPP/446r5vv/32FmexvF4v//nPfzj33HMBWLp0KXl5eUyYMIHdu3e3KaP02WefceGFFwJw8cUX88knnwAwefJkFi1axF//+tdQIDVx4kR++9vf8rvf/Y6dO3cSExPT6uP1SNoPpVvBXQ2J2WDu1PvrQhz15C+sA7l9bjx+T/sCLLfxJRCTaqeu0tPKjRtHWCaHMdbq1a/3sOTd7xjWO4H/fV/K9CEZbW7joQQryzeVwSqsdHLVC2sBsLaiDL0QQvR0h8o0dYWJEydSUlJCcXExUD8Ga//+/cyYMYPXX3+duXPnRmxz2223cf/992OxNL5sOPHEE7njjjv4/PPPmzzmggULmD17NtOnTyc3N5fMzExWrlzJihUr+Oyzz4iNjWXGjBk4nc4m99FSwZt8TzzxBF988QXLly8nPz+fgoICLrzwQsaPH8/y5cuZM2cOTz75JCeeeGK7j3nYqyoEdw0k9YPY1mUIhRCtJ+mDDlTjqQHokAxWzsnHMGHuoFZuHPkwdkwv0i81qvt9uLmYveV1rNhUBMDlUwa2uY2HEpyc2NdEgPXK2vr+/ZLBEkKIrrV582Z8Pl+jrni9e/dm8eLFPPDAA422mT17NmVlZaxbty7qPm+77bZmqwIOHjyYtLQ0br755lD3wIqKClJSUoiNjWXz5s3NBmjNmTRpUmiM1/PPP8+UKVMAIzM3fvx47r33XtLT09m9ezfbtm1j0KBBXHPNNcydO5dvvvmmTcfsMbQfXNVGOXZHMsSlNz1BpRCiw0gGqwMFA6xYS9urCOIxus71GZ6KMrW2yEXkw/gp2VhSHYCRNQoanBHHtE7MYLVkDFaQBFhCCNH5gmOwwJgf8dlnn8VsblxNdv78+dx9991RuwPedtttzJs3L+r+Tz31VDIymv9eWbBgAbfccgtnnnkmAD/60Y944oknyM3N5fjjj2fChAktOpfgmC6A8847j6VLl3LZZZfx0EMPkZGRwdNPPw0YBTi2bt2K1ppZs2aRl5fH4sWL+cc//oHVaiUrK4s777yzRcfskXweKP0evE5QZkjs3d0tEuKoIQFWBwoGWPG2+LbvxOPHB60ProCGEZYK635XVOUK/ZyV5Ghj41omGGA1FV/Vuesn+JIiF0II0fmaKuYwYMAANmzYEHqslIrIUoXPazV37tyIyeuD82EFrVmzptk2XHfddVx33XWhx3a7vckS7zt27GjV8mhFO1555ZVGy2655ZaIEvVHtOpC8LogoTfEpIDF3t0tEuKoIQFWB6r11gIQZ2l7F0HlNQKsNmkQ0AQDLK01ByrqM1jp8Z37IRuMDX1RKhgCFFbWB3uSwRJCCCE6mM8NtaVGYJWQ1d2tEeKoIwFWB6p2VwO0a6Jh5fXja2P36EYZo0CAVeXyUufx0S81ht0H6zC3KTvWcsExWE0WuaiqD/ZkomEhhBCig3jdRrdAv8e46SrBlRDdQq5uO9Duqt1A+4pcKJ8fX5sDoAZdBE0m3F4/a3aUAdA/tR1jw1rBdIgy7eHZNEsnB3tCCCHEUaNqH/hcYLJAyjHSLVCIbiIZrA5S46nhgS+NykvJ9uQ270f5NLqtQUeUDNZdr2/kxS+NWe0nDU7nf9+XMqJP587cHkxKNZXBCh8PpqSakRBCCNE+NaXgc0JdGcT3gsQ+3d0iIY5qEmB1kDKnkSWaN3geGbHtqNDn86Mcbfy1NIhnTDEWfiiuZkiveG45ZRgzjs9g0uA08vomt719LdBcFUGX18fBGjdXTBvEeWP7dmo7hBBCiCNebSlUGDdSMduMAEsI0a0kwOogwQqCM/rNaPM+tNZon8Zka1w6t4V7iHikTIqiSic5fZOZOTQTgFH9U9rcvpZSzQRYRYECF8dmxHNsZkKnt0UIIYQ4YmkNVQfAGgtJfcESAyYZ/SFEd5O/wg4SmgOrHQUu3E4fSoO5rQFWg3hGa82BSie9Erq2D7Y5FGA1fq4oUOAiM1H6hQshRFcxm83k5+eH/i1evLjTjvXMM89w9dVXt3n7lStXkpSUxKhRozj++OOZNm0ab775Zge2sLH2tHn9+vWh1zU1NZWBAweSn5/PSSed1KLtX3/99Vb/PuLj46FkK1TsNioGxmWALU6CKyEOE5LB6iDBAKs9BS5qylyYALOjYwKsSqcXp8ff6fNeNdRcmfYDFUYGq6vbJIQQR7OYmBgKCgq6uxlReb1eLJbIy5GpU6eGgqqCggLmz59PTEwMs2bN6o4mNhLe5pycnNBru2jRIk4//XTOOeecJtdvaO7cucydO7flB9d+45+72vhnTzTKsQshDhtyq6OD1HgDAVY75sCqqXBhUmBpa4AVxhRnpbAymC3q4gCrmTLtwTb1SpAASwghutuAAQO46667GD16NDk5OWzevBmA6upqLr30UnJycsjNzeXf//43AC+++CI5OTmMHDmSm266KbSfp59+miFDhjB9+nT+97//hZYXFxdz9tlnc8IJJ3DCCSeEnrv77ru54oormD17NgsXLmy2jfn5+dx555386U9/anafh1ObwZik+dZbb2X69Ok8+uijvPHGG4wfP55Ro0Zx0kknUVhYCERmzxYtWsQ111zDpEmTGDRoEP/617/qd+iqBk8dOCuNxykDIGMYpA4CpSgoKGDChAnk5uZy5plnUlZmjA1funQpw4cPJzc3lwsuuACAjz76KJR1GzVqFFVVVYc8HyFEy0kGq4PUegKTDLcyg6W1Zvu6Evok2XB9XYRNgSWm/b8WU3x9gJXV1QGWCk5wXL9sW3E1To+fwionNouJ5Fhrl7ZJCCEOB+Vv/IB7X02H7tPWJ47kMwY3u05dXR35+fmhx7fccgvnn38+AOnp6axdu5bHH3+cJUuW8OSTT3LfffeRlJTE+vXrASgrK2Pfvn3cdNNNrFmzhpSUFGbPns1rr73G+PHjueuuu1izZg1JSUnMnDmTUaNGAXDttddy3XXXMWXKFHbt2sWcOXPYtGkTAGvWrOGTTz4hJibmkOc4evRoHnrooWb3ebi1GaC8vJyPPvoo1J7PP/8cpRRPPvkkDz74IL///e8bbbN//34++eQTNm/ezNy5c41smN8HpVuNFUyBawRHMoRV4l24cCF//OMfmT59OnfeeSf33HMPjzzyCIsXL2b79u3Y7XbKy8sBWLJkCY899hiTJ0+muroah0NuegrRkSTA6iDBSYbjbK0LsL5fU8R7T27kjHQ7Dq8flMLaxgArYWY/qj405uJKmN6XwkBBiV5dPN4pWhfB+978loM1bob0SiAtzibl2YUQogs110XwrLPOAmDMmDG88sorAKxYsYJly5aF1klJSWHVqlXMmDGDjAyjUu5FF13EqlWrACKWn3/++Xz33Xeh/Xz77beh/VRWVoayJXPnzm1xoKLD7tg1tc/Drc3B/Qbt2bOH888/n/379+N2uxk4cGDUbebPn4/JZGL48OGhLBd1B+tX8HuNwCrse7SiooLy8nKmT58OwCWXXMK5554LQG5uLhdddBHz589n/vz5AEyePJnrr7+eiy66iLPOOou+faWqrxAdSQKsDhLsIhhraV2Ri7oqNwAmb/2svG0tcpE0ZwBJcwaEHhd++D0AvQ6DLoL7yp14fH48Pj82i/RMFUIcnQ6VaeoOdrtxE85sNuP1egEjoGl4I0w3MbchND2nod/v57PPPosalMTFGTckX331Ve655x4Annzyyaj7+frrrxk2bFiz++zKNrdU+Pq/+MUvuP7665k7dy4rV67k7rvvjrpN8PcBYe2vLQOLw+gO6KoCWn6Tcvny5axatYrXX3+d++67j40bN3LzzTdz2mmn8dZbbzFhwgRWrFjB0KFDW3VuQoimyZVuB6n11OIwO7CYWhezKqWwNvicVB0UgBRWOkmKseKwtn9MV2tEmwersMqJy+vH49NY2jqRshBCiC4xe/bs0JgnMLq3jR8/no8++oiSkhJ8Ph8vvvgi06dPZ/z48axcuZLS0lI8Hg8vv/xyk/uJlkU788wzKSgooKCggLFjxzZ6/ptvvuG+++7jqquuanafXdnmtqioqCA7OxuAZ599toVbadi/Djw1RiELix3i0hutlZSUREpKCh9//DEAzz33HNOnT8fv97N7925mzpzJgw8+SHl5OdXV1fzwww/k5ORw0003MXbs2NDYOyFEx5AAq4PUeGraVKLdZFY4GgZY5o4JQA5UOLu8eyA0LtPu9Pgor/Xg9Pjw+PxYzfK2E0KIrhQcgxX8d/PNNze7/u23305ZWRkjR44kLy+PDz/8kN69e/PAAw8wc+ZM8vLyGD16NPPmzaN3797cfffdTJw4kZNOOonRo0eH9rN06VJWr15Nbm4uw4cP54knnmhRez/++ONQmfarrrqKpUuXhioINrXP7m7zodx9992ce+65TJ06lfT0xkFSiNZQvgsObAgMZlbgSILYtNAqtbW19O3bN/Tv4Ycf5tlnn+WGG24gNzeXgoIC7rzzTnw+Hz/+8Y/Jyclh1KhRXHfddSQnJ/PII4+EXqeYmBhOOeWUDjlHIYRBNZc+PxyNHTtWr169urub0chNq25ifcl63jrrrVZt9+3/9rHhxS1Miq/PfCX+aACJM/q1u03zHvsfiQ4Lz10+vt37ao1Pvy/hwie/YNkVE5gwKI1dpbVMe+hD4mxmxg9Ko7jKxRu/mNKlbRJC9ExKqTVa68ZpjcNUtO+oTZs2hbq3CXFI1UVQuRds8WCPh7he3TK/lbxvhTi0pr6jZAxWB6nx1LRpDiyTSeFo8LmpOijDU1jh5LjMZu6SdRLVoItgYWByYafXGINl6aAMnRBCCHFE8XuhuhBsCZB+bHe3RgjRRhJgtdMzG57h8wOfs6FkA8cmt/7DUClwNBhoqyxtD0A8Pj83/fsbLCZFYZWzy0u0A5hNkWXaD1QYAZbPr3F6fNJFUAghhGhI+6FslxFkJfbp7tYIIdpBAqx2en7z87i8Lvon9OeUAa3vw6w12BT4FJgDAUl7ilz8UFzNK2v3hh53xxishmXag/NxAVQ5vaTF27q8TUIIIcRhye8Dd43RNdBdBYl9wdb6Md1CiMOHBFjtVOOp4YxBZ3DL+FvatL3fp7Eohd+kMPsCEVY7utAF574KyuyGDFbDMu3hAVa1y9vlZeOFEEKIw5LPC6Xfg7cOUJDcP6KYhRCiZ5IAqx201tR6ats09irI7/NjUeBXKjCHR/syWIUVzojH3dFFsGGZ9vCgr9rlxSpjsIQQQhztvE44uB28LkjMBkcyWKSHhxBHAgmw2sHlc+HTvjaVZw/yeTWWQBdBjUah2lWmPTxbBF0/yTCElWkPzJ0ckcFyemUMlhBCiKNbXblRih2MyYMdid3aHCFEx5Ir3Xao8dQAtDODpbEq8IbPyt6eDFaVk+RYa+hxejeMdwrW7AjvImgPnJPXr7FIgCWEEF3KbDZHzIO1ePHiTjvWM888w9VXX93m7VeuXElSUlJoHqxp06bx5ptvdmALG2tvmwcOHMiWLVsilv3yl7/kwQcfbLxyXRmUbWfA+FMoUWmNgqsBAwZQUlLS5rYIIbqfZLDaoUMCLL8fm1J4/ZrgjGTtKdN+oMJFVqKD8loPQLcEM+FdBLXWFFa6OCYtlu8KqwGwmqSLoBBCdKWYmBgKCgq6uxlReb1eLJbIy5GpU6eGgqqCggLmz59PTExMaLLh7tawzRdccAHLli3jrrvuAozv9n/961/873//a7Chy8hcWePAZAVL1xeiEkJ0PkkltENHZbAsQE2dtz7AamWZ9iXvbmHqgx/wyto9rNhUSFZS9xaRMIeKXECVy0udx0f/1PrXSObBEkKIw8OAAQO46667GD16NDk5OWzevBmA6upqLr30UnJycsjNzeXf//43AC+++CI5OTmMHDmSm266KbSfp59+miFDhjB9+vSIoKK4uJizzz6bE044gRNOOCH03N13380VV1zB7NmzWbhwYbNtzM/P58477+RPf/pTs/vszjYvWLCAZcuWhR6vWrWKAQMGcMwxxzB//nzGjBnDiBEj+MsjDwAKUo5pwW+n3s6dO5k1axa5ubnMmjWLXbuM7oUvv/wyI0eOJC8vj2nTpgGwceNGxo0bR35+Prm5uWzdurVVxxJCtJ9ksNqhIwIsn9cocuHVGgLdBFubwfrTh98D8NWOMgCuP3kI1588JFQmvauFl2mvcXkByEio76ooY7CEED2FUuo64CeABtYDl2qtnc1v1bS3336bAwcOdFTzAMjKyuKUU5qfJqSuro78/PzQ41tuuYXzzz8fgPT0dNauXcvjjz/OkiVLePLJJ7nvvvtISkpi/fr1AJSVlbFv3z5uuukm1qxZQ0pKCrNnz+a1115j/Pjx3HXXXaxZs4akpCRmzpzJqFGjALj22mu57rrrmDJlCrt27WLOnDls2rQJgDVr1vDJJ58QExNzyHMcPXo0Dz30ULP77M425+bmYjKZWLduHXl5eSxbtowFCxYA8NTfniTVrqkr3cMJc87l7AsvJa2Vmaurr76ahQsXcskll/DUU09xzTXX8Nprr3Hvvffy7rvvkp2dTXl5OQBPPPEE1157LRdddBFutxufz9eqYwkh2k8CrHao9dYCEGdpZwZLgVeDyWICn25zmfZv91cyNCuB3L7JbW5PRwgv0+70GJUukmIkwBJC9CxKqWzgGmC41rpOKfUScAHwTLc2rA2a6yJ41llnATBmzBheeeUVAFasWBGRkUlJSWHVqlXMmDGDjIwMAC666CJWrVoFELH8/PPP57vvvgvt59tvvw3tp7KykqqqKgDmzp3bouAKjKq9QU3ts7vbHMxijRgxgv/85z/ce++9ACx98D5efeNtUIrd+4vZums/aX1al8H67LPPQr+biy++mBtvvBGAyZMns2jRIs4777zQ73HixIncf//97Nmzh7POOovjjjuuVccSQrSfBFjt0CFdBL1+zErh1aBMCny6zWXav9lTzrTjMtrclo4SHIOlNTg9xp2z8MIbFhmDJYToOSxAjFLKA8QC+9qzs0NlmrqD3W5kU8xmM16v0evAmDYk8rM6PMhpqOG6QX6/n88++yxqUBIXZ3x3vvrqq9xzzz0APPnkk1H38/XXXzNs2LBm99mVbY5mwYIFzJ49m+nTp5Obm0tmZiYr33ubFR+u4rMP3iY2azAzZszA6WxzArRR25944gm++OILli9fTn5+PgUFBVx44YWMHz+e5cuXM2fOHJ588klOPPHEdh9TCNFykkpoh2qPUbShPWXacRsZHi+E+ta1pkx7+JeH1tArsfsHzIZ3EXR5gxmssABLMlhCiB5Aa70XWALsAvYDFVrr97q3VV1j9uzZoTFPYHS3Gz9+PB999BElJSX4fD5efPFFpk+fzvjx41m5ciWlpaV4PB5efvnlJvcTLYt25plnUlBQQEFBAWPHjm30/DfffMN9993HVVdd1ew+u7LN0QwePJi0tDRuvvnmUPfAisIdpCQnEps5gM2bN/P555+3aF8NTZo0KZSde/7555kyZQoAP/zwA+PHj+fee+8lPT2d3bt3s23bNgYNGsQ111zD3Llz+eabb9p0TCFE28mVbjvUegJdBNuRwdKBDI9XayODResmGi4LVAsM6o6JhRsKryIYzGCFB1g2KXIhhOgBlFIpwDxgINAHiFNK/TjKelcopVYrpVYXFxd3dTNbJDgGK/jv5ptvbnb922+/nbKyslABhQ8//JDevXvzwAMPMHPmTPLy8hg9ejTz5s2jd+/e3H333UycOJGTTjqJ0aNHh/azdOlSVq9eTW5uLsOHD+eJJ55oUXs//vjjUJn2q666iqVLl4YqCDa1z+5uMxhZrM2bN3PmmWeCs5IfTRmNFwu5+aO44447mDBhQov2k5ubS9++fenbty/XX389S5cu5emnnyY3N5fnnnuORx99FIAbbrghVMBj2rRp5OXl8c9//pORI0eSn5/P5s2bD1lERAjR8VRz6fPD0dixY/Xq1au7uxnsqtzFE+ue4I1tb1BwcQFmk7nV+3A7vXy2tIDBB+v4qsbLuMwYdI2H3reOw9xMJqq4ysXWwiqOzYzn/c1F3PLK+tBzv5k/kh9PaF3f7o62t7yOyYs/4Hdn59Ar0cGip7/ihZ+M58InvwCMIhzXzJI+4UKIQ1NKrdFaN05rdM2xzwV+pLW+PPB4ITBBa/3zpraJ9h21adOmUPc2cRSoq4CaIvDUGqXYM4aCqefdz5b3rRCH1tR3lIzBaqOFby+k1FlKmiOtTcEVwMsPrGaS0w1K4fRDbE46NZ/vR9ma39+vXl7Hqu+i3yUdmN72bFpHMYcyWISKXCRGdBGUDJYQokfYBUxQSsUCdcAsoPvv8InDV105lG0Hsw3siZCQ1SODKyFE+0iA1Qa1nlpKnaWcf/z5/CTnJ23eT3lhLSrJwkFg7m8nERtvI3FWf0yO5n8tB2tcoZ/z+iXzu7NzSIm1UVzlYkSfxGa27BrBMVh+rXF5jS6CMWFBo03GYAkhegCt9RdKqX8BazGGyn4N/KV7WyUOW1pD5V6wxED6EAmshDiKSYDVBsV1RvYoLyOPrLisdu3LBFRbTMQlBao4hc0X1ZQaV/2cFoMz4hiaZQRVvQ6D8VdQX93I79e4Ahksh9WM1azw+LRUERRC9Bha67uAuzpgP01WrRNHCGc5+NyQMrDHB1c9bfiIEIebnv0J0E2KaosAyIhtX0l0hVEQwtfKz7HqwOS9cPgEVeHMprAugoEMlt1iwm4xslhSRVAIcTRxOByUlpbKReuRrrrY6BroSOrulrSL1prS0lIcjsPv+kKInkIyWG0QDLAyYzPbtZ9gpzlvKyOsmvAAK6H7y7I3FF6m3euvz2DZLSaqXWCVMVhCiKNI37592bNnD4drhcGjlvaDaucNP78PPHXg94CrCmJS4ODmjmlfN3I4HPTt27e7myFEjyUBVhsU1xpfkpkx7QuwgoGIpxUBls+vqXXXdxE8HDNYJlN4mfZAgGUxYQ+Un7dKBksIcRSxWq0MHDiwu5shwhVtgscnwdl/g5xz2raPg9vgr7Og7qDxeNhcOPcZaGPhKyHEkUMCrDYorC0k1hJLvC2+XfsJZbACWZ6WqHF7Ix7brYdfsBKcB0trcHp8WEwKi9mE3SpdBIUQQhwGigNZpm9fa3uA9c4tRgbrsneNaoEpAzqqdUKIHk6udNuguK643d0DAYI95Tzelmewgt0DzxqVTYLdwqh+Ke1uR0cLdRHUGpfXH8pchTJYUuRCCCFEd7IlGP+7a9q2fdEm+O4dmHQ19J8gwZUQIoJksNqgqLao3QUufF5/KMDy+lsfYM0YmsnD5+e3qw2dxaTCuwj6cAQyV7ZAgCUZLCGEEN3KEqjY66pu2/brXwZlhrGXdVybhBBHDLnSbYOi2qJ2Z7A8Th8m6qvttVR1oER7vP3w7eNtCivT7vT4QwFW/RgsyWAJIYToRv5Ad3t3GwIsrWHDKzBwGsSld2y7hBBHBMlgtZLWmuLa4nYXuHA7vaEMVmuKCAYzWPF2a7uO35kalmkPjhMLlmmXuWCEEEJ0K5/H+L81GaxdX0BNEST1hbLtMOW6zmmbEKLHkwCrlSpcFbj97nZnsNxOX6jIha/ZNSMF58CKO6wzWMb/Pr/G5fHhCARWjkCg5fK05oyFEEKIDhYMsNxVLVu/uhieObU+82WywLAzOqdtQogeT7oItlJRXcdMMuxxeiOKQbRUtTOYwTp8Y2MVqiJodBEMZrCCY7Bc3pZXTRRCCCE6nM9t/N/SDFbB80ZwNeQU4/HUX0Nsaue0TQjR4x2+V+mHqeAkw71ie7V6W7/Pz3+f+pZRs/vjdtVnsFoabjg9Pn718joA4g7jACto6Qffkx5v57hMo5x9osPo1uhvRUAphBBCdLhgJsrvadn6uz6DtGPhwmVQVw4xyZ3VMiHEEeDwv0o/zAQnGW5LBqu8qI7v1xRRtLOSiWceGxqDNefK3BZtv/tgLQCD0uNIi7O1+vjdoaTaxfA+iQDccsowEmOsnDKydze3SgghxFHN18LACsDvh12f13cJlOBKCHEIEmC1UmFtIQAZMa0PsJzV9R/obqcXc6CKYOagpBZtHxx/dfvpwzq8UIRn7152XnoZ/tpa0n9+Jclnn82OBQvwFhWjTCYcw4ZRt3EjADE5OfT7v8dbvO9gIJkUa+XWU4d1aLuFEEKIVgt2EQRw14Ittul1y3eCsxz6ju30ZgkhjgwyBquVimuLSbGnYDO3PoNUU+4K/exx+kKBh7K27NdQEyrR3vEVBF3btuHZtQtfSQl1a9biKynB9e0m7IMG4S0qovqjj9AuF5b0dGo+/bRV+zab5G0mhBDiMBLsIghQtb/5dct2GP+nDuq05gghjixy5dtK7ZlkuKaiPsByhxW5UJaW/RqqXUYGrDMqCGqPJ+Ln4OPkc88Bi5HotGZlET9jesS6LSHzCgshhDishGewKvZEX6e6CNw1RgYLIPmYzm+XEOKIIJe+rVRU1/ZJhqsDGSyP24/H6cNiUmBRKFPLuvvVTzLc8T07tdv4slFWK9rtxh96bEPZjGydsgV+9vvRXm+T+2rI3MLzE0IIIbpE+Bisv8+FnQ16ZmgN/zcJHugL+wqMsuyJ2V3aRCFEzyUBViv4/D62lm1tc4BVGwiw6ird1Fa5ibWYUC1M7/j8OjTJcGdUEAwGWKb4eLTbjXYbXz7KZsNktdb/HAi2guu3hEkmFhZCCHE4aVjk4ulTjKAqqGw71BSD9sOap43Jhc0ybF0I0TISYLXCXZ/ehcfvISsuq03b11TUByWFXxXSxwTKfOjgY+O+Cgbf+hZvbzD6iXdmBqs+wApksGxRMli0LsCySAZLCCHE4SRaefaakvqfG2a0UgZ0anOEEEcWCbBaYWv5VkzKxILjF7Rp++pyFwNy04lJsBITeOUT5ww45Hard5QB8Pm2g1hMCnsLx2y1RrBLoCkuDr8nPMCyRg2w/K3JYEmAJYQQ4nDic4OpQcEoT039z3u+AkcSJPc3Hg+e1XVtE0L0eBJgtUJRbRHzj51PsiO51dtqraktd5GcGcPIadmhF94+sGUl2oPi7JYOL9EOQKBwhSkuLlDkon5MlgrrIhj8mVYUujBLF0EhhBCHE58HzDa4fhOc8pCxzOOsf754C2QOh145xuMR87u8iUKInksCrBby+r2U1pW2efyVq9aL1+MnLtlOXLK91RUEgzqjeyCEZbDi45ruImi1timDZWlBN0ghhBCiy/g8xpiqxD7G+CoAb53xv9ZQvBkyjod5f4JL3qjPZAkhRAtIgNVCpXWlaHSbJhiG+hLtoQArsFxZDh186LCBt51Roh3qx1SZ4+LQ7voy7aaIMVhWlDU4BqvlGSwpciGEEOKwUL4b/m+KUZo9OJ+l1WH8H8xg1ZRAXRlkDIXYVBg4rXvaKoTosaQkTgsV1RYBtKOCoBHAxCXZsdrNmAgEHS2oIuj0+kM/d1YGS7s9YDajHDEdXuRCyrQLIYQ4LHz5Zyhcb/xL6GMss8QY/wczWEXfGv+nD+n69gkhjggSYLVQUV37AqyNH+8FIC7ZhtVuCesieOjgo9pZP+dUZ5RoByNgMgIoa5MBVng2KzhGqyUkgyWEEOKwEF6e3RwYUxzKYAUCrP0Fxv+987uqVUKII4wEWC1UXFsMtC3AKjtQww9fG9vHJdsxm031XQRbkMGqdtUHWIkOazNrtl19gGWLnGg4EHRBcNJha2j9lpIy7UIIIQ4L0QKsYAYrGGDt+9oYcxWX1rVtE0IcMTp1DJZS6kdKqS1Kqe+VUjc3sc4MpVSBUmqjUuqjzmxPexTVFmFWZlLsKa3etuqg0a/7tKtysVjNKJNi3KkDjCdbUACiJizAyky0t/r4LaE9nsAYK6tRRdAdXkUwrItgoIqgPkQVwR9+e2qoa6B0ERRCCHFYCJ//KjQGK9hF0Al+P+xZA31GdX3bhBBHjE4LsJRSZuAx4BRgOLBAKTW8wTrJwOPAXK31CODczmpPexXVFpEek47Z1PoiEzWB8VcpWXGhZUprMKsWlVyvcdcHWL0SHa0+fktotxuTtT6DFSxiER5UtWYMltmksAaCR5kHSwghxGHBV/99iinQiccalsFa/zJU7IKhp3d924QQR4zOzGCNA77XWm/TWruBZcC8ButcCLyitd4FoLUu6sT2tEtxXXGbx1+FKggm2ULLtFe3qHsgQLXLF/q5V2dlsAJdBE02G2iNv64WMIKqYD2O0PO0rItgcP4r6SIohBCiW5XvAq/bmGA4KJjBsgRuXHqdsOl1SD4GRp7T9W0UQhwxOnMMVjawO+zxHmB8g3WGAFal1EogAXhUa/33hjtSSl0BXAHQv3/3zEVRVFtE/4S2Hbum3IU91oLFVp/90j5/iwpcQGQXwU7LYHnckfNcVdeAxYIy1QeB4c+3JMAKFreQIhdCCCG6Te1BeCSn8fJQkYtgBssJVQcgdRCYZBYbIUTbdeYnSLSrat3gsQUYA5wGzAHuUEo1qouqtf6L1nqs1npsRkbb5qFqr6LaorZnsMpdxCU3yDx5dYtKtENkFcHOCrD8wSIX1mCAVR0KpoLCuwi2aKLhUCV6CbCEEEJ0k31roy8PBlhmKyizUaa96gAkZHVd24QQR6TOzGDtAfqFPe4L7IuyTonWugaoUUqtAvKA7zqxXa3m9DqpdFe2o4ugu1GApb0tz2BVd0UGK6xMO4C/piY09iooWAQjuH5LSYAlhBCi2+xZHX25Kew7zhpjjMGqLpQASwjRbp2ZwfoKOE4pNVApZQMuAF5vsM5/gKlKKYtSKhajC+GmTmxTm5S7ygFIcbS+giCAs8aDIy4yWDG6CLbs5S+vdTM4I47Tcnt33kTDHk+UDFbDACt8HqzmqwiGkwBLCCFEt9nbVAYrrJeGxQEVe4wqgwm9u6ZdQogjVqdlsLTWXqXU1cC7gBl4Smu9USn1s8DzT2itNyml3gG+AfzAk1rrDZ3Vpraq8dQAEG+Nb9P2PrcPiy0ymDKKXLRgkmGXlxq3j/PG9uP/TR/cpuO3hHZ7MCXF1ncBrKnBZG3QRTBiDFYrAiwZgyWEEKK7VOyJvtwcdglkjYGy7cbPksESQrRTp040rLV+C3irwbInGjx+CHioM9vRXsEAK9Ya26btvR4/FmuD8u4+P7Qgg3WgwphDq7O6BgaFTzQM4KuJMgZLqVYVuQiGVVKmXQghRLep2h99ecMM1sEdxs+SwRJCtJOUyWmBak810I4MlsePxdogg+VrWZn2osquDLCs9WOwqmsaBVhaa6OqoMXSogArWNFEyrQLIYToFl4X1B2EvAUwaGbkcxFjsBzgrjJ+Turbde0TQhyRDnmFr5Q6/f+zd97hcZTX275ndna1q25JlmzLliX33gu2AWMMGDAdU0PoAVKoPxIIJSEJJCTwpZBKCc0hprdQDO4GbFyxjXuVq6xm9dXuTvv+mJ3Z2SbJRW7MfV2+pJ2dfd93Zlfeeeac8xxBEL7TQswvGz2h0txprewZj67rKLKGK1ZgKVqbUgTLG0yB1T79r6z1hGJt2m0RrBjvR7MZcVtxIlgODg4ODseExnLjZ9E4uP79aJHlsX2nS2GrdneaE8FycHA4bNoinK4GtgiC8AdBEPq394KORw4nRVBVNID4GixVb2OKoNGk+KilCLrNCFZjnIugieB2H5yLoFOD5eDg4OBwtKjbC493gm3zIv2vTNF0/ftQEN6Wlhd5jTv8HZvbE5zvLAcHh8Ok1RosXdevEwQhE7gGeEkQBB14CZih63pDey/weMAUWIcSwVJCYYHldqErGuXPfGNErwQQ0uMFzO9nbkQU4KdT+nHFvxaxencdGSkSae3kHmiiyzKix4NoSwu0Ilgx3zWCx31QLoJOiqCDg4ODw1Fj+3yjp9X0SyLbMgoivyvNxs/U3Mi2zsNgx0JIyTwKC3RwcDjZadNVu67r9YIgvAP4gHuAS4GfCoLwjK7rf23H9R0XHI6LoCobAsvlFtH8CkqFkW6IAO4u8ePNXl+OSxS4e3IflpXWMLJ7B647peiQ1171r39R+ee/4B06hOD6DXGdngWXi5S+ffgy10fd+mV0aqpmmPmc10hLlPKM5s6udGO9otdH7dtvU/v++y3O/V9VQ9fB9T+BDY7IOuFxFxTQ4+OPEFNSKL3mWprXto/hpyBJdP3bX0mfMIHql1+m4v/9MeF+Um4uPT76CFd6GrtuvoWmZcsAED0eur3wPKnDhyd83Z577qVxzhyKXnmZ1BEjrO0HXnuNiid/b/2NiG433Z57ltRRo6Jev/v2O2hctIiUHj0oef89hAR3u3fddhv+pcso/u9reAcMSLiO3T/5CY0LFlrH3O0ffydt3Li4/Rpmz2bv/T9FV1WkvDx6fvwRYmp8NH3/r39NzVtvR50XE7Whge1TL0CpqTHO71/+TPrppydcl4PDCY8poOxkFkZ+Dxp11VECa+SNsOgZ6NC9XZfm4ODw3aBVgSUIwoXAzUBPYDowRtf1inDfqg3Ad0JgSaKEx+VpfecYFDmSIqjLauQJnYR9sMrrA7hEgaZwc+Gpgztz6fBDL7gNrFtv/Fy9BiE1ldzrrrOtQaf6+ecJrF5D3eAeaLpOZdle8n96P2pdPRlnGrnq+f93Hyl9epMWviAr+PnPaV61qtW5X/hiO0FV46z++fQtcO4KnsgENm6gaeEXqLV1iAX5BNauxTdwIKljxhzRefRQiAMvv0xo61aYMIHA+vWIPh8drr46ar/gli00zpuHWl2FKz2N5rVr8fbti2/IYGr+O4PQ9h1JBVbj/Pnoskxw27YogRXYsAHB7SbnuuvQ/H5q/vMfgtu2xwms5nXrQJYJbtoEsgye+P8XmhZ+AUCotDSpwAqsXUdKjx6knXIKB155heCWrQkFVmDzZvRAgPSJE2lcsACluhpPAoHVvNZYl7J/v3VeTJTycpSKCtLPOIPG+fMJbtniCCyHk4+6PfDWTdCxT2Rb/4tg/F3R6YAh46ZplMDK7Qk3fw75/Y7OWh0cHE5q2hLBugL4k67rC+0bdV33C4Jwc/ss6/iiSW46pPRAACUsqlySiB6ux7KIMbloDqnUBwxhdcBv1Dilew8vNdBeK+XKziL/vnujnq/+97/RNQ0tHGFSFZncW26J2kf0eulwxRXW44wzJ1niqyVm1H9GQ0BhxNXDyB9W2Or+Dscvte++R9PCL9DlELquo8syaRMm0PHOnxzRebRAgAMvv4wW/tzqIRkpLy/uc1v/6ac0zptnfb71UIjUsWPIueEGav47A11uoUYwHHGKrSPUQyFcOTnk33cvSk0NNf/5T8JaQ/s2LSTjSiCwIs8nX4ceCuEbPoyOd93JgVdeSbpmPRQCUSTzogtpXLAgaf2jfXuiYwPIuvRSQ2AeRA2lg8MJw+K/w56lxj+T0bdCt9HR+4USRLAAisa27/ocHBy+M7TF5OKXgPW/lSAIPkEQigF0XZ/TTus6rvArftKkQxNYqhXBcqHL0QIrNoJVHrZkB9heGU5LPMzaK/tFW2zjYDDqrLSwznO53Wiqiq5pcfsdDpL4nTahPCmw9z8z6+9ibfyPyDxhYxW7cEo0j+V2GbOf2JY+bboe3ie6jlAPyda4gjv5OPY1tSjkWllHbO+55MJJbuN+objzErsO0ecFUWxR+Dk4nBSIEoy6BYpPS/BkOBHYHtVycHBwOIK05cr3LcB+xa2Gt31naJKbSPMcYgTLMrmIj2DF2rRHCyzjDtvhmlvYL6SSXahq4Tv6Hq9hU6sobTewaAttaPflcJxj9kfTQyHrYj2Zy+RhzeNygctliZ/WBJYeCqErCmhaVJuBNvVpizFq0WXZOibRPN4EAkqXZcS0tPA8Lf+ttGQGY80nSS3uG+vw2dJ+kXXFCCxTFLvdB+0C6uBwwqDbqowHXwEX/BFausEXG8FycHBwOEK05dJX0nXd+jYO/37kb10fxzTKjYccwaqvMoptJbcYF8GKtWnfnzCC5TqkeU3sF4CJLogFtzsisMJ1HZqiHNac1tjhn6JjeXvCY48sWQKrHSJY5rhREawkn1vjeTkSnbG3GWiLwEoQ5bGOKSaSZu2jqqCqiGHDl4QCzBYBTibAdF2PCCdBaLG3nHkOWovO6aFQZF0x82q298yY68jeRHFwOOY07IeK9ZHHWd2S72sKK6l9+0s6ODh8d2lLeKRSEISLdF3/EEAQhIuBqvZd1vFFs9xMuufgHQT3ballzisbAMNFUG+KvqiJTRGsqA9av287QhEs+93uZJEA3RRYPkNgqQdhwd7i3OGfUhsaKjsc30RS4mRbiuCRj2CZc5lz6LJsuVm2vh6PEQ0ShJYjR+EbCC0JLEEQjEhPbJTLFHOWkEkgsGw3KJJGihQFdN0STYLHk1QU6nIbUwRlGVdurvV7onVbAquV1EYHhxMKTYX/1zd6W1YL5lC3L4Sa0nZdkoODw3ebtly93wG8JgjC3zCCEruB69t1VccZzWozea6Dz9Wuq4xYxUpuF7ocjHreFdMHa399AJ/bhabrlsA67BqsVlME3ZbBRUpYYClHSGCZOBGsEx979KT9I1juqAiWmJkRv4878XpajQZpmiFuSCKwbGIu0TjmY1eSVLzYba0ZUgg2gdVybVUk/TGpEAuFkq7LjFg5ESyHk5Its+K3ZbcQwcrq2rIAc3BwcDhM2tJoeBtwiiAI6YDwXWkubCeoBEk5hFQCX0ZEQEme+BosV2b0mOX1ATpleVE1nV0HjH5Z7S2wRHsNls+owVKPUA2WKatcTg+sEx4hgcAS20lgie7oFMFE8yRajym6WhIQrTnt2cVcoqhSmyJYbRBY2kGuWWyjyUWyddnPkV3AOjicFBzYFr+tpRRBBwcHh3amTVfvgiBMBQYCXrOppq7rv27HdR1XBNUgXpf3oF8n2lLjXAlqsFyZ0ReOFfVB8jNS0PSIwDrsFMHWIlhuu8BqnxRBlxPBOuGxR0+Ofg1W4sgrGDVQWujgokHW73ICgWU7ppYiWMnMJOLmaMEZ8GDWbAgjT9Rro/YJW+db60pwbOY8YgtznQwIgpAGNOu6rgmC0AfoB3yq67oTtjtZaSiL3+ZEqBwcHI4hrZpcCILwL+Aq4E6MoMQVwHeq1XlQDZLiOvgIlqZGHI0S2bS7sqIvHPfXByjI9JKfaYg5jyTiPkwLvtZTBD1WiqDpInikBJaJE8E68UkcMWqnGiy32xIImpzYRTA6ZTHikGeutaU6Jev3WJt2m4tgZJz4fcAmsBL8rUSLuCRRKTlmzQnqvSL7tu4iaK0rWQTLPt/J7yK4EONmYCEwB7gJePlwBhQEIVsQhLcFQdgoCMIGQRDiO0I7HBvkANTshOwiw5K9Y3/I6wtu37FemYODw3eYtoRHxuu6PkQQhDW6rv9KEIT/B7zb3gs7njhUgWV3jJUkkaCiRj0vpnls++pRKYJw+OmBECuwErix2VMEwy6C6hFyETRxBNaJjz16cjQiWPZGw63atMdFsJILiNYiWPZoWSKhZq6rzSmCLTUPpm0RLK0N/bJai6xF5nNHpWCepAi6rvsFQbgF+Kuu638QBOGbwxzzL8BMXdenCYLgAVIPf5kOR4R/nAI1O6DbWLjxI1AV0JxgpYODw7GlLVfwpne4XxCELkA1UNJ+Szq+0HWdgBI4pBos3RbBEiXBiGAJWLlzz8zbaj0vqxpBRbNSBAHr5+EQJbCS2F2r7VyDJToC64THbtMem5J3xOc6KJv2kCViIk2C2yawYuurYqNlicYxI1pielrCMWLnSB5JOxhRKCNmeNsmsNKT9cGyWdmf5CmCgBCOMH0PuCW87ZDvVgmCkAmcDtwImK1KTuoTeEKw4CmQPIa4goj1uksy/jk4ODgcQ9ryv9D/BEHIBp4CVmLIg+fbc1HHE7Imo6MfUg2WpkUEkiAI6IqGDMwlRDEu/jR7c9T+bpfA4MIszJeNLs45nKVbdRnWGlqxaU9pL5t2R2Cd8CS1RW+nuaJs2luKYMmyrZ7JHff6WFo2uYieK9E4lotgSxEs22tacvyzr7mlqJJl0+5uQWCF57TW1YpNu9bYmHCuk4R7gJ8D7+m6vk4QhB7AvMMYrwdQCbwkCMJQYAVwt67rTeYOgiDcBtwGUFRUdBhTObRKoB50DeY9Hr29sfzYrMfBwcEhAS0KLEEQRGCOruu1wDuCIHwEeHVdrzsaizseCKqGtfoh1WCFG45e+9hYAHRZIyTAb3QjKPjkZYO5clS005EZ7dn+2/M5bG+ImIushG5sksuqwXIf4QiWNa9jcnHC01JKXnvMpdU1W/O1JLA0WwTL/Hy3JFa0KIEVL0KiBVaiCFZsKl4rNVituBnaUwS1pqak+xrmFBFjj2TjmeuKi86FQiAIIEnGXCdxHyxd1xcAC8D6DqvSdf2uwxhSAkYAd+q6vkQQhL8ADwKP2uZ8DngOYNSoUYefeuCQnCeTuAPm9j6663BwcHBogRYdFHRd14D/Z3sc/C6JK4gILK908BEsM0VQCAsYXdaQbVqjU5YXURSi/pmIooBwmMJEi7m4S3ZBrLVTBMuxaT95iBZY0QYNR3yucGqerqqgqolrByUJRDFK8NEWk4tWbNrtx5TIbc8Scy24CGotzBG73W5ykUz0WMLPlhaZdDyv1zoviY7NaqB8EqcICoLwX0EQMsNuguuBTYIg/PQwhtwD7NF1fUn48dsYgsvhWCNKcNkLcMssmPr0sV6Ng4ODg0VbLOo+FwThcuFwr/ZPUAKKEW3yuA7+bn04gGUJp1iBVZB58KLtYLDqPKyLuJYF1pF2EXRSBE8eomqejlINVmvzmC5/sX25WorQ2NMboxwFLTFnr8FKJLBMF8HEqXhgEzspKa26CNrXHBtxto8neGziqKU5kzQStqdafgcaDQ/Qdb0euAT4BCgCvn+og+m6vh/YLQhC3/CmyRjCzeFoo9o+tyNugEerYMgV0G0MpMQ3JHdwcHA4VrSlBus+IA1QBEEIELZp0HU9s11XdpxgRbAOoQZLDxdTmf2wdEUjSCR7pFN7C6yYC73EF6pCnIugcqRTBB2BdcITubiPb+x7xOcKp+a11tA4mRBruWlvxM48kZ16fA1WkhTBJGYSLc2RaJyoFMGW+mC14jZoP1fJ+ne1xbHwJMEtCIIbQ2D9Tdd1WRCEw03buxN4LewguB3D+t3haBOoN352GgznPsnh59E7ODg4tA+tCixd17/Tt4UCqhHBOrQarPgUQb/N+CI7tX1SrEziLuIkV6K9In2wwimC2hGyabdSBJ0vwZOCeEHTTimCBxXBOrRGw3ECK8ExJRI9bTK5sNVDHYzAaqleS2xFiMVHsJIbeLTkWHiS8CxQCqwGFgqC0B2oP5wBdV1fBYw67JU5HB6BWuPnuJ+Ax3HKd3BwOH5pVWAJgnB6ou26ri888ss5vnjh2xeoCdQAHJJNu6bq5LoEmufvZkdhKtmba2gi0my4vbMu25rKZUWwjnANlolTg3VyILjdCU0ljjRirMBKUutl1WrFipU22LSL6WlodfVx2+Nt2hO78YnhaO+hCqyDFYWtNVG2j5fYXv67E8HSdf0Z4Bnbpp2CIEw6VutxOIIEw3+zKd+JBBoHB4cTmLakCNqLg73AGAyb2jPbZUXHEX9Z+Rfr90NqNKzpnJohEVhcxt7uqWQDOzp5uWtgIR0zDn68g56/jXbaWlj/mH2wFEdgOSTArFtqd5t2d9vmETzuhPu1aNMeFoeu1DTUyqrI9gTpiInGsYRMSoqVMhk/R9gyPS0Npaoq7nn7fK2m/oVbLbQW6bKfA/O8xM5nWcK3cH5OBgRByAJ+idG7CgxHwV8D3ymDppMOXYfdy4zfvVnHdi0ODg4OrdCWFMEL7Y8FQegG/KHdVnScYNZemRxuHyx3fYhqQeeue8Yd9traSmsRAJM4k4sjXIPlCKyTg9jUPaT2aeZpprC11tA4EumKdjVsuWlv4uhSor+VZLVM5n7JImVRaYj79iVZR8yak0XdYsVjK3MKbndi98NQKFIzZ0b+dL3do+jHiBeBtcCV4cffB14CLjtmK3I4dEJNsOlTQ2B9Gr7f63UiWA4ODsc3h3KFtAcYdKQXcrxR6a+MenyoESyTjCaVBvfRvZhpc4qgKOByuRBdLgRBRJWPTA2WidMH6+TA7toneDztdnFuRbCCrdRguVsyuWjZRVBMT492EUxmcpHERdCqdUrk6CfbBFYrLoJRdVEJ9tUsIdZydC7SbNmT1P3QHsFC10FRLOv3k4yeuq5fbnv8K0EQVh2rxTgcBpoGsx+Dpc9Boa0EzolgOTg4HOe0pQbrr0Qct0VgGEbx8ElNhb8i6vGh1mCZd4lzQxrbMxKZTLQfcYX7CS+IDRdBUTTW5nK7j3gEy7FpPzmwm0q0V3qgOQ+A5vcbj5O4FZouf3ooZDTQFY2uE4kiOCb26JJmEyqJomUtNRo2BVZLhhNi+sGZXKBp6Ipi9Pgy95PbJh7jTC4SuB+KNpFmbmuvXmbHmGZBEE7Vdf1LAEEQJgDNx3hNDofCP8ZC1Wbj93pbNNipwXJwcDjOaUsEa7ntdwWYoev6V+20nuOGiuZogXWoKYIqxkn2IKC2s2tg3PzmhV4rdtqaYESwAFySdMQFlhPBOjmwpwgeFYHV1Bj1ONF+WoL1WOtMkAIXZbMuy+iahmBrzBs7Tqzo0UMyuFwILlfLhhOCgOhLjRJxidZhChzRLnrsAitOiLWWIphY+OmhkNUc2RSsmm3bScYdwKvhWiyAGuCGY7geh0PFFFcADY7AcnBwaDt+v5/9+/ejqipdunQh7Sh/37VFYL0NBHRdVwEEQXAJgpCq67q/fZd2bIlNETyURsO6pts8A0HIPLIXpbquo/uTvw1aQ/QFqqwoKKEQku0iUtN1VFGMCCy3O6mLoBwM4E7xIgcC6ES3lXF7UqwIAoCuaUhaCLemooSCkEBc6pqGHArGbU+GIIq4PSloqoqmaUgt3H3XVBXFTNUSXUgeD6oio8ZY0IsuCdElosRckLo9KSAIyEHDpl/yeBBFV9Sa7cesyDKaaowtuT2ILhe6riMHA7gkCZcUvVY5GABBMOYBlFAITVMRXZJ1XHIwgK7rUa+PPffmdlWRcXtSUBUFTVPjzhlgrScWd4rXEiL2fcxjjuwoEWr2I/ibIiJIU61zZ58LIBRojjofJvY5BATcXi+6pqEqClI4AgMQqqxEE+Lt4M1zJ3g8aDU1aH4/ou2zoEkSiiig1tZGmVZomkagvg6NiM26WleH6PGgNTSgCgK6K/JfovlatbYWwetFDgaRGxujo0nNzWhNTaiKgqoouD0edL8/yi5drquL+txJHo8RnXO7rc+P4PGgCgLNFeV4OuTgCousQGUlOpG/YdHjQW1sQmtqAszPnYraaP6tuyPnJbwPgBYM4urQwZoLQKurQ7OdHzkYRBCEqP8fDhchNfWo13npur4aGCoIQmb4cb0gCPcAa47qQhzaD9t3jYODg4OJpmls27aNNWvWsG7dOjQtchVeWFhIv3796N+/P5mZmezcuZPevXu321raIrDmAGcBjeHHPuBzYHx7Lep4IFZg+STfQY+haTqajtUQyp11ZAVWxdNP85/lC+hRUUO/sgMAzO1fRHpQZsz2Mmu/t5rKYUgPmPs/xAWfcM2vn6JTrz5oqsrHtXvx52SQFb6ocknuhDVYX735H75+53WyCzpTW14W93yfsRO48L6fW4/f+d0v+d6mbwB4+Y5/c8lPH6HnyLFRr3n3yccoXb3yoI75ovseYu7Lz9J4oBqAgWecxWnX3MC/bv8+5/7oXmb+409MuuEHrPr8E2rK9gIgulxc/tBv+PD/PUHQ3xQ1nsvtxpeRaY1n0m/CRLLyC1jy3psA5Bf35Pu//wsf/fn3bF5iBHD7jjuNC+55gAP79vDqT39iXUSn5+bxg7/9m3kvP8eqzz5GSklBCQYZNmUqk2/+IRu/WsDHzzwFgsAlP32EtOwcZjx6P5pqCKzv//4vVO/ZxUd//j0AKalp/ODvL/LNzI/46o3pUev0phlCIdDUSEZuR5pqayyhByAIItMe+Q1Fg4ay8LWXWP6/d+PO6YjzL2bSDT8A4MsZr7D0g7cBKOjRi+t+92drv1WCzHbZj2t7Def4jIju2795hN3rvzUn47IHH6Nk2Ejr8wLQsaiY65/6mzXO3Jf+xarPPrYen3H9rWxZupi9G9dx2c9/xbv/m8GgnAxmv/ESoSE9uUEOYXa82bT4C+O8CAITMvPJWreOwLp1SJ06AdDc2MAbX32OPLgH66+8mCG7I3/Hi3oVUpvmJbVfEVeFz9uWccZ/Y/VeD18O6UHOf1/gpvGGEY0QdtXccuppbOyUw/aCDoiaxhnpxmpEn4+GWbPZMGsU8/t3J+CRyGvwM2Z7Ga6sLESfD0VT+efNVyPbetDlNvgZu70MMSPSYnBPbTWzBpfAA3fiUjUmbtzF/qw01nftSM9OOXQNn2/Bl0pg0WI2jRxFk0fii77d0ESRHuU19ANErxfR52PXN8t59+arOH3jLtKDxg0TT0mxse5U47i2nXueNf/unAy+7ZYPus6Y7WXkNUZn1DWmuFnYr4gx2/bFPdcSvRd9hZST0+b9jyS6rtt7X90H/PmYLMTh0FAT1AJ7MmDiT+O3Ozg4nNSEQiEkSUIURQKBANu3b0eWZTweD6mpqei6zt69e1mxYgUHDhzA5/MxYsQIBgwYgCAI7N69m40bNzJnzhzmzJmDIAjous4999xDdnZ2u6y5LQLLq+u6Ka7Qdb1REISTvsOfX/GTnZLNvSPvJdOTeWgRLDU6zuPJOrLW7KHSnQBsz+/A6dfdAkDg83cJeNzk/9T4EnJlZ8ObL1r1V5qqUl9dSadefZCDQfxyiKKiEk656TZjf3fiFMED+wyxUltehpSSwvgrvmc9t37BHEvMRPbfQ15xT1J6DmHvnPeo3R8vymrK9pJf0pN+Eya2eqyaovDl669yoGxvlBhaN382/SecAWCJoaUfvkNTzQG6DxlOXrfurPj4ffZv20zQ30S/CRPJL+kJQF15GatnfUrjgWo69+5L77ETAFg7bxY1ZXvRFIXUrGxyCruyf9sWa825XYuMYwwfc31lBaqiMGzKVOorK9i+chlqSLbOmRI0Il6rPvuYyTf/kJqycKqLrlO7vwwlZEQh+o47jU2Lv6C+ssLax9zmr6ulpmwv3rR0xlxqmKPt27Sercu+ts5FQ7UhJkZOvZi0DrmE/E18/e4b1Jbvp2jQUGrK9pHWIYeRUy+xXrPy0w+j3rsD+/aSlt2BDp0LqSjdFvUeBAo7Qel2VJdI2o9vs85Bp159KBk2isVv/5fa/fuAkRzYtxdfZhZ5XYso27IpapwD+/aS2TGfYVMuYPHbM6gp28vejesA2BMWazv7lhAKi+FQdiQdyH7uGDeW/PB75h3QHwB/bQ1yWOiGepSQf/WN1mub530Ecgh/ipuMqecDOnr4ZkKgYh+s+poDleXW/llTp4KqossKa1d9DRX70ESR1B/9EICCRx6meeU3hBSZwNz/GXN0zCP/8utI6dMbb//+NGoK8oJPKe7UlbzMbEr378Wf4jP26d3Lmksu6gqCQHGnrpTu30PqzTehl+2CXdtQhw0h/XTDcbzj3XeROmIEAGUHKtGWfwGAMngghQ9ejujz0fGuO/nGrcHeUkKXXkR+tx4ApJ9h/J2ln3kmBQ8/HJVquGvzt1C6BQQB6cKp5HctiX7Pdm+HDauoPX08AwaOoK2IvoO/MdVOOHnKJxr+BC0O+p0PE+4++mtxcHA44siyTH19PbW1tVRUVFBeXk5dXR2SJOF2u3G73bhcLvbv38++ffvweDykpaVRX1+PqqoJx+zWrRuTJk2if//+SLZ0+5KSEk4//XTq6upYv349jY2N9OnTh6ys9jPMaYvAahIEYYSu6ysBBEEYyXegYDigBPBKXi7rfejOvlpMiqAn++DruFocPxhJr8u95Wbjl8/fjXqsaaohsGzo4ZCpKaR6TT6HbgMGA2YEK4GbmU10paSmMfrCyHnZv20LlTt3xOyv0LlnLybdeB3PzHkvLjUPjIbG+cU9o8ZKeqyqypevv4ociE9xi1+rMVfX/oPoPXY8Kz5+n1Cz8ZHtNXocfcedCsDeTRtYPetTADr17GOtY9+mDdTu34eiyKR1yKFLn/7s27QBAEVR6Ni9BF1TObB3j3Ec4XMzcOJZ7Nu0nu0rl6EosrWOuOO2bTdSy4zX9xl3KpsWfxFOZTS29R47IbxNQZVlfJlZ1jpXe31RAstk8JlTyO1ahL+ulq/ffcMaS1VkMnJyo8731qWLo95vTVVIz8mlc59+lG3ZGDWubksd8/Tra62/oEdvRk69mMVv/9c6Nk2RSc/uQGG/AezesDaqHkpTFDI75jP6wstY+emHcecDQPf5ICywNNt/pHbxL2Rnk3vpldix93ATcnIifxeAtuCTyHMZGeRcf731uPrrL2FV9Ll0ZWdb+0i/3w0VhrhL6d8PgNThw0kdPhx/fR2EBRbelKg5My+5GBZ8yoArrqb/qWcgv/B3tixdHLUPgB5OoRx87fcp/ePvSD//PNwL58KubYhdOluNjb19+uDt0weA+lUrICywpK6FZJ47xVhf796k9OsLe0tJnzCB3LPPi5rLlZ5Ozvevi9rmfvlZQ2AB3lPGkjvlgqjn02d9ChtW4e3XL27tJwh667s4HDfoOnz5p8jj7CKY+kcoOOkNjB0cTjgCgQA7duygsrKSmpoa/H4/fr+furo6srKyKCoqoqioiIyMDMrLy9E0jY0bN7J161Z0PfJfc3p6OtnZ2QQCAWRZRpZlFEWhQ4cOTJw4kaamJgKBAP369aNfv35kZGQQDAZpCqfD5+XltRqNysrKYty4o9MuqS0C6x7gLUEQzArTzsBV7bai44SgGjwka3Y7sQIrpcORFVjJHMrsJBRLpsAyG6La6leSuQjax4mtJ5IkKW4eVZZxSW4ks0YowToURYmauyVMC/lQc4Kas/C9aTM1zly/y+226pnM19nnk2KO2/67qsiosowkuXFJbjRVNeqEZBlJktA00Tom+3k0x1Hl8OvdHqsWzDo3imzVupn/ADy+1KjXxo0Xfl3SNZvrCJ9z+2vNn7HnO/b9VsLvm0tyoypKlDCyH499TMkdqRGLncsluUHX0VTVqitSZRlPWDBIMYI+ItBsoku2/y6HjViUhA2xzbEktyfuc6wqtvUrclStUbK6Q/t5MV+rxAjnqDkT/B1A5L1IdgPDPG7rM2AT2cnWZp839lwIBxmwSfTenmgIgtBAYiElYKS2O5wolK+DJf+KPC4aB73PPnbrcXD4DtHc3MymTZuoqqrC7Xbj8XhobGwkIyOD7OxsCgsL8Xq97Nq1i1WrVrFhwwbrezE9PZ309HQ8Hg8lJSVUV1ezePFivvoq2hsvIyODcePG0bFjR7KyssjPzyc9XBt9stCWRsPLBEHoB/TF+KLaqOv6ifkNfBAE1MBhCyxd09HDF6cBdFIzjmwNltomgWUrrg9fQOnhiEDsBbnxu5T4wtV2sdraRTqAEhYDgigiulxJRZvkbnsrNpfbnVhg2caz/zSFAkQElj1k7Ir6PVp4KTZBYx6vokS2CZqGoiSfT5VlFMUQEkpdjMCSjYt7w9ghIrBSrItrxSZQw6IkvF/Ue2V7Hzy+VJrluqjtiURPrIGBy+1GDkQC0qYwMsWnqiiR3+XI8ZifK3NNLts6zZ9RAlGRrX0URcbnjohA+wW9GaGMFl2232UZV9gFL+FnKrzNk5oaNYauaWiqijc9I7z++M+riVELF91SIfrYE4soT2qqZewR+5xd9Ca82WCO4fVarzO3JXP1THash4IqK0mP70RB1/WM1vdyOCFosKWUT3sR+pyXfF8HB4c4dF1H0zTLwKw1/H4/mzZtYuPGjWzZsgVN06w6pUSIooimaaSkpDBs2DAGDx5Mp06dSEmJv26WZZm9e/fS0NBAp3C9dG5uLuJJblbTlj5YPwZe03V9bfhxB0EQrtF1/R/tvrpjSEgNHZI1ux1N0zE/PlXolPiOrE27JodafQftF2eS14sihyIRLFukx8TldidMbVPsQk2KnjTRRaMhniIX+smiDbHRsJZwuSWCiVwTw3//5h0UMxog2S7wzdcljwBFiy0ziuTxpUYJDFOAiOFoljGvGUmIFhTG633462oTHrcmqZaQg5gIVqxASRDBkmznLsWXSnN9rMCKFz0pMTalsREVVZFxe71R0SbJdkzm8aiKHBYtik1IRyKZiqxEnw9ZBq8vMqZk+2zYPqOmEI5aU8z6jDH1xJEgKxroi47MKZHt/rrauM9jbJQsTmDFHHvsc+bYzQ31Uc8pMX9jLrdxvLEW8qYANcWjYhPerUWwYo/1UFAVGY838fE5OBx16nZHfu9zLnhO+rJvB4fDprKykpUrV7J9+3ZqampQFIWMjAzS09Pp0qULKSkphEIhvF4vgUCAlJQUmpqaqKqqYt++fSiKQmZmJmPHjmXgwIEUFhaiqiqhUIiUlBQr7a+0tJRAIEDXrl3p2bMn7lYykdxuN8XFxUfnJBxHtCV88ANd1/9uPtB1vUYQhB8AJ7XACiiBQ2oubEdqVvCEr6Eq0RiU0vZoTVvQQm0QWLaLM7cnhQCRmhbzIjNKaEhuQglETFSKYGwEK+YiXdOMdLqW7trbL87biktKHMFS1cQXonaBkihFMPa47dsNgaTgyohOfzPFkW4TWObFeSJBlOKL77tgigRNVaMiFZ6wIYAS3hY7niFabEIwJoIVeyyxoieRoDUu+GNT8KKFYuQ5BV9Gpu34lKj57JFMVZZJSU2Ni6LZj994jWSZgAAEw++TkkAcmefG5TbSDhOn2pmRoFSaag9EHZe5Pfa4YtenKDJuvHHPW6+NjX7ZxtY1zbDbD9vbW2l8NkEZmzJp7hcVOZTtKYKJa/ns88b9fR1kyZF148AVn+5rjngo4zo4HBJ1e0EQ4f6t4In/P9TB4buCruts376dNWvWsGvXLgRBoEuXLvTu3Ruv10tTUxM1NTXs2rWLnTt3IooiJSUlFBcXI0kSjY2NVFVV8e233xIKhRBFEUVR8Hg8hEIhUlNTycvLY+TIkQwZMoQuXbpE3fyTJMm6qZ6RkUFGRgZdu3Y9VqfjhKItV/yiIAiCHo4TCoLgAtqvy+hxQlAN0sHd4bDGKNlaY/2+A42p7raFatuKJitAdH+hWOx36qVw6NY0udCsC+Toi3YlwR3sFlMEwzUx1r5xdSfxzoSmA8xBRbAkd1wKln0+LWYO0dY/ynxddDpk4t/F8PEYUYWYqJSi4JIkdF23jsmc1z6fmebnyYkv/VDCUSEtPIf5PrjN9LDwNnv/K0VR0BQ5ypVNtL1vHtt2V0wapGqL7CV677QoESVHzRslsMJRnMi5SBCdkSN1cMY4ZhQtRsTZopv299QS0LbPcpR4D58Xwn2zYonUMvmor1KiXmc/T7FR2tg0xLhxZZnUrOyEz8eOrSoKoscV9Zz5XtmjilECS1EQJbe1nxbuqxW7tmTzxkZJDxYrYhrzt+zgcNTY+AnsXQGTH4W6PZBZCGm5x3pVDg7tgqZp7N+/n/r6epqbm2lubkbXdUvEeL1e9u7dy/Lly9m/fz9er5cePQxH2G3btrF27VprLEEQyMvLY/LkyQwfPrzFWiZd11EUBXf45mpsRpLDkaMtZ/Yz4E1BEP6FcRvzDuDTdl3VcUBQDR5WiqBd7HxKiL8S4C7xyDoFa3IIe+22lqBviP3i2Wo4G2tyYa8/SlaEb49gJUgR1FQFXdMQRDES0TEvKpOkECYaqyVcbslyA0w0VuyFoSS5rVQv83XJ6q5izS+i0vTM2qGQbEXdzAiWruuWiJXstUhyJEUw0XpFlxQxulBko0lvWADbI2Wx48W+VyZJBZY9qhRzUW+eg0TRpUjkLFoY2UVE7HvokuKjZYkjYXLUZ8MuDlqLnlrnwCZwE+3r8fmio1IJooQtzRE3boy4TDan+dhqIJ1AhFqv8fqixpDsglq2pQi2VoPl81kW/bEky5+PHyss6JOY3JjDHKx5hoNDm3n9GuOnNwuqNhsCy8HhJEBVVfbu3cu2bdvYu3cvtbW11NbWxhkmJSI3N5eLLrqIIUOGRGqyVZXq6mpkWSY1NZXMzMw211oJgmCl9Dniqn1py9l9ALgN+CGGycU3GE6CJzVBNXhIva8slIh/YAM67VHVYFwIRV+kxe9jq50KX8BrWjhFMEkNVmLzgMg4cWlmtqiN5Im4t7lsaVGx4idR/VdruCR3XKPg2LVF7e92IwhClDlG0rqrmBosXdNQgsEokSDbomBWFFBVo44lNtplT90zMUWa8VrFSnsTXZFojxIjdDRFjnNdTJYiKNgKR+3i1h45sj8flSKoKHHCzv5cdJ1YJDXSPC+aJeaUuBTH2DmM10jREaxEEUrb+szzkjRF0BI7qXHRN/t5ihP8CaziY5/32ExI7CgtjG2lCMYajyT4e4g2FzmIFEFfatK/gbYaVpifjWQmHCeq8YXDCcisR42fw753bNfh4BBG13XKy8v59ttv2bRpE7qu06dPH04//XR8Ph+aprFhwwaWLVtGVVUVPp+P3NxcBEGgvr6eyspKQqEQgiCQn59Px44d6d27N507dyYvLw+fz4cvfIOusbGR+vp6mpqaKCgooGPHjlEpewAul4v8/PxjcSocDoK2uAhqgiB8DfTAsGfPAd5p74Uda4JKEK906BEsLRjp3dNelyZazIVXIiMJ+zZ3SuIIlhQTyWmptsXcx45dVEQJrCROcfa5D0pgJXERTHaH3y7wWqvBij0HYFzsu2wW5PYx7L3EVFlBEAy3xKh6LcWoQ4rFFFRmDZZp+mCKwSiLeLuDYTjKkWj9iSJl5rG3VIMluaU4QRArFO3Pmcdjj7DYa7AUW1qbZdNOSzVY7qioZMIIZcwapJYiWOFtKamplrW+EVWNbI8dM26OJJExe4Qq9rlkYyc6R8nGiIr4tSWClSRaB5FIU1sNK1TZcElMbiPvCCyHo0yvycd6BQ4nEbqus2fPHvbv309zc7MlajIzM+nUqRMejwdd16mvr6eqqordu3dTV1dHU1MT1dXVVFdXW/VNLpeLr7/+mrVr19K3b1927dpFRUUFOTk59O7dG7/fT0VFBaIokpGRwdChQykpKaGkpMQSUsnwer3k5eUdpbPi0J4kFViCIPQBrgauAaqBNwB0XZ90dJZ2bDlcm3b9qAis5BeJ1rYEAss0uUjoIpikBiM6RTCJwLJdyNu3GxGsZCmCByuwkqcIxu8fSUOzHPbstVaiy7ZvfD1WqLk5SmwEzTRDu8CS5TjBABFB5PYmThGUwi6CZqQi6lxFpSdGUvXi+mBFpQgmdtmyix5FSRDBSpAiKLmluPdUU1V0XbOOJ1ENltRCiqAZ5dHDkaeoGiybaE4ooBOIM70VF0FznYpipOvFbk8mkhI9Z87rTkkxxFoScZZo7EQ3G+zbY48r1lAl2XrM14guF5InJW4804yirZEn0zo/NqJpzRUexzG5cGgXNC1+W09HYDkcPrqus3LlShYtWkR1dXXS/bxeL6qqIof/rxMEgfT0dNLS0sjJyeGUU05hwIABpIWdePfu3csnn3zC2rVryc3N5ZJLLmHIkCEnvfW4Q9tpKYK1EfgCuFDX9a0AgiDce1RWdRxwuDVY0RGs9rko0eMuEiMXRtade3sNVopxPLGNhsWYuqRWa7ASGCVAJFoWd9c+USNiK43wIGqwkuybVGDFRA3s22IRY3qB2fePi2BJEroWuYC11xSZKV5mP6eENViKjDstHVe4jkmV5SgTBHOb2+uLu+BOts6UZAIrRvRIMe+dKMXWzxlzuFyJRXOKLQ0u1oUy1kUwyuTCEmoxzoNtENixESG314dL1xK+70qCdbptAqS1OqrY3+3bxLBgTFa/lSjClahOLdEccecrKkUweQRLlCK1fHZib6K0hhUxTfC3ah/HHNfB4Yjij7nwveMr8GUfk6U4nByYaX2zZs1i27ZtFBYWctFFF9GzZ09SU1Px+/0EAgFqa2spKyvD7/cjiiK5ubnk5eVRUFBAaoIMFJPCwkJ+8IMfHMUjcjjRaOnq9nKMCNY8QRBmAq/Dd6PC+YOtHxBUg4ds0964tIyGmoj1dHtEsHRVtYSSSXSaU7geynaxFOsiaO8XZZK8BqslgWXWCUX3oUp04W1fX6KxWiLZxXhLNVgQm/6X+COfLPXOHoUxDRhcktsyD0gUgbLvK3niP0NWGl7YRdDezNdKEVSUcETBfsHdgk17ki8Csy4q1jrfOm4zoqKquAQhUoPljtSDQSQCFYlgRUwuJJuQtae12SMy1mcjTpS1LrBj67d84RosJUGjbctZL3w+Yj+TKUnqqFpKETQcI43zksgEpqWxE9WpxR6TuZ/LbW/MbXcRTFJfpShhUWTUONp7a0Xeh7Y5AmpmzZytji7RMSbqkefgcNg07It+3GnQsVnHdxQ1fD3RWj+jo0EoFEKSpISRIFVVKS0tZcuWLezbt8/6P0+WZYLBILIsIwgCkiQRDAZpamrC7XZz/vnnM3r06KhapqysLLKysigoKKBv375H8xAdviMkvbrRdf094D1BENKAS4B7gQJBEP4JvKfr+udHZ4lHn0e+egTgkFIEdU2n9t2tUdtk4MHz+h2JpUXmkeU4uRuX6uXxRF1gmc5m1t3tBGl65kWy/WLN6FkVuXOdNEUwfGEWcdWLpOjJMeYFh1qDlYhEtWf2dSaru0o2dqwRhilCLKt3d0RgGbVIStxciWzhTSLpcwpyoDmqNspyFkxSk5PM+bClFEFTnCU6/kQRldiGyfbnJY9p5Z3Apl1yo4RC1uclUYqgEvOZa8v7H1cjFha4iQ1PZBAEK1obG1VNZnKhxMwRPWZ04+rkLoJtr8GKbYWgysbfq7mvPUVQ143zmaj5cbQxhhJlkpHoWJJhN1VpKdW4reM5OBwU9WXHegXfaT788EPWrVvH5ZdfTv/+/Y/6/JqmsWbNGpYuXUpZWRmiKJKXl0e3bt3IzMxE0zT27NnD7t27CQaDuFwuunTpgiRJaJpGeno6ubm5lkCUZaNeuVu3bvTp04eMjIyjfkwODm0xuWgCXgNeEwQhB7gCeBA4KQWWokUEySEJLCU+l7wwJ5U7JvY8rHXFzRMKocc4y8RGsGK3mRdwuq5FPZcohU5TI6Ih9mIwmclFXIpgTF1R1FoPoQZLSrJvUpOLmKiBIIpRdVeJ9o1dk91RL8oow54iqMhR9V72fWNT8sz1WhGs2BqumBosUXQhiCKKHIprzBxdg5W4cFZySyiykvR8J6oJiuqDlSDt0y4C7WO63IbLo92d0t441z5PrKteS8RGl0yBmyxF0G4OYreoh0hkq6UarETixzovCdLxWho7NhVWijmv9v1Swrn9EVEcLdTiBJYZCbWJ5Ljz3UZBZApX8/OS6HmIPzcODkcEM4I14BIYeOkxXcp3jYaGBlavXg3A/Pnz6devX5xr3eGgKIrV2NZscltWVoYsy+Tl5bFr1y4WLFhAZWUlBQUFnHbaaSiKQnl5OatXr7ZqovLy8hg0aBC9e/emZ8+ex0W0zcGhJQ7KBF/X9QPAs+F/JyVNcuSu+CGZXKjx9VaeI9z/CsICK3bqBHfh7dvEcF+ouAhWguiNPVpiRS/cHhQ5FFcLFXvRaF4YirYL79jC+UQW8a2RbN/Y6Fhk/+i6l5bmaqknlnkcQTPtT3JH6tiU6MiSOZe5rxhzriyTh/DFuhIWWdFOfPFRsUgfryQRrARmGub+QX9zXC1Q7BixNXaxkRa7ULCLQPuY9vox89zFC7XoxrtS1Lk2Pl92jG32z7ViRbCSpbLGig77z0RRJvOxOX/SekF34hqllqJjhjCSLOv8pCYXSaKYkicFJRQ0zDrwJnyN+fls7QZLS0RqwIzPS9zzBxkRc3A4KOrLQBDh8n+Dy+nNczTZsGEDAGPHjmXJkiWUlZXRpUuXQx5PlmV27drF1q1b2bRpEwcOHLCeS0lJMb7zYmo5c3NzueKKKxgwYECUuNN13drX6dnkcKLhfGJjsAusQ7FpTxTBSjmCd4OseUIh9LgUweimsPafYFzMCqLYYqNhu2GFJ3zNbtZduL1eFDlk9WuyXhMXLYiu7ZIkKa6uI7Z+py0kE0iJnAWNY4lOy2pprihRFVOPZaUI2iJYgq2OLWENVgJbeDDSLSP1PApaTA2XJLnRrDEjUY+ENvO2dZopcYmOK1E6X+w5Um0pp4kjT5EUw2Rph2YtkPl5SdRoOFFaoYknNRWlLlpgeVJTo+p+IudFT5gaGonqJI7keJK5CCqKNX9snVG0wErQ0y1mbCVuvQluYCTpg2WeE0U2zm9qVjpKKJjUeCI6RTA+cpYsfTbZWMlSBK3otBPBcmgPGvZBWr4jro4Bu3btIiMjgzPOOIMVK1awcuVK8vLyqKmpASA9PZ3U1FRL+GiaRk1NDRUVFVRUVFBVVWXZm9fW1lJfXw+Ay+WipKSEwYMHk5KSQjAYpLm5GZfLRbdu3fB6vZSXl9OhQwf69OmTsObKrKdycDgRcT65MdgFliQc/OnR1XiB5W4Ha5DWUwTjL4jMFLlYhzF76lGsKQEQ5xYXqxfFJNECUwCICY0B5KjXtoVkLoJtFVgtzWUf2+7UZ7q02ecRJQnRliKoyDKxLnHmvrGizp7+ZxpFqLJsCSTRFgUy1y9Kki2CFVmn/U5fMvFpnvtkNW921zrzjTWiIkneU1sUJ96wwrg4Nz8vYgIXwVhhbX9PPD4f/rraqPXF9niy12AlFB2yEvWeWUIjxkUwkROgOX/8c9GCMblNuzfqGI15lBhXysQugrGfITMq6/Eaa0p8rJFIqH2d9vHbEnGyW+cn+ls92PEcHA6a+jLI7HysV/GdQ9d1du7cSVFRET6fjwEDBrB8+XJWrFhh1RkDuN1uy3lPCRvqmGRlZSGKIpmZmZSUlJCdnU1hYSHFxcV4wmUJyejRo0e7HZuDw7HGEVgx2AVWo9x48AMo8SmC7RLBkuPN3+0XfuZFYuzFYlQEy3QuS3ChnkisSe7E/1laKYIxaUn2C+/YFMEj6SKYqHdS1PxtSRFMYnJhurTZ55FiXARNBzYIi1iXlDSCZfbHMmuwlLBbnP1cycFA3LZk4yVasx0p3NdMtUWVEr3OeN4UWLYarFj3P5trXaIaLHvqYLRZRuLPhj1FMJFRh9vri6r7Mc+LrusJHe1URY56z2Ld78w5EkWpkqYP2muwkrgI2qNm9mitFhvBSlKDpcW9381R603Ym850fEwg2kyxZdrit4R5w8WIqibug2eO01ZXQgeHNrPxY9g2B/pOPdYrOWnRNI19+/aRlZVlGT4EAgFWrlxJQ0MDvXr1AuC8884jKysLXdfp1KkTAI2NjdTW1uL3+0lLS0OSJHJycsjPz6djx46tiigHh+8qjsCKwS9HLtZl7eDv1iaKYNEOjee0RBGsBDVY9gtJQRAQRTGqD1ayC+5ErmqRC0Uh4Wti6zQiF9HJ61YSmUAkIxJBEy2jDmhBYMUIq5bmsp+HWNt6M1UvkYugGcmx26S73O6kLoJqKBRJEXTLcdEqye0m0NgQt60lV8IWt5vpfMkiWElqsOLc6OxpcknSDmPd71pK1UvkIhjby8vljrdFt0ewEhku2FPdEs3r9npBEBKKKG9aety5SHbssa813s/oujX7c/Zjso+ZaD+XFHm/PamJ+3YlPNZDTBFs7fjs4zgRLIcjzls3Gj/VYIu7fdfRdR1N03C5Ehs1JSMQCPDxxx/z7bffWpEmv99PKNzmolu3bgwdOhQAn8/H5MlOg2cHhyOBI7BiaFKMCNZZRWcxrc+0g369botgNao6pbLKt4WZXHXEVhieJ5HJhU1MaTERAxPB5ULXIimCsRfciVzOEtVq2Ul2MWu/YEwmsA7GRTAqIhaKfBkHE6QIii7Jisy1paltstom+wWs1QfL7Y5qNKwostGbyfaayL7Rf2KhcANiye1GU6IdA801KsEguq7ZTDrcUXMnIpl4jIsqxZpcJHi/WxIoCV0EoyKV0e6CUSmI2NLtbMdmEtvLKzYlT1NV23lJliIYLXbiWwcYoi1himArDoPmeYlrORAn6mzptUqM82MCQWvsJ0edx0CDUceQzFbe3Ob2+hKOeTApfYne22T7ODVYDkecjM5QuxPG3HasV3JcM3fuXBYvXswDDzzQooNeIBBg586dbNmyhV27dlFZWYmu64wePRqXy0VTUxNpaWmkpaXRtWtXunXrlrD+ycHB4fBwBFYMjSEjLfD/Rv3fodm02yJYTZrOpoCGy31wd5zaNE9IbjGCFdt3CIw7YPYIliLHC6yW7oZHhEe0tIuLUiRIEdRUBV3TLDe1ZKYLLWFdjMdkXCaKYNlPjX0dScdOkiLokiJW6VaaXlSKoJEqZ6+1kqTkKYKRMSTrvCj26IU9HdC2LdDY0OIxJN3eWg1WgqiLS3JbRiaxNUyW0YMsR4kWMESeXcy53G4rZbKlz4ZJrBOiWUtlno8oUa6H+7NpapT1vpGul6D2q7UolBKpg0ueIuhOeLPA/DtKJFaNz4a9BiuxwFLliMW65I58flJaEVjmmmL3iXV/bAl7NDnR8dnHURNYuDs4HBSNFfC30XDtG1B0CgRqDXHVZ8qxXtlxi6qqfPHFFwB8+eWXTJw4MU4U7d69mzfffJOGBuO7wuPxUFRURP/+/enduzddu3Y96ut2cGgvdE2j4UA1mXkdj/VSkuIIrBj8inFhk+ZOO7QBbC6CAQ0kBNyuI393KJGLYKK0vtiLJSHGpj3WhCHW3MD+ezKTiDhDAVvNivEzUg9j9uJKdsHfEsn2NaM7dmw1uHHrSDh2TNQq9neX5LYiZUYEK5JmGRsJFCU3zeEIROyc5oWzKLlxSUp4W3PCeaRE25IcQ0vvjT1FUIx5faKIpVmXZ49mRNUhWXVi0Z8L0SWhaxpyMBh17HZB01KKYGwvLyE8n3lRb4oGe7ROlWXEFFfUY9OswT6fKisIgojociWM0qiy0ehXdLkSRpfMtbokKb6eUDZ7b0WLUvP3hBEse7RZU9E1LSrSGrRqsJKnCCpW7ZcUtc7o4257iqApaFtsNOxEsBwOl62zDVH14hQ48xEI1EF6wbFe1XFNaWmp9fuCBQuQZZmzzz6bffv2sXbtWurq6ti0aROZmZmcffbZdO7cmaKiIseBz+G4Ys2cmVTuLGX0RZcfljAKBZp557e/ZN+m9fSbMJEzb7odX0Zm1D5BfxOqLCMHg2R2zEcQBBRZZs+6NXTq1RdvevrhHk6rOH99MZgmF4cqsHRbHyw5fJXvkdpBYMkyekwoR0sQdYq9IBJtJheaosRdmMcaVth/l5IUs0bSwKINBWJNJqIElmW6cPgugnIw0PLrYtaRCHsUJJFtvcstEWxqsrbZTS7UmPNoTyOLF1gR8WS+X3KgOaGDnNVHLGpb4mNIJrxckoSmqpFoU4xINcfTFMWWUmnra5XgPXVJEsGmsB27IFgulOZ5lsNpkInGiURD498Td4JeXoahhhy1BlFy47JFEN22QLNpViHFCBlVibj0iQmMHCKGEfE27Jrts+qyvW/258UoYxDZ9pwcJWrN+olEPassoSpFPj/mOUloPKFEuwhqCVOEW484qTHvraaqUdFm+z6OwHI4bKo2R36f+7jxM+O77SBYXV1NTk6O9X+wrutR5lPbt29HFEVuvPFG5syZw6JFi1i5ciWBQACXy0VGRgZDhw5l0qRJlomFg8PxxMZFC5n13N8A2LlmJd//w19xe4wv76baGqp27aSw/8A21eV/8d+X2bd5AyXDR7H5668QRZHzfvJ/1vM7vlnOx888RdBvXLMV9hvAeT/+Pz7685Ps37YFjy+VUy67in6nTiQ9Oyfqu+5I4gisGJrkJtyiG4/r4Jxx9FAIpaoKpaLJ2maWY7VVYKl1dWhNTeCScBfkG2McOIDq9yNgONRpqoogiigV5VERLDkUxF9fFxkrwR1sw+TCha5pBJoaCfibkqaMNR6opr6qAoCGA1XGc9bFcGKTC39dLfVVFfjr6yxLePvzteVl+ML/+TeH1xrbU6slDqZeK9Hr2hotixZY8fVb9hqsptpalFAoumFukmgYQH1lubXdpSSIlEVFO+LdDw8lRRCw3stkjYYbDlRHRczMn4GGeuqrKmisOWBtM0wYAjQ31CNJERdK8/X2YzR/Njc0UF9VQVNtTfRztvPqTolPyTWiZUFjDQeqI+clLLDqyvcTyozcuZIDAXwZmdb4TbU11FdV0NxQb22TJDeBxkbrnIAtzc9tRB/tz1nzho/dXI+J+XckulwIgoi/rs56PuhvJiU1IhzNlEl/fWQOMwIrJfgMmCmCDdVVUXMCyMFgVIqg/W/WbNgsBwNxr4ulvrLCOi/mWLXlZVHrMG9iqCG51fHspOfkRt28cHBg74r4bRmdjv46jhM2btzI66+/zvnnn8+oUaPYvHkzH374IaNGjWLSpEkIgsD27dvp2rUrRUVFXH/99axcuZI9e/bQrVs3Bg4ciM+XuNG8g8OhIgcDvP34o4iSi0k33EZ+cdst9Zsb6hFE0TKOAlj56YfkFHbj1Guu58Onn2DHN8vpM3YCNWV7mfHoT2luqKegR2+mPfIb63W6rlO2ZROaqtC1/yAAavbvY/WsTxl2zvlMvvmHzHv5OVZ9/jFdBwym36kTmfPCP1i3cC45XboyaNJZiJKb5f97lxfuvAWXJDFu2jXs37qZha+9xMLXXuLHL74etc4jiSOwYmiSmw46eqVrOnvu/SmNcz5H6jwc39gfAmBKm7akCCoHDrB14hnoYUHU5amn8BR3p/SKK/mqdyEFdU0U1jQwb0Axg3dX0O1AA3pWZJ2vP/ozKkq3WY8jKT2RO9iZHfMRRJHmxgaevf16FDlEYb+BUeswU5Jm/uNPcWvs2L0H21cuIys/Op1DchupVUvee5Ml770JQEpaZG1mof5/Hrw7bi7hICzszbWlZmYTavZbdUmJSM3OjntdbI0PQHqHHEs8WMdji9RZrw33SBJdLiS3x6hnc7lY8t4bQHT0xW1zw/N4vYguybK5nvfK8wnXYj62p8l5vKlx+yY6Boj0Mssv6Rk9bni8eS8/F36cmuT5Z23bUq3n1n8xj/VfzIua3+PzUbNvDzX79uDLzIocd3ht1jHazvumRQvZtGihbRxvguONPjZvRiYer4/6ynKe//HNtv1SUV2GgPjPz++JOxd5RcWGWBMEvnz9Vb58/VUA0nPzjHX6fGxb/jXbln8ddy48Ph/rF85l/cK5ceN6fKnW58C+HsD6O/L4fKz67CNWffaR9VzPUafEzbP6849Z/fnHUdvN82c/D2k5OQDMeu6vceuJrNl4v2Y9/7e45xuqKuPWmgx3+PgBXrzn9oT7KHKozeMB/PD510i1fUYcHNi/Nn5bWt7RX8cRprq6moULFzJ+/HgKCtqW8qhpGgsWLADgk08+4ZNPPrGeW7hwIStWrKApnDlx7rnnAkYUfPTo0YwePfoIH4HDyUSgsZGU1NS46ExzYwPzXn4OTVU594f3JMxMqqvYzwdPP0Hlzh0ATH/gLvqMO43zfnxfwgjT5iVfseTdN2lurCfQ2GhlYHQs7sGU2+9CDgUp27yR0793Ez1HjMGXmcWmrxbSe8x45rz4L1RFYfyV32PRW/9l6ftvcfr3bsJfX8c7T/zCuK4VBCbdcBtDzz6Pz599BsntYeylhnXcmEuuoGzrJj5/9hk+f/YZAEZOvZhx064lJdW4Du01aixbli6m77jT6NSzN7qmsW3FUvx1tVbtdXvgCKwYGuXGgxZYdZ/sQMiYRkq/PYhZxdb2BlXH5y9Hk4qTvtZEra5Gl2Wypl1O3dvvIO8vQ/Aad/SbMzNg4GA83Upg4edUjxrGmIlTCB2ohNnGhVxDdSXdBg5h8OQpfPLMU1H9i3K7FnHmTbfTbeAQFr31X/y1tShyiEGTzmHUBZdErSOnsBsX/d9DBJqie4B509LpNXocRYOG0G3gkKjnRJeLyx/6DXWV+yPjdI4U1PYZOwFBFOPSizp0Lmz1vNjpNWYc5//k/8jt1p30Djk01dZQs38fQX8TnXr2obJ0O3lFxVTv2UVu1yLrdcOmXEBmXj5d+w+MG/P7f/grTQkE1rRHHicUaCa7UxcALrj7ASp2bierYydLzFz+0K+pqyxHQKDHiMiX3Tm3/YR9WzaSlt2B1KxsfvD3F2luqOfA3j2EAn4kt4eS4aOsNCxd0+gxcgwAI86/mOxOXXBJEj3D206/7iaKh48kJTWNjt1LotZ6yzMvWIYe1/3uz2TlR98JHnD6ZFJS01BVBV9GFpkd86Oez8jJ45Kf/QJ/fS0AvvRMsguMMS6450Eqd+2w9k3vkIs3PZ0JV11H1wHG3aTcwm7W8/0mnI7k8aAqhuW5+f5OveunVOzcbu1nnheATr36cME9D5LeIYfcbkX4MrPo2L2Eqt076di9BG96Op1790UPG6tIbg89R45B1zUjpzpBylr3QcPw+FK5/Oe/sqKvAHlduwNw7g/voXzH1qjXCIJIjxGj6TliDJW7S+PGNM/LmIun0bGo2FqPSZfe/QC49IFfcqBsT9Rz3foPjnp8yc9+wYF9u6O2uSQ3vUYbQmz8FdfSpW8/PF4fvceMx5uekfBmgoBAyfBRpGV34OKfPkpzQySCLYouCkp6sn/blri1JsKd4qXbgMF07tXX+rzEzlXQszcVO7ahhV1I24LZfNnBAYCmami2/X9782ew8SMoGHTs1nSEePfdd9m7dy+yLHPllVe2un9VVRXTp0+nrq6Oc845B03TqK+vp66ujosvvpiNGzeya9cuqqqqCIVCjBo16igchcOJjqoofPj/nrBuhl/ys1+Q16279fyiN//DhvBN053frmLwpLPp3Lsv+cU9yOxYgBIM8v5Tj1NfWcH5d95P9yHDWf6/d1n24TtUlm6j95jxBP1N1JTto0vf/hQNHMK8l5+j8UA1vceMRw4GcKd46dSrD998+qF1EzQrv4AhZ52L6HIx4PQzWfnJByz78B12rvmGSTfexojzLuLA3j0s+9+77PhmObUV+0HTOfu2n7Djm+XMe/lZvn5nBs0N9Zz34/tI72DcfEzL7sA1v3mazV9/yYYvFzDwjMn0Hj0u6px06dOfLn36W48FUbS+b9sTwd6R+0Rg1KhR+vLly9tt/Fs/v5WAEuA/5/+nza/Z+4uv0EMaNL0PKUUgjWB5k4K4fRbFOz/jm+fe4YbxxS2O0bxuHaWXT6Pwmb+w9667ybvzJ3iKi9n3f/fz+aj+9B1/On3GTeC9J39F8bCRXP7zX7HhqwV88sxTgHEne9Ckczjlsqv4x63XWh/Yd598DH9dLdf97s8AvPLTn6AqCjX79jD17p/Rb/zph3imHBwcHNofQRBW6Lp+wlxdtvd31AnNzkXw0nlwyT9BdMOQK471io4Isizz29/+1nLqvf/++0mNaTthsn37drxeLwsXLmTjxo2cfvrpVipgMmJrshwcTIz64UisZMl7b/Ll668y9Ozz2bpsMYGmRooGDWX4uReS3akzL9/3QwafOYWS4aNYM/tTtn+z3Eq59/h86JqOEgpx2YO/pHjYSGvcbSuWsuzDt9m7aQOiKJLdqQs1ZXvRNQ3Jk8IVjz4eJWLAiKKtnv0poWY/gyedQ3Yno9ay8UA1L9x1K6osk1/ck+/99o+ILheBxkZWfvoB+zZvpEPnQgZOnEynnr3RVJV5rzzP9pVLGXXBpQw/98KjcGbbTrLvKCeCFUOlv5Ke2T1b39GGZWzh8SFIHnSgWtHp0bgHt+JvUw2WHm76J/p84HIZNuyhcJqfqlhOY4Blz2o+hoh7WqL+RfY6F0EUrXqKg3Hwc3BwcHBwOGRUBT6+3/i9+FTILmp5/xOIsrIydF1n3LhxLF68mN27d9O3b1/r+VAohN/vZ8uWLXz8cSQ1eMKECZx55pmtju+Iq+Ofuor9eHypcW52raFrGrvXryU9J5ecLtFZPU21Nfjraskq6BSXQl+5q5Ql777B5q+/YvCZ53DWD36Mpqp8M/N/lAwbyVm3/ojRF13GvFeep3zHNt793S8RBBHJ42HctGtIy+5Az5FjkAMBqnbvpHLnDip3laIqMj1GjIkSVwA9R46h58gxNNXWIHlSSElNpb6qgv3bttCldz/Sc3Ljjs2bns7YS+JvoqTn5HLFo79lzaxPOO3aG62sIG96OuOv+F7c/qLLxeSb72DyzXcc1Lk91jgCK4YKfwWndD7I0GHY8EBwp4DLDSpogKgaIsfThhoss/ZKcLsR3G7DJVA2mgnrmmb0/AnbqwvhonHzMUTuYiTqSRVlIS66UCwbbeftd3BwcHA4CmybCxXrjN8zT66eTLt3Gym/o0ePZsmSJezatYu+ffuyfv161q9fz6ZNm5DD38lpaWmcddZZ5OTk0K1bt5aGdTgB0HWd2c//nTVzZholAX970apr0jWNr978D9kFnel/2qSE11yf/O3/sfGrBQiiyBWPPkG3AYNRZJkvXnuJ1bM+CbsvpzD1rp/Sa/QpaJrKV2/8h6UfvI2AQE5hV9bMmUlBz9740jNoqq1h6DnnA5CV34lLfvooqiKzetZMyrdvYeDEyaRld7Dmd3u9dO7dl869+8atLRH212bm5ZOZl9/C3skp7Nufwr79W9/xBMa5wrbhl/00yo3kpx7kByYcwBKkFBAldNXQXKJm/IfqblMEKyywPB4Ej8focxWS0cJ3rkzrZEgcwQKzQawLBCGq75DdgEEURZRwtOxQXfkcHBwcHBwOin3fGD/vXQ/tZIt8rNiwYQOdOnUiJyeHzp07s337dioqKnjzTcP0acSIERQWFpKdnU23bt3wJGl54tD+HNi3h+b6err07X9IkUGzrKZixzbkYICyLZtYM2cmeUXFVO0qZevyr63SizVzZlrGX1+9MZ3M/E5k5OQy6IyzKB42ku0rl7HxqwUMmnQOpatXMOff/+T8O+/ni/++TOnqlQw+8xyjBuqj9/j4mac490f3sH7hXLavXMagSedw2rU34EvP4O3f/oJ5Lz+Hqsik5+ZRMiw6W80luRlx3vGVVvddwBFYNiqbKwEOXmCFEdwp6IR70gAuzRAybYpghUWP4LYLrJAlsHRNQwsLKiEcTo0TWOEGsZLktvoeGSmCkbdZEEWUUNDa38HBwcHBoV1ZOR3m/9ZIC8w6OHOj44WysjIaGxvp2bOndZMTDPfAPXv2MHnyZACGDh3KJ598wrPPPovH4+Gee+5JWo/lcHSpr6pkxi9+RqChnpEXXMoZ378FMETTuvmzWT37U7r2H8TE6yJOqdV7djF/+r8pKOmFIodYO+9z1JBstcIA6DX6FC687+f8+67bWPHx+/Qddxr+ulq++O8rFA0awsgLLmXlJx+ihILs2biOzV9/Rfchwyjbuom8omIm3/JDdq9dzbtPPsb0B+5CSklh8i0/Ylg4ElXYbyCv/fwePvrz7xFEMeo5gKl33s/7Tz9O2eaNjDj3QivlzuHY4ggsGxV+o79Lx9S2d5gO7bG5e0kpoIUbtwKiZjhxeaTW75JYAsvjQfC4IwJLDEewNA09nBJo/uduTxGESETKaKQasWm3R6rsf3jJmtM6ODg4ODgcETQVPvyJ8Xt295b3PU759ttveeeddwAoLCzkzDPPxOv1kpWVxaxZs5AkiaFDhwJGtGrz5s1UVlZywQUXOOLqGKLIcpSt+PL/vUuwsZHCfgNZ8dF7DJo4mbyiYjYt/oLP/vUXvBmZ7N+2hR4jRtNtwGBCgWbe+/2v8NfVsXP1N+i6Rs9RY0nNyqZTz96kZmbTWHOAQWechSi6OOXyq/j8X8/w7ZzP2L3+W5RQkMm3/IicLl3pMdxwGpYDAb56czrrFswlLasDF977IJLbTcnwUVzys19Qu7+MfhNOj0rFS++Qw01/fpY9G9aS1bEgyiUZIDUrm2t+/RRyoDmuFYvDsaNdBZYgCOcCfwFcwAu6rj+ZZL/RwNfAVbquv92ea2qJ6oDRUDTP2/aeHBV/W2X9LkhuUCX0sI2xSzUiRT5366dZl02B5UZ0J4pgqVYEyxJYMREse6NSzbRpj6nBsvdEcCJYDg4ODg7tyu4lxs8hV8PEnx3btRwCu3fv5v3336dbt24MHjyY+fPnM3369Kh9Jk+eTGa44bkkSVx33XXHYqknLf66WvZuWk/X/oPiTCRURSbQ2BglSFRF4bN//plNi7/ksp8/RvfBw1AVhY2LFtJ77Hgm33wH/7r9ejYu+oLxXbux+O0Z5HYt4qpf/Z4Zj/wf7zzxKMOmTGXXt6upqyjnql/9nrxu3VGCwYRmDiYDJ05m45cLrJ6E46ZdS06X6HpDt9fLGdf/gInX3RLXo8pszZIIj9dnibRECILgiKvjjHYTWIIguIC/A2cDe4BlgiB8qOv6+gT7/R74rL3W0laaQkZDv3RP27o661qMxb3LA5qEphvCJyVo9KXJz0xpfSzTRdCMYMkhdDmE5gmnHGqa1X8mkiIYE8GyCSwliYugPYLlCCwHBwcHh3aldpfxc+LPIPfgHHqPNYqi8MEHH5CRkcE111xDamoqgwYNYsuWLbjdbiorK+nRo4djVnGYHNi3l6UfvMXwKRdQ0KNX1HMbvlrA/Feex19Xa6TO3XQHgyadDUDZ1k3Meu5vHNi7m9xu3Qn5/fSbcDqbFn9BTdk+AD5/9q/c8PTf2L3uW5rr6+h/2iRSs7LpNmgIS957g9LVKzmwdzcX3PMAvvQMrvnN03z0lz+w4uMP6NC5C5Nv/iFdw43kSWv52lAUXVx8/8OsnTeLlLR0Bpw2Kem+seLK4eSjPSNYY4Ctuq5vBxAE4XXgYmB9zH53Au8Ax7wteZNsCKxUd9vuAmj+6CangiscwdJ1VF1HUozxCjJbb7ZpugjidiO4PZZNux4WQZqqoqstR7DMWitJclsugoqiJI9gOSmCDg4ODg7tSXON8dPXoeX9jhHbt29n9+7ddO7cmZKSEkRRZMeOHTQ1NbF7926qqqoscQWQmppqpQM6HD6qovDuk7+krnw/ezeu44an/o7k8VBbvp/ZL/ydnWu+oVPP3pxx/a2snTeLz/71F9I75CDLIT760+9xe1NIz8lFcnsIaI18/e4b5HXrzuSbf0heUXfeeOxB3njsQYJNjXgzMikZNgIwGs4v+/Ad9m3eSMmwkfQZOwEAX0YmVzzyOIHGRlJSUw9aCHl8qYw4/+Ijfp4cTjzaU2AVArttj/cAY+07CIJQCFwKnEkLAksQhNuA2wCKitqvd4YlsKS2CSy1PhT1WBDd6IILDQjpIczKq/SUNqQIRkWwPFYESw9HsHRNs+qqhGQugrYIlt1FULKlKIpOiqCDg4ODw9HCfwAQwJt1rFcSx/Lly/noo4+sx5Ik4XK5CIZbmQAMGDAgqqeVQ2JK13xDXrfupHfIidq+4Yt5NDc20rF7MdV7duPx+egxYjTecDRo3YLZ1JXvZ+jZ57N61iesnT+boL+Jpe+/hSAKjL/ye4y95EpEl4teY8Yx/YG7eed3vwSgc6++XPbQr6yx5FCQhqoqOnTqbF0nnfuje1n6/ls0Hqjm9Otutm4sZ+TmceZNtyc9Hm962zKZHByS0Z4CK5GzQ0xOHX8GHtB1XW2li/lzwHMAo0aNih3jiNEkN+GTfEhi205LrMBCdIMgouqg6aHEL0pCtMmFBy0UQguFoiJYZlQqUR8siESkXLYIlirLiFGNhm0pgk4fLAcHBweH9qT5APiyQTy+nM3Wr1/PRx99RK9evbjsssvYt28f27ZtIxAI0LdvX/LzDTfh7OzsY7vQ4xB/XS271q6m1+hxSB4Pqz7/hDn//gfejEwGnDaJytLteFJTObB3DzVle+NeL7pcFA0eRu/R41j42ksU9hvA5JvvYN+m9cz59z8A6DlqLBO/fwsdOnWxXuf2pHDFI4/zzWcf4XK5GHXh5aTYTETcnpS4Zr0DJ05mwOlnoqmqc83jcFRpz0/bHsCemNwV2Bezzyjg9bC4ygPOFwRB0XX9/XZcV1KalKY2R68A1Ppg9AZRAsGFhoDXdXACS4sVWPX1htGF2x7BMowrRFfyPlgALreEqijouo6mxrgIOhEsBwcHB4ejRXMN+HJa3+8osmnTJt59910KCwu5+uqrkSSJXr160atXr9Zf/B1CVRS++O9LrJnzOaddewODzjiLvRvX88lfn6a5oZ5TLr+GURdcwpczXqFr/0GEAs2s/OQDMjsW4HK7ye1axJCzzqV46AgqdmzD5faQmdeRLUsXsW7BHEpXrSA9N49zf3Qfgihy0f2PsHbe53Tp2z+poUNGbh6nX3vjQR2HIAiOuHI46rTnJ24Z0FsQhBJgL3A1cK19B13XS8zfBUF4GfjoWIkrMCJYae60Nu2rNSvUvrs1atuy0npyyCZTTCXtIAWWHgqBKCJIUnSjYZvAMo0rBMGswYo1uTDeTpdkpAiagsxuUyrYTS6cGiwHBwcHh/bi80dh7TtQOKr1fY8CiqIwZ84cvv76azp37sy1116LdJJfePvr60jNjE7P1DSVZR++y5YlXzHhqu9TtmUjnXr1IdDQwN5N6xlw2pkU9hvA6s8/ZsXHHwAw98V/MffFfwHgy8wis2MByz98h9LVKwj6mzjj+lvJL+mZ1Co8r1vEor9z776MvfRKyrZupqBHL3zpGQBkF3Ti1Kuvb69T4eBwVGm3/1l0XVcEQfgJhjugC3hR1/V1giDcEX7+X+0196Hil/1tFlhm/6tSUaNa8TNSTEfWRTx4UNDpmVF7UHPrIRkh3N1dcEf6YOmSCzAcBM26KjNy1VINVqjZb6UJ2u/cWBEsQXCa0Tk4ODi0gbDb7XJgr67rFxzr9ZwQbJ0Ni54xfvdlH9OlhEIhli1bxrJly6itrWX48OFMmTIFr7d1A6oTmZWffMC8V55n3LRrGTn1YlJSjeub//3xSbYuWwzAu+F6JjvrF8zl0gd/yboFc+nUszfn/ug+3vrNQyhyiHN/eC/dBg4h6G/ktYfuY//WzYy/4nuW+19brcJTUtMoHjL8CB2pg8PxR7veutF1/RPgk5htCYWVrus3tuda2kKj3NhmB0E9aESPfqX5ubqvhr4hyPieBdSWCvgbqunXqYYac19Na9WJRpdtAsvjQZdldFlGkyQgZNi0hwWW6R4Y7yJo1mBJqLJiCTJ7KqApsCTJTUt1bw4ODg4OFncDG4DM1nZ0CLN7aeR3f/UxWYIsyyxfvpwvv/ySpqYmunfvztSpU+ndu/cxWc/RRA4E+GLGqwAsfvu/bF26iCt++Tv8dbVsXbaYMRdPY+AZZ1O6eiXdhwxj06KFdOhcSPfBw3jz1w/x1m8eBmDSjbeT27UbN/3pWZRQ0Oo3lZKaynVP/hklGKRD58Kk63Bw+K5ycsfGDxK/7Cc/Nb9N+2phgdWETp5HBE0GPQUPOg2hRrSmJmtfXZYRUlruhaWHQghhISR47BEsCbQQuqqiyEbKn9n/Ks7kIsZF0IpgueNNLpz6KwcHB4fWEQShKzAVeAK47xgv58Rg9Ruw4PeRxzU723W6hoYGZs6cSVVVFePHj2fo0KFUVFTwxhtvUF1dTY8ePZg0adJJ069K01S++O8rCKJInzHj6dSrDxWl29my5Cs69+5HjxGj2bNhLUooyGUPPkYoEODTvz3N248/guT2ILokRpx/MWnZHSxTiPFXfM8a/8pf/o5Fb76GLzOTYeecDxiCym4oAZCRk3f0DtrB4QTDEVg2muSmg45g+YFcr4CuhlBDApIAeqAWtakxsq8sQ1sElj2CFRZYmiRCyIhWmYJJUxOnCJq1VqaLYCRF0N5o2IhgOQLLwcHBoU38GfgZkJFsh6PVSuSE4b3bjJ89zoDt8+H0n7bbVMFgkFdffZXa2loyMzN57733mD17Ng0NDaSmpnLddded0OYV6xbMoXT1SsZeeqVVx7RtxVKW/+9dBEFk1cyPmHTjbcx58Z/Wd/4Vj/6WHatX4HK76TpwMG5PCpLHzf/+9CSqLHP6dTdbkahEpGZmcdatPzoqx+fgcLLiCCwbB2VyYQksnWwJUEOo4aCV7q9Ck2wRrFDrhheGwDJEj2gTWHpYmOkJarBiI1hiuNbK5Xaj2Ewu7DVYZqqieJIX9h7vyLLMnj17CAQCx3opDg7HBV6vl65du+I+jm7+CIJwAVCh6/oKQRDOSLbf0WolcsKhBOGxunadYtasWVRWVnL99ddTVFTEokWLKCsro6CggFGjRpF+AvczKl29kpn/+BMAW5cuZuAZZ1E8bCRfvPYymR3zueKRJ3j1gbv4/Nln6NC5kMt+/ive+e2jvPWbhwDoNXocbo9xDdFz5Fhu+uO/CPqbyC/uccyOycHhu4JzlW3Dr/hJk9omsPSgiiZASIdsN6iqjO7XEQCxqRJNtEWw2iiwxEQRLJcRUYuKYIVTBJPatEuSEcFKUINlpghKjoPgMWXPnj1kZGRQXFzs1MI5fOfRdZ3q6mr27NlDSUlJ6y84ekwALhIE4XzAC2QKgvAfXdevO8brOn5RbN93g6e161TV1dWsWLGCMWPG0KOHIRpOP/30dp3zYKmvrKBi5w56jRqbdJ+K0u3s+GY5I6deghS+Dqjes5uP/vx7OhYVc+H/PcTit2ewevanrJ71CYIoctkDvyS7U2eu+92f2bpsMUMmn4s3PZ1Lfvoo//vTk3QfMpxTr/5+1DxZ+QXteqwODg4RHIEVRtEUmpVm0jxtjWApyC4BSRNIFzTq1CBCOKDkatyHJka+ZNoksGQZwW1zEZRlQ2SJkZ5XZkTKimDF2LRLthosTVES1mA5KYLHB4FAwBFXDg5hBEEgNzeXysrKY72UKHRd/znwc4BwBOt+R1y1QmO58fO8P8CoW9p1qoULF+JyuTjttNPadZ7DYcH0f7N5yVdMe/hxug8ZlnCf2f/+B2WbN7Jl6SJ6jR5H7f4yNn41H09qGhf/9FGy8gs4/yf/x4jzLsJfV0tet+5kdjTqxXO6FDLm4oiQze1axI3/7x9H49AcHBxawBFYYfyKH+CgIlhBEfLTUhCURoLr3kOd9hA7djRTVLMDzZUd2bfNKYKRCBaA1tyMFhZYmhpJEdRas2lvqQYrPJ7TA+vY44grB4cIzt/DSYIpsLK7Qzu+p9XV1axZs4axY8eSkZG0PO6YEmhqZNtKw03xs2f/wvhp1+KSJJrqaskv7knRoCHs27yBss0b6TdhIju/XcVXb0zH7fUx8IyzGHvJlZaQAujU8+R3P3RwOFlwBFYYvxwWWAdRg+UH8jO9aKEDqNWbKc/ysFdspkQLoTUefIqg5SIYjmRpjY1oovEFpdtSBHU1cYqg6DLeTilcg6W0kCJoNiV2cHBwcGgdXdfnA/OP8TKOfxrKjJ8Zndp1GjN6NWHChHadp6001hxgw5fzqdy5g1EXXEp+cQ92rlmFKstM/P4tfPXmf/jsX3+x9hdEkUsf+CWrZ32KNy2dc267E7fXiyLLiC4RUXT6VDo4nMg4V9lhmmTDlKKtAksPqjRqGp0y0wyXQMDfqJKWGRZHfn9k3/DzLaHJIVzhbuZWBMvvj45gyTF9sGJMLsw7wC7JDbqOHDQMFKREESwnRfA7T3p6Oo22GwEAmzZt4vbbb6e2tpZgMMhpp53G5ZdfzgMPPADA1q1bKSwsxOfzMWTIEG6++WYmTZrECy+8wC23GOlA33zzDSNGjOCpp57i/vvvt8Z+4okneOuttwD49ttvGTx4MAA333wzd911V6vrvfXWW7nvvvsYMGDAQR3nxRdfTEVFBYsXLz6o1zk4OBwCDfuNn+0osKqqqlizZg2nnHLKMY9erVswhy9nvEJjzQFr246Vy7j+qb+xe90a3F4fw8+9kMFnTiHQ2ICqyEieFN7/w6+tJr/jr/we7nDTY8n5bnZwOClwBFYYU2DF2rTrmkZwy1bQVFwdOuDuZHxp6EGVOk2jMEVDqzVe629UScuOt2NXqg8Q2LDBeuzKzsbduTPNDfX4Moy+lXoo0mgYt5vGFDcpsooWFk2qolC12+glEvI3UbWrFDVGYFnjh/+Dbjpg/IdvdwwUXeEIlpMi6JCAu+66i3vvvZeLL74YiAihKVOmAHDGGWfw9NNPM2rUKADmz5/P4MGDeeONNyyB9frrrzN06NC4sR9++GEefthoXpmens6qVauintd1HV3XrZsAsbzwwgsHfTy1tbWsXLmS9PR0duzY0W4GCoqiIDnOnA4OULsLXB5I63jEhjxw4AAff/wxAwYMYOTIkcydOxdJko559Kp8+1Y++9dfKOjRi6HnTKX32PEIgsj0B+/io7/8gfqK/XTtPxCXJOGSpKg+Ulf84rd88+mH+DKzGHbO1GN4FA4ODu2Bc0UQxhRY6e5oS9eaGTMo/83jxgNJos+ir3BlZqIEFOo1jWm/uB6zLLupQaawczpCSgp6MGiNsedHMf0kXC70Pz/Npy/8jWsf/3907t03qgZrb101C/sVkdkcpEAyBFGoORIR273+W1756U+ihjTTAwFS0owo3JwX/2lMZ7sj5vb6jH1S2xapc2h/fvW/dazfV39ExxzQJZNfXjjwoF9XVlZG165drcdmlKklioqKqK+vp7y8nPz8fGbOnMn555/fpvlKS0s577zzmDRpEosXL+b999/nySefZNmyZTQ3NzNt2jR+9atfAdHiLj09nbvvvpuPPvoIn8/HBx98QEFBvEPWO++8w4UXXkhBQQGvv/46P//5zwEjEnfHHXdQWVmJy+XirbfeomfPnvzhD39g+vTpiKLIeeedx5NPPhk1b1VVFaNGjaK0tJSXX36Zjz/+mEAgQFNTEx9++CEXX3wxNTU1yLLM448/bgnVV199laeffhpBEBgyZAj/+Mc/GDJkCJs3b8btdlNfX8+QIUPYsmXLcWVT7uBw0BzYDh2K4QimuL3//vvs2rWLbdu2sXnzZjZt2sSkSZOOmQW7pqpsW76Ej//6FL6MTC578DHrZinAmTfezufPPgPA5Ft/nHAMX3pGVHNfBweHkwtHYIVJliKoVhtRoA7f/z4106ej1NWhHNBRm2T8RNqdBD1ZNNaESMv2Ujzjv8j79qH5/ez7mZFalTpmDDnXfx//suUceOUVdq5ZCUBF6TZDYMm2CFaPEpgLjWmpFJb0gLLd1jxZBZ2oK99vPc4rKmbi928hIyfX2jbgtDOZ9/LzKCFD5NlTDoZNmUpu12506tnnsM+Zw8nHvffey5lnnsn48eM555xzuOmmm8jOzm71ddOmTeOtt95i+PDhjBgxgpRWGmvb2bRpEy+99BL/+IfhfPXEE0+Qk5ODqqpMnjyZNWvWMGTIkKjXNDU1ccopp/DEE0/ws5/9jOeff55HHnkkbuwZM2bwy1/+koKCAqZNm2YJrO9973s8+OCDXHrppQQCATRN49NPP+X9999nyZIlpKamcuDAgbjxYlm8eDFr1qwhJycHRVF47733yMzMpKqqilNOOYWLLrqI9evX88QTT/DVV1+Rl5fHgQMHyMjI4IwzzuDjjz/mkksu4fXXX+fyyy93xJXDiU/1NsjpecSGKy8vZ9euXUyaNIktW7awadMmevbs2a7Rq/qqCpa8+ybdhw6n58ixUb0kNy3+ks/++WfkYID84p5c+uAvo8QVwOAzzyErvxPB5qYW7dkdHBxOXhyBFSZpiqBsmE/4hg6lZvp0QjsaqfukFAGotgmstYNuBSAr34d3QE+8AwYQ2LTJet7TvYiMs85CV1R45RWwDCrCJha2RsN62NgCATTbHClpaaR3yIkSWJLHQ/GQ4VFrljweug8ZzrblXwPR6YAer4+eI53/8I8nDiXS1F7cdNNNTJkyhZkzZ/LBBx/w7LPPsnr16lYF05VXXslVV13Fxo0bueaaa1i0aFGb5+zevTunnHKK9fjNN9/kueeeQ1EUysrKWL9+fZzA8ng8XHDBBQCMHDmSWbNmxY1bXl7O1q1bOfXUUxEEAUmSWLt2Ld27d2fv3r1ceumlgNHgFmD27NncdNNNpIbTeHJyclpd+9lnn23tp+s6Dz30EAsXLkQURfbu3Ut5eTlz585l2rRp5OXlRY1766238oc//IFLLrmEl156ieeff77N58zB4bhkxjVQuQF6TY57SlVVli5dyujRow8qnXbNmjWIosioUaM49dRTOXDgALm5uUlTiQ+Hsi2b+PBPvyPkbyLU3MyaOTPpWFRMn1NOxeV2s/PbVexc8w2d+/Rj2DlT6TlybFTan52iQUMSbndwcPhucOT/hzpBSRbBMlP3TPGjNRmOgGWnd+JlImmAgZQccgvT6XdKpLDXdAO0/25FqWIcAO0pgppq9rmKOAeCIZRinYWS1VLZ0wIdQwuHg6FLly7cfPPNfPDBB5YoaY1OnTrhdruZNWsWkyfHX1y1RFpa5G9ux44dPP3008yZM4c1a9YwdepUAoFA3GvcbnfE1MXlQgn3iLPzxhtvUFNTQ0lJCcXFxZSWlvL666+j63rcvmAIpERW4ZIkWcYysWuxr/21116jsrKSFStWsGrVKgoKCggEAknHnTBhAqWlpSxYsABVVRk0aFDCdTk4nBCoCmz6xPg9PT5dd/Xq1Xz22Wd8+eWXrQ61cuVK/va3v7F7927WrVtHjx49SEtLw+Vy0bFjx0MSV2abEzDs08u2bmLFx+/z3I9uYva/jXT6b+d+RmN1FYX9BnLd7/7MuT+6l5ryMr568z8sfO0ldn27mk49e3P5z3/FgNMmJRVXDg4ODk4EK4zVBytGYGmWwDLEjx4yLuQOZHowzdd1BEKeDLoPzrUa+QKWKDN+jxFYagKBFRZCutlAWNejvhRcbjdCzBdLMvFkv0PoCCyHtjJz5kwmT56M2+1m//79VFdXU1hY2KbX/vrXv6aiogKX69BrL+rr60lLSyMrK4vy8nI+/fRTzjjjjEMaa8aMGcycOZNx48YBhng7++yzefzxx+natSvvv/8+l1xyCcFgEFVVOeecc/j1r3/Ntddea6UI5uTkUFxczIoVKxgzZgxvv/120vnq6urIz8/H7XYzb948du40TGkmT57MpZdeyr333ktubq41LsD111/PNddcw6OPPnpIx+jgcNxwYLvxM7c3DIuvLZLDNwubmppaHWrWrFk0Nzfz/vvvU1tby6RJkw5rabvWruGDp3/DuGnXMuqCS5n74r/Y8OV840lBYPXnH1MybCRbl31NvwkTmXrXTwEo6NGL/qeegaoqNNfVkZGbB4Lg9GxzcHBoFUdghWmSm5BECY/oidpuRpZEU2DJhsBqlCMOfrI7HV1wkR7jIBgVwbIElimi4gWWGBPBAsM90ER0uSwXQJNklq5RESzH3cwhAX6/P8rQ4r777mPPnj3cfffdVtrcU089RadObbNbHj9+/GGvaejQoQwfPpyBAwfSo0ePQ66zKC0tZdeuXVGphyUlJWRmZrJkyRKmT5/O7bffzi9+8QvcbjdvvfUW5557LqtWrWLUqFF4PB7OP/98fvvb33L//fdz5ZVXMn36dM4888ykc37ve9/jwgsvZNSoUQwbNox+/foBMHDgQB5++GEmTpyIy+Vi+PDhvPzyy9ZrHnnkEa655ppDOk4Hh+OGyrBT7uUvQFpu3NPmjZdk7rcmzc3NNDc3A0Yz4YyMDAYOPPQ0alWRmfmPPxFqbuar16fTbeAQNi/5ipTUNKb86B6Khwxn+gN38f4ffg3AkMlTol5vfu+6bQ1/HRwcHFrDufIO0xhqJM2dFndnSg/JCG53JLoUFlhNsooYjjQFU7IBSMuKEVj2CJbVRDg8ju1LRtf1qBRBK4IFUSmCoijGR7DakCJodxh0cDDRYkS+yR//+Mekr5k/f37U4zPOOCNhhOmxxx5rcW6z/1ZxcXFcCqIpPlqa296/a9q0aUybNi1q3+LiYvbu3Rs3xsqVK63f586dG/f8gw8+yIMPPhi1rV+/fqxZs8Z6/PjjhqvojTfeyI033mhtz8vLS9pr64YbbuCGG26I2/7ll18ybdq0NhmJODgc1+xfCwiQl9hAqa0Cq7LS8OXt2rUre/bs4fzzzz+sFgjrFsylobqSM66/la/ffYP/PHg3ANf8+ikKevQC4Nwf3ces5/9GQY9edBvo1E45ODgcPs6Vdxi/4idNircuN939hKgIlkiDrOK2BFYWQFwPLDMiBQlSBC0RpUM4SmXVYNkufE0nQABBdMUJLDHJF48pvFy2WhUHB4fjhzvvvJNPP/2UTz755FgvxcHh8Fg5HRb+AYrGgSdxXZJZ+5hMYFVXV1NTU0N9vdGy4qKLLgIgP7/tkSNNU6natZP84h4A1FWUs/jt/1LQozcjzr+Y4qEjeevxh+k3/nRLXAF06dOPG576W5vncXBwcGgNR2CFaZKb4hwEwW5yERY/sgqINMoKXQWBrT0uRg4Ls7Ts6PRCIYHAEmNMLjRNQw8Z1VxmSqE9fTAUTpWAcKqC2MYUwbDwchoKOzgcn/z1r3891ktwcDh8NBU+DPdlHH5d3NNlZWW8+OKLjBkzBjAElt/vZ9euXfTo0YMdO3bQp08f6+9h3LhxuFwu8vLyDtrM4vNn/8q6+bO5+P5H6D50OG889iDN9XWc9+P7EASB3K7duO3vL8Wl2js4ODgcaRyBFcYv+9sksFAM8dMQUhkie9hVdE54R53UzGiBhS26ZKYLRtIAwwJLUdBMgWVFsCJ3+OwNhgVRjPvCaS1F0Km/cnBwcHBoNxrCbUP6nAtD42sJV6xYgSzLVpqtqqq88cYb7Ny5k4EDB7Ju3bqoGsStW7cekrjatXYN6+bPBmDph2+z/ZtlNFRXcsWjT1A0aKi1nyOuHBwcjgaOTXuYoBrE6/LGbTf7U0VSBA3xUycrpBJJvUvRm6McBIGo1Lz4FEFDYCmyjB4y6qzM+iy7yUVUBEt0QUy6XzKHQCdy5eDg4ODQ7tQabpmM+QGI8eLF7KFn1k36/X7LYXPdunUAUX3sKisrrZ5xLVFfVcmutWtQZBlVUZj70r/Iyi/g9OtupmzzRr6d8xkjp14SJa4cHBwcjhZOeCNMUA3GWbRD2N0v1RcRWIohsBqDCvk2geWlOe61dsQYgWWaXKiyjC5HR7DsKYJyMNJ3RxTFOPfBpALLsWZ3cHBwcGhvancZP7OLEz5t1hSbNVj79u2L26eqqirqcceOHVuccv+2Lbz1m4cINTeTkdeRjkXFVO/ZxcU/fZReo8aS3akznhQfRYMdceXg4HBscCJYYYJqEK+UOIKF3UVQ0cAl0BTSsFtapAjxzVDtxLoIamFjC1WRIzVYCVIEAcvYQhDFuOeSpQA6AsvBwcHBod3QNND1iMDK6kppaSkVFRUsX76cJUuWIMsytbW1MS8zBNeQIYZb36BBgyguLuaiiy6iQ4cOQMsCq6G6ind++wu86ZmcfdudqLLM9pXLGHr2+fQaNRaA3qPH0X3IMMfgycHB4ZjhRLDCBJQAKa6UuO26LCPaa7BUDUEUaAwqSHrkP2+xlf/IY1MEzf5WRgQrnCKYpEeWO8VLqNlvCCw1VmA5KYIOh0Z6enqU3TnApk2buP3226mtrSUYDHLaaadx+eWX88ADDwBGfURhYSE+n48hQ4Zw8803M2nSJF544QVuueUWAL755htGjBjBU089xf3332+NPX/+fH7+859HWZkrikJhYSGrVq2ic+fOcWucP38+Tz/9NB999FHCY7j77rt5++232b1790HXbDg4OBwCoSZ4diI0VYDkBW8WZHQGtzeuxcKnn36afJjtm3C5XBQXFzNq1Cg0VaWD20V1c9DqIZeIr999nVBzM9c+/jQdOhfSe8w4Gqqr6Ni95EgdoYODg8Nh41yRhAmqwcQCKxRCcNts2hUNXGKcwKKVG2VJBZaixEWw9JgolTucwy66XG1OEUzmLujg0BJ33XUX9957L6tWrWLDhg3ceeedTJkyhVWrVllNeF977TVWrVrFq6++CsDgwYN54403rDFef/11hg6NT805/fTT2bNnD6Wlpda22bNnM2jQoITiqjU0TeO9996jW7duLFy48OAPto201rfHweE7xd6VUL0FAnXQWA5Vm6H7+Ki/k7b0rdqz7CvGdC1g+PDhAHz2zz/z7uMPU7tmmdUzKxY5EGD9grkMPGMyHToXAuDLyCS/uIcTrXJwcDiucCJYYQJq4giWJoddBK0GwTqCS6ApqCBqAi6lGVXyIdHyRZglsEQRJAlVjU8RNOu07CYXYESwzNe2NYKVrD+Ww3HIpw/C/m+P7JidBsN5Tx70y8rK5e8/CwAAh39JREFUyujatav1ePDgwa2+pqioiPr6esrLy8nPz2fmzJmcf/75cfuJosgVV1zBG2+8YUXEXn/9da655hqWLl3KPffcQ3NzMz6fj5deeom+ffu2OO+8efMYNGgQV111FTNmzLAaHpeXl3PHHXewfft2AP75z38yfvx4Xn31VZ5++mkEQWDIkCFMnz6dG2+8kQsuuMBqVGxG9ebPn8+vfvUrOnfuzKpVq1i/fj2XXHIJu3fvJhAIcPfdd3PbbbcBMHPmTB566CFUVSUvL49Zs2bRt29fFi1aRMeOHdE0jT59+vD111+3qXjfweG4pmx15PeUTAjWQ/GpVv8qMCLTrSEA5evX4HK5qK+sYMOXCwDYt2mDtU/p6pWUb9/K4MlTSM3MYsfqFShyiH7jJx6xw3FwcHBoD5yr8DAhNUSKlCiCFW40LAiGyNJ08AjUNIQQtBQKKlbgUgMMKAm1OH5sTyzNbnIRV4MVLbAkWwRLDUXP45hcOBxJ7r33Xs4880zGjx/POeecw0033UR2dnarr5s2bRpvvfUWw4cPZ8SIEZZzWCzXXHMNt912Gw888ADBYJBPPvmEP/3pT7hcLhYuXIgkScyePZuHHnqId955p8U5Z8yYwTXXXMPFF1/MQw89hCzLuN1u7rrrLiZOnMh7772Hqqo0Njaybt06nnjiCb766ivy8vI4cOBAq8e0dOlS1q5dS0mJkXr04osvkpOTQ3NzM6NHj+byyy9H0zR+8IMfsHDhQkpKSjhw4ACiKHLdddfx2muvcc899zB79myGDh3qiCuHk4LmPasRxDS8Ux6DXpNZ9Pr/o64sh/55dVH7XXbZZaSkpDBjxoykY9WW70fXdXatW4Oua/QZO4HNS76ialcpWQWd+PivTxNoqGfrssVccM+DbFr0Bb6MTLr2H9jOR+ng4OBweDgCC8PdqGWb9kh6n67q6IKhs9AF3HITPXd8iLfHWS3OYTYRBhDdbiudIkpgWVGymBRBT1hgiSJyXIpg4rdQcmqwThwOIdLUXtx0001MmTKFmTNn8sEHH/Dss8+yevXqpILJ5Morr+Sqq65i48aNXHPNNSxatCjhfqNHj6axsZFNmzaxYcMGTjnlFDp06MDu3bu54YYb2LJlC4IgIIfrEpMRCoUscZaRkcHYsWP5/PPPmTp1KnPnzrXSF10uF1lZWbz66qtMmzbNEjk5OTmtnosxY8ZY4grgmWee4b333gNg9+7dbNmyhcrKSk4//XRrP3Pcm2++mYsvvph77rmHF198kZtuuqnV+RwcTgT+uyUVn+8arh17G1u3buXzynyoXEVGh+gbCFWbNzDp8iu57LLLqKupYc68eUZTYpuVuxwM4K+rpXrPLlxuN/1OncjmJV/xyk9/guhyoakqw8+9kDVzZvLiPbcDOsOmXOD0snJwcDjucWqwMOqvgKQmF1EOgJqOCrjCAssVfm1rmAYWAHjcqOE6K1Wxm1y0HMGKchEM55u31mjYweFg6dKlCzfffDMffPABkiSxdu3aVl/TqVMn3G43s2bNYvLkyS3ue/XVV/P6669b6YEAjz76KJMmTWLt2rX873//IxBo2ZVz5syZ1NXVMXjwYIqLi/nyyy9bvFOu63rCGg1JkqJspEO2CHFaWqRtw/z585k9ezaLFy9m9erVDB8+nEAgkHTcbt26UVBQwNy5c1myZAnnnXdei8fj4HAi0NjQwG65A6XN6WiaFnUjZfny5VH7rnjvddYvnMuQIUPIyzXcARFd9O/UEd+uzXTpOwCA2v1lVO/ZRU7nQkqGj2b8ld+jc+++aKpKalY2k268jVv+8jyDzzyb1Kxshp7t/C05ODgc/zgCi1YEVmwES9ORAY/R0gOXal4ItuIiGBXB8qCGL+oSpQjGGlmYd+tEMWJyYUaoHBdBhyPJzJkzrejR/v37qa6uprCwsE2v/fWvf83vf//7pAXqJtdccw3/+c9/mDt3LhdddBEAdXV11jyxTmSJmDFjBi+88AKlpaWUlpayY8cOPv/8c/x+P5MnT+af//wnYBhU1NfXM3nyZN58802qq6sBrBTB4uJiVqxYAcAHH3yQNHJWV1dHhw4dSE1NZePGjXz99dcAjBs3jgULFrBjx46ocQFuvfVWrrvuOq688spWz4mDw4nAtvXfABDSBJ599lm2b9/OWWedRVZWFrW1tXTo0IEbb7gBd101giKza61Rr5Viqwn21FUhNdVTNNCo76wtL6N6z25yu3VHcrsZd/k1TPnhPQBMuPI6BEEgIzePs279Mbf/8xVyunTFwcHB4XjHEVgYFu1AXA2Wrqqgqlb0SfB4QANZ1/GEHQSlNkewYmqwTIGlyGit9MES7X2wwumDZoTKqcFyOFT8fj9du3a1/v3xj3/k888/Z9CgQQwdOpQpU6bw1FNP0alTpzaNN378eC655JJW9xswYACpqamceeaZVpToZz/7GT//+c+ZMGFCq659fr+fzz77jKlTp1rb0tLSOPXUU/nf//7HX/7yF+bNm8fgwYMZOXIk69atY+DAgTz88MNMnDiRoUOHct999wHwgx/8gAULFjBmzBiWLFkSFbWyc+6556IoCkOGDOHRRx/llFNOAYx+Pc899xyXXXYZQ4cO5aqrrrJec9FFF9HY2OikBzqcNGzdvAEJ4yZEeXk5Jbkd6NW5gJ49ewLQIc1Hts+Ld98OBKBsyyYA3LYWCjVlRqPhTr364pIk9m3aQH1lObmF3ax9cgu78eMXX2fIWecepSNzcHBwOLI4NVgYBhdAXA1WbGTJFFjNaqTJsEtpbtMc9hRBwWOLYCW0addwud2oZuqgGcGy2bSbAkp0JdbIjsByaI3YVFSTP/7xj0lfM3/+/KjHZ5xxhuXeZ+exxx5rce7Vq1dHPR43bhybN2+2Hv/mN79JOn5qampCk4p3333X+v2DDz6Ie/6GG27ghhtuiNpWUFBgRaMAfve73yWcNyUlJWlPn/POOy9hCuDq1asZOnRoiz19HBxOFLQ/DWZb3XkMYCd9z70NIb2AT37zIOvSUug7YRIrV65k39dfUD6wPwA9Roxm+8plNDc2YI/f1pTtBSC9Qw55RSWsnT8LgPwePaPm86alH5XjcnBwcGgPnAgWhkU7xKcIxtqnCx4PsqKxvylIjsfQppEaLL3FOcTYCJZuTxGMqcFSVcuaHRJHsKxtSVITzRTBllfl4ODQHjz55JNcfvnllmBzcDhhqd0NDeWsqsvATyq9xT0MHHUa3Tp3QgAO7NtD3759Sdv2Le6GGtZ/MQ+APqecCkD1rp0o4e9SqbbKGtaXkUlBj57Wd1pBSa+je1wODg4O7YgTwSJSg+WVWo9g6ZqACnx/THdqP92LS2vZ7cwkNkVQDYu6hC6CmoZk3z8spkRRtCJYQtiJSU8ioVxOHywHh2PGgw8+yIMPPnisl+HgcHjoOvx5EPvJ4xOuoYRdDOwoguQh0NgAQM2+vYSa/Ygh43t0+4qlpGV3oFu4xurLN15l78b1ZADpuXk0hof2ZWTSpU9/1syeCYJAWnaHY3CADg4ODu2DcxVOpAbL4/JEbbfc/WwugjoCMtC7YzrLAEFruV7ERLCl7AluN5pqCCNFURK4CKq4bbbYYlhMCaLLqs9Klhpo4qQIOjg4ODgcCn6/n9dee42O2RkMoIQN9MSFwuV8gjjaiMqaAquhujKqOTBAp159yMjtCMDejeut7Rk5uTRWV+Fyu5FSUhhw2iRUWcaXlXWUjszBwcHh6OAILGwRrHANlq7rBNauJbR9O2CPYLkRNI3UYBP61i0AiLpCTXY2DZKbHL8fFzqqolC7vwwlFKQq3QfAro3rDDtnTaNSC6DpOggCSmMDZRvXEfRIaALsW78Wf20tkscmsCwXwUgEy9yWLEUw8ryDg4ODg0PbmTdvHnv37mXvXljFJXSkim7eAOk/Xg0ZBVTt3om/PtJYePsqw6J9wOlnsn7hXNKyOyRsX5DZsYCyLZtwe33G84LgGFk4ODi0O7qmodbVodXX4y4sRDgKWV6OwCLepj2wdh2lV1xpPe/KzgZA6tABpVmlb/0Odj7/NQy8hUCKi7lnTwFg+4cfsv+jNyxzCgB6dgFg6eOPRE8a/vJpqK/j8/o66N8d9/w5zH7h74BxB9CksN9ANnw5n8J+AxAliVWffUTvsRNY+v5bZHYsSHhMZnPinqNOOZRT4uDg4ODwHWXXrl0UFhaiNlaxvy5IJXn0HzkeMgpoqK7ilft/HFUnXLpqBQgCp3/vJpob6hlx/sUAnPeT/6OidDsrPjIadHftP4hNixYSaKg/Jsfl4OBwfKCFQuihEK705GY2cnk5/iVLCG7fjisjE0/PHqQOG4aYmYm8ezdNi7/Gv3QJuqoh5eeTNu4U0saNQw+FCGzcRODbNTR/u5bAunXI+/eDogAgpqbiHToE35Ch5N5yM67MzHY5RkdgYRNYYZt2tbYWgE6//AXeQYPwDhxoPH7sMbY9vZINDel0mTwMFsnkP/k4zPkIgObm5ihxde6P7iUjuwO6348rK9vY+OnPUPesRRl8J5v21bPh22+s/ZttXzqCKHLrX18g6PeTX9yDkmEjyeyYT78JExlzyTTSO+Qy9OzzyMzLT3hMbq+X2/75MqmZ2UfgDDk4ODg4HC0UWUFyH5uvZ13XqampYdiwYYylkr8uNbZ36VYEQF3FfgDkYKQZeE3ZPjJyO5KW3YHLHnzM2j7gtEn0m3C6JbC6Dx56dA7CwcHhiKLrOmpNDfK+MsRUH1LHjghuN6Fdu5B37UI5cAC1pha1tha1vg4xNQ0pLw+pY0dcHbLRGpvQGhsIbNpE84qVBLdtA03D3b2IrKlTyTzvPMTMTPzLl+NfshT/kiWEdu40JhdFsLseu90QvtaWOnVCTEuj8YsvqJk+PW7d7q5d8Q4eROb55yPl5SGmpRJYtw7/qlUceOUV8n54R7udM0dgEanBslIE5bBt+5Ah+MLiCsCVmYkmeahOSad7UQks2oyYGynMVcLq2KSw7wCyO3WOnuxrHRrq4Mzx7F64HmwCSw5ELN9F0UVWfqT/UGZHQ0iJLhcZOXnGtiTiysTcz8EhES6Xi8GDB6MoCiUlJUyfPp3s7GxKS0spKSnhmWee4c477wTgJz/5CaNGjeLGG2/kxhtvZNasWWzfvp2UlBSqqqoYNWoUpaWl1tjV1dVMnjwZMBoWu1wuOnY0ajKWLl2Kx+OJW4+d5cuX8+qrr/LMM88c1DF98803jBgxgpkzZzJlypSDeq2Dw/HA6/9+hf2l5fg0kXFXXciQIX0BqK2tJSUlBZ/P167zNzU1EQqFyMnJIWfvTgpEHxk9RtG7d28A6irKrX1Fl4vMvHxqy8vIyk+cTWHWEANkhL+zuvTp345H4OBwYqDrOlpdHYLPh+DxJEyrPazxVRX/8hU0f/MNuqLgyszA1SEH0NGamghs2Ih/+XLU6mojq0oUETwePIWFuIu740pLI7R7D/Lu3YT27kX3+1udU/B6jWtlvx+tsTHueTE9Hd/w4aSfNRnR68O/bBlV//gnVf/4Z2SftDRSR40i+6qrSB07Bm+/fmiNjYY4W7Uata4WT3ExqSNH4SkpRhAEdFmmadEiAuvXI6R4SendC++gQUgdEpjnXH45YETRxFauRQ4HR2ARiWCZJhexrn52BE1HQUfUDZMK027d7XbHNUgVW8nxNK3UrXU02wWW46Dv0L74fD5WrVoFGD2i/v73v/Pwww8DkJ+fz1/+8hduv/32hGLI5XLx4osv8sMf/jDh2Lm5udbYjz32GOnp6dx///1R+yiKgpTkb2TUqFGMGjXqoI9pxowZnHrqqcyYMaNdBZaqqrhcrtZ3dHA4SKQde9EFkTK3n4/eeoPPnt1Ph1492VPXQH5+Prfffnu7fvbMHnM5a19C2PM6txedinjdn2msOYA7xWtFsAC86RnkFHZtUWDZcUkSd778JqLLufRw+G6iaxpNX3xBzX9n4F++HK2pyXhCknAXFJA6ahTpk87A3a0boe07CG7bCqpG+qRJ+IYNBV0ntGMHgfXrCaxbb/wM95D0dOtG2qkTEEQXwe3b8S9dipqgZ6SJmJ6Ob+QI0saOQdd10HX05gCh3btpnDcfze/H07Ur7m7dSB13Cp6uXZE6d0YPBFEqKtBlGXdhIZ7iYqS8XFzZ2Yi2G0BaczNKRQVqXR1iejpiejpSbq7V2xWA229D3ruXxkWL0IMhfEMG4x0wIK5GypWVRdqYMaSNGZPwWAS3m/SJE0mfOLHN70V7iitwBBaQwOQipv+VHUEDDSwXQATjZ0pKSlwES2rFyS/W6S/UHLk7IDgC6zvD75f+no0HNh7RMfvl9OOBMQ+0ef9x48axZs0a63HHjh2ZMGECr7zyCj/4wQ/i9r/nnnv405/+lPC5lrjxxhvJycmxIk1XXXUV99xzD83Nzfh8Pl566SX69u3L/Pnzefrpp/noo4947LHH2LVrF9u3b2fXrl3cc8893HXXXXFj67rO22+/zaxZszjttNMIBAJ4vcbf9B/+8AemT5+OKIqcd955PPnkk2zdupU77riDyspKXC4Xb731Frt377bmhejIXXFxMTfffDOff/45P/nJT2hoaOC5554jFArRq1cvpk+fTmpqKuXl5dxxxx1sD5vk/POf/+TTTz8lLy+Pu+++G4CHH36YgoKChMfh8N3mkvvu4K2HrmOwciqbunip7JhPU10D6DoVFRW88MRjFGWnkVlQSPfBwynsNyD++6JhPyz4PUheOPNR8KS2ae7m5mZefPFFADrs+QwAMbcYgGfvuJ6s/AIK+w6w9k9JS2f4lAtISU1j2JQLWh1fEAQ8vratxcGhPdB1HbW2FjEt7ZAusNWGBvwrVhAqLcXdqRPuwq64uxbiys5GEASUAwdoWrwY/5KlyHt2o4VCuLKzDfHhSaHxiy+Qd+/G1TGPrIsvwl1UhB4MoTU2Etq5k8YFC6j74IPIhGExUv3887g6dEALBNDDN+MFrxdv375knnsugstFYN06qv/1LADuwkLSxo0j4+yzSTv1VESfF7W+3hBcooiYmmqInXY0exB9Pjzdu7e6n7uwkA5XXNFu6zhWOAKL+BqsWNt0O6Kmo4kCqmJErnTdiFqlpKTERbBatErX1bgIVsgewXLujjscJVRVZc6cOdxyyy1R2x988EHOO+88br755rjXFBUVceqppzJ9+nQuvPDCg5pv8+bNzJ49G5fLRX19PQsXLkSSJGbPns1DDz3EO++8E/eajRs3Mm/ePBoaGujbty8//OEPccf8fX311VeUlJTQs2dPzjjjDD755BMuu+wyPv30U95//32WLFlCamqqdYf+e9/7Hg8++CCXXnopgUAATdPYvXt3i2v3er18+eWXgJEGaQrMRx55hH//+9/ceeed3HXXXUycOJH33nsPVVVpbGykS5cuXHbZZdx9991omsbrr7/O0qVLD+q8OXw3kHJy6Purx/m/N67nmX0/plbsztrmatTKUhq7+ClPSSO4/CtCQZ1F/3sPqWMnsvM70b2wkLzCrnTu1Ye8z3+AsHeZMWBWNxj3I9BUEETLYCkRe/bsAaBHfhp5FTXGxg4lKOHvxLqKctKyc6z9C0p6UjxsJMXDRrbPyXD4ziGXlaE1NeEpLm7zxb9SWUndBx/QtGgxWjBI2imn0OHqq5DCaekAWlMTNa+/Qc2MGch79iB4PKRPmkTmuVPQQyH8y1cQ2LwJtaYWV3o6ro55SNnZaMEQeiCA4JZQampoXrXaMkuwI6anI6SkGOl2gJiZSUpJCYLHg7xzF4HVa9D8fryDBpF/7z1knHVWwmtMXVFo/uYblJoaPN2LSSkpRguFaJw7l6avl+DKSCelf398AwfiKSmJO0daKIQgSQlv0ksdOiROmXNoFxyBhVGD5RJcuMVwo9+YBsN2BB00QUBVwimCGEIrJSWFxph801gBZQwQ/nJTQnECTA44EazvIgcTaTqSNDc3M2zYMEpLSxk5ciRnn3121PMlJSWMGTOG//73vwlf/9BDD3HRRRcxderUg5r3iiuusFKc6urquOGGG9iyZQuCICDLiRt3T506lZSUFFJSUsjPz6e8vJyuXbtG7TNjxgyuvvpqAK6++mqmT5/OZZddxuzZs7nppptITTXunOfk5NDQ0MDevXu59NJLAaxIV2tcddVV1u9r167lkUceoba2lsbGRislce7cubz66quAkUqZlZVFVlYWubm5fPPNN5SXlzN8+HByc3PbesocvmMMzx9Ol15DebDgQ57f8Rjd0wr4tLGQzJp6qjpvoKbHCAD0cCOOuqDG7k1b8c36BEGWcWXnU9L9VqZkrca3/EUYewe8dD7U74VL/wUZncGTDhkFRjNhXYdV/2HPgU4IgsBV3Q8gVBhr+XptHamhOdbayrZuoueoU8gvLmH0xdPadDwjp17CjlUrjuxJcjjh0EIhlIpKpNwc1JoadE3HXZCP4HYT3LGDqr//g/qPPwZdR/D58A4cQEpJCWJqKlogCJpqpLKpGp6SEtydCqj//HP+f3vnHR9Vsf7hZ862NBJSKKEm9JqE0KRJEEFEpEuRq6IXFQUUvUX8YUHFhh31qoiCciEUFUSuglIVpAUIRYq0YEJLg/Sy5fz+OLubTbKpJLTMw2fZc+bMzJkzu9k53/O+807mps1gtWJq0wbFZCL5449JmTcP38GDqXXHQLL37CHtm2+xpqXh1b07/hMmYE5IIP3HH8lYZ7fU1qqFR/v2GBs1xpqZgTUpmfzjJxAeHggPE5gtKF5eBD44Ee9evTG1boUlMRFzQgL58fGYE85iy83BFBqKV9eueLRvX9gVrpwIvR6vrl0LpemMRvyGDsVv6NAyy1e325uk/EiBhWbBcoRoh9IFlqKqoAOrxYZQhNNqZTKZuHz5Mq5/TrrSnr5Y84odz8uWFizJ1cMxBystLY0hQ4bw8ccfF3NZ+7//+z9Gjx7NrbfeWqx8ixYtiIiIYPny5RU6r7e3t3P7+eefp1+/fqxcuZK4uDiioqLcljG5LLyt0+mKueNarVa+/fZbVq9ezauvvoqqqqSkpJCRkYGqqsUmD6v2OZRF0ev12FyiFeXm5hY67tr2iRMnsmrVKsLDw1m4cCGbN28u9bonTZrEwoULuXDhgluroETiQAjBtE7TePjnhzna5gKtdgRwd5eGHP/DwJ/JYez3iifFx4feDQUj2EDu2YN8Y7gLc8sO6K25ZApPYnNsnDgWSBfPZG5ZOR2P+B1a5QvtD0QUPfSYArFLIDicxBN72aF7gLp162FKWQtArlXPti37YEtBMCbVZqN55250vG1gua8n6v5JRN0/qcr6R3J9YE1PJ+fgQVBB5+eLLScHW0YG+sBADA0bkh8fT+6hP8iPiyPn0CFyDx0qHA0O0AUGoq9bl7yjRxEeHgQ89CAerVtr+Q8eImPjJtS8PITJVCBYhCBt5Upn+cAHJ+I3chSmZqEA5J0+zaVF/+XyqlWau51Oh0+/KIImTcIzIsJ57nozntGCInh4YmrRvMKCSO/vj0fr1pXuP8nNjRRYFBdYttIElg1Ug8BmsaHTFwgso9GoTXx3yevWCuW4sbPkoTMU9kUvNAdLSAuW5Org5+fH3LlzGTZsWLGgFW3atKFdu3asWbOGbm4ml86cObPCFixX0tLSaNiwIQALFy6sdD3r168nPDycdfankaAF7li1ahUDBw7k5Zdf5t5773W6CAYEBNCoUSNWrVrF8OHDycvLw2q10rRpUw4fPkxeXh65ubls2LCB3r17uz1nRkYGwcHBmM1mFi9e7LyO/v3788knnzB9+nSsVitZWVn4+voyYsQIXnjhBcxmc4lWQYnEwS3Bt9CtfjdeS53L4nbvY/4zjebenjS1moi0BnE+X/DO8SzWNHycr+81Mmnnp6w8aSBT8SGqeyc27juNoVVH9uzP5I9vjzEiLJwGU1bAtvcBAWe2wbYPOE5TEk9cYhcjsFnzuS33J7i4BdoM4bzvbfDnymJtqxvS7Kr3h6T6yY+PJ2PDBrJ37Ubx9sZQvz6Kby2sKalY09NRPEwoXl5YMzLJ2buXvBMnCu5pSkHx8cHUvDmBjzyMoWFDrCkp6Gr7gyLI3rEDa3oGtaZOwX/sWPRBWvTjsqw1lpQULMkpmJqFFgtIZgoNpf4Lz1Nn+pPkHTuGsVkz9G48BoTBgGe4XDpAUj1IgYXmIuiYfwUlRxFUVRUdoCqai6BOrzifpDuCXJTbOGvNR6f3K5TkKrBkFEHJ1aRTp06Eh4ezdOlS+vTpU+jYzJkz6dSpk9ty7du3JzIykr1791bqvP/+97954IEHePfdd7ntttsqVQdo7oEOdz8Ho0aNcgaYiI2NpUuXLhiNRgYPHsxrr73GokWLePTRR3nhhRcwGAysWLGCZs2aMWbMGMLCwmjZsmWJ1w3wyiuv0L17d5o2bUrHjh3JyMgA4IMPPuCRRx7hiy++QKfT8cknn9CjRw+MRiP9+vWjdu3aMgKhpFw8EfkEf/vxb3zfaTsP3/cw1kt5JC/Zi++JNOpavflK+LD1vIV/rMjgoylz+bsuGwye4OHLZeVnduzYwf1T/s6GBV/y/Ql/HlA98Br0ulZ5bhoHl83m29MOq6zKSNbSOs0ecMevMX+laJZfL7/aGD09adapKwc2rCOwUZOr3xmScuEI4qDz80PNycGamUn+6Tiyd+0iPy4OUNH5B6CvVw9Dvboo3t6Yz57l8spV5B3VPntjSAiq2Ux6YiKYzVro7dq1UXNzsWVnI0wmPMPDqXXnILwiIrS5R2lpKJ6eKLV8sSRexHz+PIZ69fAIC9PWTCph7p//mDGVuk59YKBb0eSKzte3mLudRHK1ECW5ylyvdOnSRY2JianSOv+15V8cTT3KDyN+ACDxvfdJmT+ftn8cKpTPlmvh3KztLPdR6RRSl9MHkmk3Us/atWvp2rUru3fvxudIDI6fkX8sW1P8ZF/eCX/9DnfP5WheKP/7YI7zkN5kwpKnBdxo1b0Xdz/9bJVep+T64ciRI7RtK9eCqUnYbDYiIyNZsWKFc00hSWHc/V0IIfaoqlrxmP3XiKoeo6ZtnMaeC3v4adRP+Jm0h3IpX3zJ6S9+IL/b4zQ0mbBkpZD762t4BAeir18fXe3aJKem8H3z5nTr1o0WjRuy8oO3adexI0Oe/Degras1f/58fHx8uLd5Juq29/CjYB7x+Y7/ZMmKXbTo0p2h/5iJzWpFp9djMZvLjJArqRryExK4tHgJmRs3ovP3p9bt/fH/299Q7HNGVXvI7qyt28j94w/yExLIO3ECW1oa6PWFgzEoCoZGjZyR7mz2B0IOPNq3x/fuIdTq3x9j48Za/TYbak4OwsurytdokkhuFkoao6QFC/dzsNy5B1rTNctWuhsXwYI5IgIoh2i1Fg9y4RBXQKF5IBKJ5Mbm8OHDDBkyhBEjRkhxJakQT3R6glGrR/HFoS94uvPTAAQ89CCKby0uLvuKw3VH0q5WEOlRz2HNXotPykUsiYl4Z2cTCuwEdu4CGjXnyK4dtNy8ntZRt7N69WrMZjMjRozAt149yDoNsf8FvQe5yRZOHk4GVWXg5CcRQjjnDEtxVfXknzlD3vHjGJs2xdisGdk7d5L638VkbtoEioJ3r55YL6eR+PY7pCxYiN/dd2NNTyfr99+xXNDWJdPXrYuhSWN87xyEsXETzaLk7Y2udm309eri1bkzulq1nOe0ZWVhTkxEzclB8fXFWCRoEGjTHITLvFOJRFJ+pMDCLrD05RFYmgDKMmhh2nU6BYtFE11OgaUIsJVPYOk9Sh6oVFUKLInkZqFdu3bOdbEkkorQ0r8lQ5oNYcmRJfyt7d+o61UXIQT+99yD/z330CLfyq43d9NEBLC0wd/45/xezrLGJ6fjeegQGb6+/NWkCaJWAKv/+zWDVYVTp04xYMAA6tWzLxB819uoPZ8k8/WRJPxs4Uzj/fgEBWAwFw9JLSnAlpVF8qefkr52HaZWrQh69BE82rYlY9Mm8o4eA8CSlAhCQR8UiKlVay0AxOlT5P35J5m//07e4SMFFSoK2GzoAgIInPwo/uPGYbB/Rtm7d5Py5QJSv/4axccH71tuwfuxx/Du1dOtQCoNxdsbU2holfWDRCIpjBRY2OdguVqwzGaEsbj4saZpYirbpGC1qugMitOC5VyTx2FGL8ucbslDKSXKoCotWBKJRCIBHo94nJ/ifuKz/Z/xfI/nCx3TG3V0eSqShNk76Z1o4Y/DybRvpwUKaPLeuwTt2MGlZctZrSgk1tduwr/ZtBkPvZ4unTtjTkzk3DPPYE1OwZKcjPWSFUMtK2mBfvilXOJE/9upFRWFqtrwvqUHtcfcg5qbS/q6dWTHxOA7cCA+t96KLT+fhMcex3r5Mg3ffadcC4xeD6gWC1nbt6N4euLZubPbiKPmM2c0i5CvL4bgYBQPD1RVJePnX7j4xhtYzp/Hu2cPcmJiiNuwAWE0OudygxbpDlXFeulS4aAQBgOe7dpR95ln8IrsRN7JU+SfPoWpRQtqDRqE4hI9FcCra1e8unbV1upUlEqFAZdIJFcHKbDQLFj+hoLF19T8fBSDGwtWhvaDmWNUsObbnEEu9Ho9ertYUoWCwFp2ZB03LoKu2IosWiyRSCSSmkmjWo0Y3XI03/z5DQ+0f4AmvoWDTBh9jCjhQTSITWLdV0doPbsneoMOoSh49+yJd8+e3JOUxLJly/DMzSY+LQP/40fIiI4m/buV5MXF4RURwYVG9TEG1yVFvUTO4TN0vfc+ah06SvoPa1C8vcn4aS0Z69aRd+oUlgsXEEYjad+txG/kCHL37yfv+AkAUubPJ/iVVwq1MT8hgZy9e/GJikLn63vV+s6BJTWV3EOH8LrlFudaQZZLl4if9DC5f/wBgE///jR4/TV0vr6oqkrWtt9J/s9/yHEJ4iNMJjzat8d66RL5p09jat2ahu+8jVdkpLaY7fIVmOP/wvvWW/Hp3VsTQvagVarZTM7Bg1iSkzGFhmqL6brcB5Q3ol3RAFwSieT6QwosNIHloStYaFTNz3f7A2ZNyyNLgGLUYc2yoei0OVg6na4gKlhZliur/amWJQ+9u4WI7UiBJZFIJBIHj4Y/ynfHv2PJ0SXM6Daj2PEGUU1I3J9Mg2wr21eepM+YVoWO16lTh6lTp6LabKyf/x8O/LmPH5d/TfuzybSZNw9dx4588/dxkHoOgPCBd9HlbxMRikKDV18FnY7kTz4hdcFCjCEhNHjjdTw7duTcs/9H2jffYmrblobvvUvmtm2krfkfgY9OxpqcpFlvgNPDR2DLykIfHEzI4v9iaNCArN9/Jy8uDt9Bg9AHBGDNzORSdDR6f3/8RoxA6HRk79nD5W+/I2DiA3i0aoUlOZm0NWvw6twFz44divWDajaT+N77WC6cx//ee/Hq0oWMzZs5949/YsvKwtisGY0+/ghd7dr89dDfyT95kuA3XseanEzie+9z4rb+eIZ1xHLpMnlHjqCvX5+6M57B2LQptvR0cg79Qe6BAxgaNcJ//Hj87x2PsD9gVby9CXxwYomfoTAY8IqMrOxXQCKR3EBIgYWbOVjmwnOwVLOVix/FYknO4bKiYtAp2KxamHaHwHK1YJWK1R7IogQLlsHDE3NujnQRlEgkEomTIM8gbm10K2tPr+VfXf6FTinsHmao70WWjx5fq5UDGxNo2iGQJu3crP2jKNz+8BSykhI5eWAvh5s3p03bNqz95D0AGrZphyXfTK8xE5yWF8cDxzpTplBnypRC9TWa+wGqxeIUGR7t2pH+vx85efvtWgZFQej1CJOJ4Fdnc/GNN/lr0sPUGjiAlE8/AyBxzlv433svWdu2kXdMm7eUueVXPCMjSXznHbBYyNywgSYLFxA/+TEsFy+CTkfD999DV8uX9B9/BJ1C7dGjSV34Fek//IAwGEhfuw7/cWO5vOp7TCEh+I0eRfKHHxE3ajTC0xNbRgaNPv4Ynz7aWnfevXqR+vUi8k6eRDGZqD9rFn4jRzgtXgB+w4Zd0ecokUhqBnKxJSDPUnyhYVeBZUnNxXIxG48WtYn2smHUK1qQC71wugiW24JlD4pRksAyeXpqbbBJC5aketHpdERERNChQwfuvvtuLl++DEBcXBxCCD788ENn3qlTpzoXAp44cSINGzYkzx71Mjk5mZCQkGL1R0VFFVr4F+D999/n8ccfL7FNUVFRlBTiOikpCYPBwGeffVaBq5RIbh4GNxtMSm4Kuy7sKnZMCIFfeF2a6BR0tfRs+u9RrGb3D+qEEAyd8SK3/u0hEpMu8Omj9xEXu4db//YQ416aw99efw/PWuV34xMu84mNTZvSZN5nBDz0EA3efpvARx/Bd/Bgmv73v9QeNYpGH32E+dw5Uj79DO+ePQhZsUITNl9+iTk+nsaff06d6U+S8csvJL75Jj633krI8mXY8vI4PWIk1rQ0Gn8xH88OHTg77Qn+mjiR9B9/JG3lKuJGjSb9hx+oM306rXbuwLtHDy4tiUYxmWj00YcE3HsvIStW4NW1K4Z69Wg8b55TXAF4tG1Lg9dfI3T5MkKWRuM/bmwhcSWRSCTlRVqwgFxrbqlh2h3h2WtFNWbX0ov00ilYLWZ0egPmIhYsymvBsuShc+MiaPD0gkupMky7pNrx9PQkNjYWgAceeICPP/6YmTNnAlC3bl0++OADHn30UYxubjB0Oh1ffvkljz32WIn1jx8/nqVLl3LHHXc405YuXcpbb71VqfauWLGCW265hejoaB599NFK1VEeHA9NJJLrjT4N++Bj8OHH0z/So0GPYscDOtUlcds5LpssWJMtHPr1LOH9G7utS9Hp6HzXMHZ8u5T8nGxGPvsSTTqUbw5QWTiCMbjDu3s3WmzaiPnsOTzatUUoCo0++pC8Y8fQBwWhDwrCu3cvjCGhoNqodccdCEWhyfzPSfl8PoGPPIxX5854duhA4rvv4dG2DX4jR6JmZ3N51SpMoaH49O0LQOPP55H122/aYrf+2jxrY6OGNP7s0yq5TolEIikJeReBuzlY5sICyx49UOdrJN9qw6BXsFpUFJcgFw4LlnqFFiyjh2bBUuUcrBrDhddeI+/I0Sqt09S2DfX/7//Knb9Hjx4cOHDAuV+nTh169erFV199xcMPP1ws//Tp03nvvffcHnMwevRonnvuOfLy8jCZTMTFxXHu3Dl69+7NY489xu7du8nJyWH06NG89NJLZbYxOjqad955h3vvvZezZ8/SsGFDAL7++mvefvtthBCEhYWxaNEiLl68yOTJk52h0T/55BMaNGjAkCFDOHRIW0D87bffJjMzk1mzZhEVFUXPnj3Ztm0bQ4cOpVWrVsyePZv8/HwCAwNZvHgx9erVIzMzk2nTphETE4MQghdffJHLly9z6NAh3ntPc7H6/PPPOXLkCO+++265+18iKQ8eeg/6N+nP+jPree6W5wo9GAQwNPQh31NHk2wzl+p7sGPVSZq0D8C/vvu1jBRFx31vziXpr9NVJq7Kg97f3yl4QLOoebRpU2jfd9Adhcp4demCV5eCtTx1fn4EvzSrIIPRSODEiYXKCEVxii2JRCK5mtR4F0FVVd3MwSoisDI0q5PO10iexYZR53ARVK4oyIXO9Sm5vZzJy+EiKC1YkquD1Wplw4YNDB06tFD6jBkzeOedd5xLEbjSpEkTevfuzaJFi0qsNzAwkG7durF27VpAs16NHTsWIQSvvvoqMTExHDhwgC1bthQSd+6Ij4/nwoULdOvWjTFjxrBs2TIA/vjjD1599VU2btzI/v37+eCDDwB44okn6Nu3L/v372fv3r20b9++zH64fPkyW7Zs4R//+Ae9e/dmx44d7Nu3j3HjxjFnzhwAXnnlFfz8/Dh48CAHDhzgtttuY9y4cc5FWwEWLFjAgw8+WOb5JDcGQojGQohNQogjQog/hBBPXsv2DG42mExzJr8m/FrsmBAC//C69FAMLMy9jNAL1i84jFrK2oy169WnZdfi1jCJRCKRVJ4ab8HKt9kXCi7qIuhiXbKm5SM89QiDDrPVhkmvYLPPwSoa5KJsF0H3FixFUbBZrRg9vbQ2SIFVY6iIpakqycnJISIigri4ODp37syAAQMKHQ8NDaVbt24sWbLEbfn/+7//Y+jQodx1110lnsPhJjhs2DCWLl3Kl19+CcDy5cuZN28eFouF8+fPc/jwYcLCwkqsZ+nSpYwZMwaAcePG8fe//52nn36ajRs3Mnr0aIKCtHV/AgICANi4cSNff/01oLkz+vn5cenSpVL7Y+zYsc7thIQExo4dy/nz58nPzyfUviDn+vXrWbp0qTOfv/0p/G233caaNWto27YtZrOZjh07lnouyQ2FBfiHqqp7hRC1gD1CiF9UVT18LRrTrX43AjwC+OXMLwxoOqDYca+wOmTtOM+tBhPHgwyEnMjg2K4LtLkl+Bq0ViKRSGomNd6ClWvJBTSBpaoqRy+kk5uVQ4bNl0Mx5zgUc47L8emYPXXsOZGCf66KMd2COd/q3kVQKXuBYcd74TlYWjmD3UVQhmmXVDeOOVhnzpwhPz+fjz/+uFie//u//+PNN990a1Ft0aIFERERLF++vMRzDB8+nA0bNrB3715ycnKIjIzk9OnTvP3222zYsIEDBw5w1113kZubW2pbo6OjWbhwISEhIQwdOpT9+/dz/PhxVFUttjBoSej1+kLXUfSc3t4FblTTpk1j6tSpHDx4kM8++8yZt6TzTZo0iYULF0rr1U2IqqrnVVXda9/OAI4ADa9Ve/SKnlsb3crWhK2YbeZix42hvujrefGApxcrki7h18ibrcuPk3kp7xq0ViKRSGomNV5g5VhyAM23ffOxJAa9/xuXzH741h5M7W9OUvubkxjOZrEzNZOFH+zhbxkeeGxOIi/LgoeX3o0Fq5SbPVV1CdOeh+JmFXaDUbOkSQuW5Grh5+fH3Llzefvtt51ubg7atGlDu3btWLNmjduyM2fO5O233y6xbh8fH6KionjooYcYP348AOnp6Xh7e+Pn58fFixf56aefSm3fsWPHyMrK4uzZs8TFxREXF8ezzz7L0qVL6d+/P8uXLyclJQWA1NRUAPr3788nn3wCaC6Q6enp1KtXj8TERFJSUsjLyyvxmgDS0tKcc7y++uorZ/rAgQP56KOPnPsOq1j37t2Jj49nyZIlzuuU3HwIIUKATsDOIumPCCFihBAxSUlJ1d6Ofo37kWHOYO/FvcWOCSHwjqxLQLqFpkY9BxvqsVpsbPjqMKpasqugRCKRSKqOGi+wUnK0G7MgjyBOJ2cBEOinuRtd7FmXs/0bcLZ/A+qPaU14bR8863sy4NEO3DUljM6DQtyEaS+lS63mQtvunoQbPDSBJcO0S64mnTp1Ijw8vJD7m4OZM2eSkJDgtlz79u2JLGPhzPHjx7N//37GjRsHQHh4OJ06daJ9+/Y89NBD9OrVq9Ty0dHRjBgxolDaqFGjiI6Opn379sycOZO+ffsSHh7O008/DcAHH3zApk2b6NixI507d+aPP/7AYDDwwgsv0L17d4YMGUIbl0n1RZk1axb33HMPffr0cbofAjz33HNcunSJDh06EB4ezqZNm5zHxowZQ69evZxug5KbCyGED/AtMF1V1XTXY6qqzlNVtYuqql3q1KlT7W25JfgWTDoTm+I3uT3u0V77zk5rHMQ3xy/S7s6mJBy9xNHt56u9bRKJRCIBcaM90erSpYta0jo55cGSkkL27oLyh5IP8uUfC3iq81PEHBdsOprECxkpGFsNpcGsHigeBdPUvvzXb4SEB9Kom56UY3vIuhjP3os5BHrq6Fzfk1V/ZmC4lIguKwNhtTDp7Y/w8vIiNzcX44W9eOcnw8pHtMqCw6Hfc7zz/FxAi3ak2mx0HzGGnSuX41e3HpM+mAcnN4JvQ8i8AJ4BkJ8JOiMYfSAgFNISoFZ9MNUq89pVVeXUqVN4eHg4n847OH/+vPPp/xWTnw2JhyGoFXiUfy2VmoTVaqVly5bXuhmSKmTkyJFMmzaNfv36XeumXDd4eHiU24UT4MiRI7Rt27ZQmhBij6qqXUooclUQQhiANcA6VVVLDQ95pWNUeZm6YSonLp/gp5E/ue3jC2/txhrgQdSpeAa0rUv/84LLF7K5d1Z3PGvJtZ0kEomkKihpjKpxQS7yjh/n7PTpzn1/4B8AK9+hG9ANoMMYENZC4spqsZGTYSZHpLBkyYZCdZovnmP9rgRoFYHZvy5m/7oAfPjhhwQEBJCamoqClReYW1Do/H5Ycg/QhyYdwsnJSCfpzGkCGzUBoHXPWyHuN1g8uuSL6TAKDn0LjbrCpPVlXntycrIz6tsLL7yAohRY277++mtycnLKrKNinK7i+m4e7rjjjjKDLkhuDNLS0rjrrrto164dERER8nN1oV69egXW/RsUoamXL4AjZYmrq0lU4yi2JGzh+OXjtPJvVey4MdSPnD9SeOr2lsxZ9ye9bmtF/pl01s47xLDpESi6Gu/AIpFIJNVGjRNYnh07Err6e+f+4iOLWXl8JcvvXs6Mbw9hsdp4qW4o1ozC5bLtiw3rTJrFzyfhGKFBejrcOYbaPp7otrxGlrIf211vcTEpibU//wIUzAmxoYM7XoeWA2DjbDi8CoAnWm9DeXYVlvx8stMvU7teMM0iu2H08ICjJc8RASBuq/aesLtc1+46qd9qtRYSWHl5eURGRtK9e/dy1VUqW9+Hg8ugeX8YOPvK67sJSUpK4mq4Ekmqnzp16nDs2LFr3YzrEtffmBuYXsB9wEEhRKw97f9UVf3x2jVJE1gvbX+JzfGb3QosUzM/smMu8veW9Vl/JJH3d59h3j1t+D36T/7cdZE2PWRUQYlEIqkuqlVgCSEGAR8AOmC+qqpvFDk+AXjGvpsJPKaq6v7qbJPi7Y1Hq4LBKC7JRk5+Hbxat+GQ6QJt6/uipuvQ+RZ2uci6rAWn0HtoNwxKXg5BterQuu/dWobDHxOUmw4tW6HqSujWgGYQ1BL0BYsaGxQb6PXo9HpMXlqIdse7M6R7SViLR5AqNbtLZEKr1YrBHibeZrNhs9nw9fWlXr16FarTLR5mIAWMOVAV9d2EpKamOvtfIpFcv6iquhVHmNfriCDPIMKCwtj01yYeCXuk2HHPNgFcNihk77rAc0PaMfI/v/NjRhotm9Ri+8qTNO0QKF0FJRKJpJqoNoElhNABHwMDgARgtxBidZG1Q04DfVVVvSSEuBOYB1SBCaV0jsZc4K+f40BVaWtuSxu1FT//uZ2/XbJRLzuX3DyVvAAPzvxY4OJ26UI2AM71iFUVxVVI6UzOCIF6fQndqjcWfi8LSxlhdcsSYEWrs1jcbjuEV4ntriiqXcjJSIgSiURSbUQ1jmLuvrkkZidS16tuoWOKlwGvTnXJ2nuRsNsaM75bEz7fGsdLt7Yk939n2b7yJLfd37aEmiUSiURyJVSnBasbcEJV1VMAQoilwDDAKbBUVf3dJf8OoFE1tsfJ2dUnaZfvuPlvrL3lWWinN0CWJg6Ox2Vw+s+0QuU8axkweGoWLJtNRXEVJHojWOxuhCXNOXAsZuyyqLG9MnDnSmMtQ2CVJcCKVlfEguWsxi62qmyuhM1S+F0ikUgkVY5DYG1J2MI9re4pdrxWv8Zk7b1I+s9neHlUexLTc5n123Feat+Ao9vPE3F7EwIaeLupWSKRSCRXQnUKrIZAvMt+AqVbp/4OlL4gThWhs6nk2FSavNSDgd8NYECT2/lXl2cQQqCzLxTcQFfcI0QIwe/b7ZrQBqLCFixT4XcH1nxQPIrnt5RhoXKzyGRpXDULlsNypcpQ8xKJRFJdtKjdgoY+DdkS715g6f09qNWrIRm/JuDdPZiPJ0Ry/xe7eOvMeR43eLHt2xMMmRpWoUiPEolEIimb6pyB7O4X221MeCFEPzSB9UwJx6t0EUedTcUKqAYrqZYU6vrVxeRpwOihR2fUoTPqUHRKsZdQRIEwUdXCAqtcFiy7a6CuyNybkixVZVmwKoi0YElc0el0REREEB4eTmRkJL//rj08iIuLw9PTk4iICNq1a8f999/vXIB48+bNCCH44YcfnPUMGTKEzZs3AxAVFUWXLgXRSmNiYoiKiip03oMHDxIREUFERAQBAQGEhoYSERHB7bffXq52r169mjfeeKPsjEVYuXIlQgiOHj1a4bISyfWIEIK+jfqy4/wOcizuo8DW6tcYnb8HKf89jD7LwucPdKFR/VpsMeTz1x8pHNjkfo07iUQikVSe6hRYCTj97wDN/e9c0UxCiDBgPjBMVdUUdxVV9SKOQgUrkJSjibU6nuWvs0CYqCh6F6FUEQtWURfBkixVFZxjVRburFau21UmsJxzsKQF63rG09OT2NhY9u/fz+uvv86zzz7rPNa8eXNiY2M5ePAgCQkJLF++3HmsUaNGvPrqqyXWm5iYyE8/lWyM7tixI7GxscTGxjJ06FDeeustYmNjWb++YKkB1+9qUYYOHcqMGTPKe5lOoqOj6d27t9vFlKsS178tiaS6iWocRZ41j53nd7o9rnjoCXqgHWq+jZTFR/A16vj6oW6kNjRy0mhl6zcnSDmbeZVbLZFIJDc31ekiuBtoKYQIBc4C44B7XTMIIZoA3wH3qar6ZzW2pRA6FWxAYnYiAPW8yh/pzmq1otMpCIq6CJbHgmUXZEWDXJRkqSrLRbCCuLNauW5XnYug/TyqDHJRHn5b/ifJ8VV7gxPU2Ic+Y4qHbi6J9PR0/P39i6XrdDq6devG2bNnnWnh4eGYzWZ++eUXBgwYUKzMv/71L2bPns2dd95ZoTZHRUXRs2dPtm3bxtChQ2nVqhWzZ88mPz+fwMBAFi9eTL169Vi4cCExMTF89NFHTJw4EV9fX2JiYrhw4QJz5sxh9Ojia8dlZmaybds2Nm3axNChQ5k1axag/U0888wzrFu3DiEEDz/8MNOmTWP37t08+eSTZGVlYTKZ2LBhA99++63zvKBZ7v75z38SFRWFj48PTz/9NOvWreOdd95h48aN/PDDD+Tk5NCzZ08+++wzhBCcOHGCyZMnk5SUhE6nY8WKFcyaNYvRo0czbNgwACZMmMDYsWMZOnRohfpPUjPpUq8LPgYfNsdvJqpxlNs8hnre+I9uSerio6T/coY6g0JZ+mhPJs3bScM/8/n+6z946Nlqjy8lkUgkNYZqs2CpqmoBpgLrgCPAclVV/xBCTBZCTLZnewEIBP4jhIgVQsRUV3tcUVCxAEnZdguWV/ktWBaLBb09IIXi6uqnNzotThUOclGSpeoquQhWuQVLugjeEOTk5BAREUGbNm2YNGkSzz//fLE8ubm57Ny5k0GDBhVKf+6555g92/0aZz169MBkMrFp06YKt+ny5cts2bKFf/zjH/Tu3ZsdO3awb98+xo0bx5w5c9yWOX/+PFu3bmXNmjUlWrZWrVrFoEGDaNWqFQEBAezduxeAefPmcfr0afbt28eBAweYMGEC+fn5jB07lg8++ID9+/ezfv16PD09S213VlYWHTp0YOfOnfTu3ZupU6eye/duDh06RE5ODmvWaGvaTZgwgSlTprB//35+//13goODmTRpEgsWLAC0RYt///13Bg8eXOG+k9RMDDoDPRv05NeEX7GV8lDLq2MdvLvWJ2NLArknLhPgbWThY7dwrr6BnDNZLFlz1Z5xSiQSyU1Pta6DZV+I8cciaZ+6bE8CJlVnG9yhqFaswsLcfXMBioW3LQ2r1eoMhOHWRVBVKx7koiRLVRVbsK5emHb7IC9dBMtFRSxNVYnDRRBg+/bt3H///Rw6dAiAkydPEhERwfHjxxk9ejRhYWGFyvbp0weA3377zW3dDgH25ptvVqhNY8eOdW4nJCQwduxYzp8/T35+PqGhoW7LDB8+HEVRaNeuHRcvXnSbJzo6munTpwMwbtw4oqOjiYyMZP369UyePNn53Q8ICODgwYMEBwfTtWtXAHx9fctst06nY9SoUc79TZs2MWfOHLKzs0lNTaV9+/ZERUVx9uxZRowYAYCHhxbYpm/fvkyZMoXExES+++47Ro0aVXV/i5IaQVTjKH4+8zNHUo7QPqh9ifn87m5GXlwaqcuPUe/JSHy9Dcz6xy18/uw2/vzxL35s5MPgiAZXseUSiURyc1Kdc7CuWxRVxSLMNPBuwJhWY/A1ln0D5cBisTgFltAXsWABWM3lCHJRThdBGeRCcpXo0aMHycnJOILIOOZgnThxgh07drB69epiZWbOnFniXKzbbruN3NxcduzYUaF2eHsXhIyeNm0aU6dO5eDBg3z22Wfk5ua6LWMyFTywUNXicXRSUlLYuHEjkyZNIiQkhLfeeotly5ahqiqqqhaLoOYuDbQHEDaXtd1c2+Ph4eH8+8nNzeXxxx/nm2++4eDBgzz88MPk5ua6bZuD++67j8WLF7NgwQIefPDBEvNJJO7o07APOqHjlzO/lJpPMeoIGNcGW5aZS8uPodpUavkYuevB9tSxKSz+6hC/Hb/yQFISiURS06mZAguBBZX5d8zn+R7PVyhEbWELlotQcrj9WfNKFirOIBdFBNbNFuTCOQdLWrBuFI4ePYrVaiUwMLBQenBwMG+88Qavv/56sTIDBw7k0qVL7N+/322dM2fOLNGtrzykpaXRsGFDAL766qtK1/PNN99w//33c+bMGeLi4oiPjyc0NJStW7cycOBAPv30U+ffRmpqKm3atOHcuXPs3r0bgIyMDCwWCyEhIcTGxmKz2YiPj2fXrl1uz+cQXkFBQWRmZvLNN98AmiWsUaNGrFq1CoC8vDyys7UFzCdOnMj7778PQPv2JVsgJBJ31PaozS0NbmFt3NpShTyAsaEPte9qRu6xS+Qc1MRU68i6NO4YSLc8PU/M383y3fFYbaXXI5FIJJKSqZECSw9YROUCMFgsFuz6ClFoDpZdPJXm1ucQVjd7kAtnFEEZ5OJ6xjEHKyIigrFjx/LVV1+5FdnDhw8nOzvbrTvgzJkzSUhwH+Z58ODBXEnUz1mzZnHPPffQp08fgoKCKl1PdHS00y3PwahRo1iyZAmTJk2iSZMmhIWFER4ezpIlSzAajSxbtoxp06YRHh7OgAEDyM3NpVevXoSGhtKxY0f++c9/EhkZ6fZ8tWvX5uGHH6Zjx44MHz7c6WoIsGjRIubOnUtYWBg9e/bkwoULANSrV4+2bdtK65Wk0gwKGcTZzLMcSj5UZl7vW4Ix1Pci/eczqFbtdzpqbCs8DDpG2Lz497cHuPvDraRmVe0YdD3x7Z4E9pxJvdbNkEgkNyk10tFfUQUWKnfzb7Va0QkwA4rB1YLlcBEsxa3PYSkrFqb96rgIXj0LlnQRvBEoKZx4SEiIcy4WaGvtuFqpXNe1Gjp0aKEn5o71sBzs2bOn1DYsXLiwxLLDhg1zRtZzZeLEiUycOLFYedCiBRalaL0ATzzxhHP73Xff5d133y10vGvXrm7dGxcvXlwszd15Z8+e7TYISMuWLdm4cWOx9OzsbI4fP8748ePd1i+RlMVtTW7j5e0v81PcT3Ss07HUvEIR+A4MIeXrw2TtvojPLcH4BnnS7a5Qfv/uBDP6h/BO7Bmi3trEk7e34qFeITfdYsT/WKH9psW9cdc1bolEIrkZqZEWLJ0QlbZgaQJLu6EsZMFyCKySxJIrRYNclOQKeKNasByWK+kiKJGUyfr162nTpg3Tpk3Dz8/vWjdHcoPia/Sld8PerDu9rtRogg482gZgDPUl/ec4bNnaQuIdoxriXdtE0Kkcvp/Si05N/HllzWHu+2IXO0+5XaZSIpFIJG6ocQJLVVVtDlYVuAgWsmA5RJPVXHYlxYJclBKm3Vir4o0sAavVitFodG67poO0YEkk14Lbb7+dv/76yxnlUCKpLINCBpGYk8jei3vLzCuEoPbQFtiyLZx7eQep3/yJThF0GxLKxdPpeCTms/DBrjx3V1uOXcxg3Oc7WLTjTJlzvCQSiURSAwWWzaqiUPk5WFarFR12C5arJao8LoIOKhKm3eRTiVaWUJ3F4oy4Vr1h2uUcLIlEIrnaRDWOwlPvycoTK8uV3xjsTa2+jQDIjrlI1p6LtOlRn9r1vNi+8iQ2q8qkPs349V/96NuqDs+vOsRTy2LJypMPzyQSiaQ0apzAspht6ARYlMo9hbNYLOjs87cUV6FUniAXDlxdC6GUMO35YCynwCrHmlNWq9UpsGSYdolEIrm58DJ4cXezu1kXt47LuZfLVcZ3UAgNX+uNPtCDyytPYDmXRa/RLbh8MZv9G+IB8DTq+OKBrvxjQCtW7z/H3R9t5cj59Gq8kurF5hIh8Yutp69hSyQSyc1KzRNY+VYEV2bBUuxlRUWDXDjzViDIhamcLoLlmPtlsVgwGAwIIWSYdolEIrkJGdN6DHnWPFadWFWu/EIIhCLw7KBF6kz8JJbacWmEhgWy+3+nyUrTxhadIpjWvyWLJ91CZq6FYR9vY+G20zeky2C+tWD8f2XNYfIscqySSCRVS40TWFazDR1gUa5gDpZamgWrioNclFdglUPYWa1WdDodOp2umsO02/u2HFY1iUQikVQdrQNaE1k3kmXHlpUr2IWDWv2bEPhAO0whfmRuO0e3sCAs+TaO/H6+UL4ezQP58ck+9G4RxKwfDjNxwW6OXrixrFmuAgsgK0+OVRKJpGqpcQLLnGvVLDiVjDhrtVpRHC6CBtc5WI4gF+VxESy60HBVWLDKPq/FYkGv16PX64tZsIQQKEoVfR2ki+ANgU6nIyIigvDwcCIjI/n9998BiIuLw9PTk4iICNq1a8f999+P2awFb9m8eTNCCH744QdnPUOGDHGGQo+KiqJLly7OYzExMYXCujsIDQ3l2LFjhdKmT59e6sLEISEhJCcnuz22b98+hBCsW7euXNcukdzMjG09loTMBLad3VbuMopRh2fbQIImdURX24R1XyKNWvnxx29nsVoKC5IgHxNfPNCFV4a1JyYulcEf/MZLP/xxw6yblW8pKrDkWCWRSKqWGiewrPYnVZWdg2W1Wp0WLOHqUueYV1XVFqzyzsG6QgtWlVmvwMVFUAa5uJ7x9PQkNjaW/fv38/rrr/Pss886jzVv3pzY2FgOHjxIQkICy5cvdx5r1KgRr776aon1JiYm8tNPP5V67nHjxrF06VLnvs1m45tvvmHs2LGVupbo6Gh69+5NdHR0pcqXl5LWDpNIricGNB1AkGcQX/3xVYXLCkXgd1co5rOZRAR7k5maV8yKBZpr4X09Qtg24zbu7d6Ehb/H0fetTSzcdvq6d7nLKyqw8qXAkkgkVUuNW2jYnKs9ibdWUlpaLBZ0ijZ4KK4CS19ZC5Yo3YJl8Chnw8pnwXIIrKIWrCqbfwXSglVBNi2cR+KZU1VaZ92mzeg38ZFy509PT8ff379Yuk6no1u3bpw9e9aZFh4ejtls5pdffmHAgAHFyvzrX/9i9uzZ3HnnnSWeb/z48YwdO5YXX3wRgF9//ZWQkBCaNm3K8OHDiY+PJzc3lyeffJJHHin9OlRV5ZtvvuGXX36hT58+5Obm4uGh/d3MmTOHRYsWoSgKd955J2+88QYnTpxg8uTJJCUlodPpWLFiBfHx8bz99tusWbMGgKlTp9KlSxcmTpxISEgIDz30ED///DNTp04lIyODefPmkZ+fT4sWLVi0aBFeXl5cvHiRyZMnc+qU9ll+8skn/PTTTwQFBfHkk08CMHPmTOrVq1dooWOJpKox6Aw82P5B3op5i5gLMXSp36XsQi54daxDVosL5O1Pont9T3Z8f5LmkXXw9DEWy1vby8js4R2575YQnv/+ELN+OMw3exN4554IWtevumVGqpLiFqzrWxBKJJIbjxpnwcrNzgXAWkk9obkIaj/GwtWlzhnkooICS28qZR2s/OIBMUpsWNnntVqtJboIVqnAcoZpl4PW9UxOTg4RERG0adOGSZMm8fzzzxfLk5uby86dOxk0aFCh9Oeee47Zs2e7rbdHjx6YTCY2bdpU4rnDwsJQFIX9+/cDsHTpUsaPHw/Al19+yZ49e4iJiWHu3LmkpJS+wOm2bdsIDQ2lefPmREVF8eOPPwLw008/sWrVKnbu3Mn+/fv597//DcCECROYMmUK+/fv5/fffyc4OLjU+gE8PDzYunUr48aNY+TIkezevZv9+/fTtm1bvvjiCwCeeOIJ+vbty/79+9m7dy/t27fn73//O199pVkRbDYbS5cuZcKECWWeTyK5Uu5pfQ+BHoF8uv/TSpWv1achAPVzLUSicuTnv0rN37p+LZY/2oN593UmPjWHO97/lUcXxRCXnFWp81cnDoF1S7MAQLoISiSSqqfGWbB8a10iD8g3ZVa4rKqqWCwWRM5loIjAcliwTm0u0SK1d+9ebDYbqFYaUodgkjQBdT4WYhYUZFT0EBwOuWmkW40cpwMNucBZ6qNSwuSxX1aApz8B3nryLSqZeVao3RTMWRDUCoDszAx0/t7obPkkJycTExMDwMWLFzUXwcwkSD8LDSLcn+PcPq29CbuhQSet3TYr1KoPLQZA3G/g6Q8ZF+0dZoXkE6DoNHfB07+Chx+0HwGiEpPgjv8CaQkVL1dZPP2h3bDKtbUCVMTSVJU4XAQBtm/fzv3338+hQ4cAOHnyJBERERw/fpzRo0cTFhZWqGyfPn0A+O2339zW7RBgb775ZonnHz9+PEuXLqV9+/Z8//33vPzyywDMnTuXlSu1dXzi4+M5fvw4gYGBJdYTHR3NuHHjAM31cNGiRYwcOZL169fz4IMP4uXlBUBAQAAZGRmcPXuWESNGADgtXWXh6rp46NAhnnvuOS5fvkxmZiZ33HEHABs3buTrr78GNMufn58ffn5+BAYGsm/fPi5evEinTp1KvRaJpKrw1HvyYIcHeTvm7UpZsTxaB9Bwdi8urTxBnT0Xydl1nry+DTEFepZabmD7+nRq4s/inWeY9+spNh7dwsSeIUy9rSV+noZSy14tHAKrd4sgdpxKlQJLIpFUOTVOYNnS4oDamJTsipc1a1YiJUsTEIriYvXxqA3GWnBgGRxYRkuGcZxmhcqvXr3auR3MAB69pbYmOhwvN/yW5MtuirthFeOECqQWSXTs/+lM8Tu+glyCOH65mdMdCqBJkybwWR/IOA+z0tyfY15Uyefv9ijs+qxwms0CH3XWttsMgaP289VpDfXal3VFhcnLgMX3AFc5JPDUPRDU4uqe8xrQo0cPkpOTSUpKAgrmYJ0/f56oqChWr17N0KFDC5WZOXMmr776qtv5e7fddhvPP/88O3bsKPGc48ePZ+DAgfTt25ewsDDq1q3L5s2bWb9+Pdu3b8fLy4uoqChyc3NLrMNqtfLtt9+yevVqXn31VVRVJSUlhYyMDFRVRRQRxyWFlNbr9drDDztFz+nt7e3cnjhxIqtWrSI8PJyFCxc6A3yUxKRJk1i4cCEXLlzgoYceKjWvRFKVjGk9hgWHFvDhvg9ZOGhhsb+HshB6hYB7WpFdzwvj/06R8OkBmj3bDaGUXk+dWiam396Ke7s14Z2f/2T+1tN8syeB6be3YmzXxngYqtBjohLk2z04/L01b5KsfOltIZFIqpYaJ7DyVYEARCXWwbLmaa4OSr32cOpg4ah7Ri/4x1FNCAD3qirnLibx+ZKVhep46qmn+PHHH0lODoQ7pmrWrpxLrieBD8K17dpNyPdvCX9pblQGg4Fp06YV5M25pAXByM8Caz679h1i6+5YAAYH/kWblLVavmGfQPN+8G4bapGFDYWsJ46BvuDpvZeXF8x+qoI9ImDQ67B2hmbNKo18F4thfiVcRvKzARX6vwjh4ytevqKc3ADfTync7puYo0ePYrVaCQwMJDu74OFDcHAwb7zxBq+//noxgTVw4ECef/55zp0757bOmTNnMnnyZJo1a+b2ePPmzQkMDGTGjBlMnz4dgLS0NPz9/fHy8uLo0aOlCjSA9evXEx4eXih64AMPPMCqVasYOHAgL7/8Mvfeey9eXl6kpqYSEBBAo0aNWLVqFcOHDycvLw+r1UrTpk05fPgweXl55ObmsmHDBnr37u32nBkZGQQHB2M2m1m8eDENG2quVP379+eTTz5h+vTpWK1WsrKy8PX1ZcSIEbzwwguYzWaWLFlS6vVIJFWJp96Tx8IfY/bO2fzv9P8Y0mxIpeppdGsjdu1NosGFTBJWnqDxqJblKlfX14M3R4dxf8+mzF5zhBdX/8Enm0/yzphwerUIqlRbqoI8szb+B3jZBZa0YEkkkiqmxgmsPKvAA9CJiltCLPnaU23H+lei6Lwlk4/2AgSgzy3+lM7Pzw8PDw8tip8QWhALg8scEJen6NRqUCjan16vx9fXt+C4c1tzOfKKS3Qe8vHQ44tdyHga7Hm1fR02fD2N4OlSlyuqWtwtzuZGkOpN4F1H2y4reqJrEI7yRFosiiNKoncd8C17zswV41Pfft4bI+xwZXDMwQLNsvPVV1+5nYs3fPhwZs2a5dYdcObMmQwbNsxt/YMHD6ZOnTqltmH8+PE8++yzTpe9QYMG8emnnxIWFkbr1q255ZZbSi0fHR3tLOtg1KhRzgATsbGxdOnSBaPRyODBg3nttddYtGgRjz76KC+88AIGg4EVK1bQrFkzxowZQ1hYGC1btqRTp04lnvOVV16he/fuNG3alI4dO5KRoT1U+eCDD3jkkUf44osv0Ol0fPLJJ/To0QOj0Ui/fv2oXbt21c51lEjKwahWo1hzag2vbH+FjkEdaerbtFL1RE4J4+DMbQTGXMDSrzH6gHIGYALaN/BjycPd2XYihRdXH+JvX+xkUu9Qpt/eCm/T1b8NybOvg1XbIbBkFEGJRFLF1DiBZVaxC6zKWLC0J/sON4uy1o0q6WaqaBS/QiiKNgfLZgGdoVC+sm7OXI/rdGV8tKUJB/u5y8yvM5Z/gWVrnt3allmukPLFcAi0oiHuq4uKhN2/QSnpOxgSEuKciwXa990RjAIotK7V0KFDC7ndFXWX27NnT6lteOqpp3jqqQLLqclkKjHEe1xcXLG0hQsXFksbOnSo09o2Y8YMZsyYUeh4y5Yt2bhxY7Fyc+bMcbsOV9HzPvbYYzz22GPF8tWrV4/vv/++WLrNZmPHjh2sWLGi2DGJpLrRK3re6vsWo38YzT+3/JP/Dv4vpvIGT3Ktx6Ajs20g/kdTSFx8hOApEWW6CroihKB3yyDWTOvD7P8d5vPfTrN6/zn+fUcbRnRqiFKBuq4UxxysWh56dIqQFiyJRFLl1LgogvlW7WZQXwmBZTHbLVh2YaWUIXiKzk1xCLNSBRYURA7UmwpZsCoisIrNiyk696Q0geVOVJQksJzRE8sSWPkFiyaXI6R88fL2+osKv+qiImH3JZISOHz4MC1atKB///60bFk+tyqJpKqp712fV3u9ytHUo7y1+61K1xN+dzOOqQLb2UzSN5UeVbAkPI06Xh3RkW8f60l9P0/+sWI/g+f+xrd7ErBYr87aiQ6B5WFQ8DbqnGHaM/MsWG1XeZ6vRCK5KalxAgudnsu6NPRKJSxY+dpNviN6oKigBcshsPR6fSHhVAy9XbToTIWEWFmLAbseL2TBEgKs5sKZS7PMuBMV7tL0JheBVaR+pYgQsrgIrMqIFkeZSjx5rRQVCbsvkZRAu3btOHXqFO+88861boqkhtO3cV8eaPcAy44t4+e4nytVh2+QJy3HtSYh30b6+r/IO5Ne6fZ0burPysd68v7YCGyqyj9W7Gfge7+yeOcZLmVV7++uY6Fho06Ht0nP0QvpPL/qEN1eXc/t724hPddcRg0SiURSOjVOYIWHR9DBMIEyIs26xZKfA4AiNOFUlsAqKogclq/yW7CMlXYR1BtcBI7NUtzCVJpwcHfMnSBzdREsWqaoK58178oEltNFsPhCl9VCeV0fJRKJ5Abhyc5PEhYUxou/v8hf6ZWzQIV2qkNaS3+yLSrnvjiE7Qoi8CmKYHinhqybfivz7uuMyaBj5spDdH11PQ8u2MW2E8mVrrs0HBYso17B26Rnx6lUFu04Q3a+ldPJWRyILyGSrkQikZSTGiewVLtlwkDFn1BZzfabbWF3EVTKL3i0/Fo5R0hom7vAEVDIglU0yEVpFLJguea15BV3yytNOLh1EXSTpjcViMGiZXRFhJCrBetKglxcNQuWdBGUSCQ3FwbFwFt930Kn6Hjkl0c4l+k+AmhpCCG47aH2nK3nhSHfSvLSY6hX6FYnhGBg+/r8+ERv/vdEb/7eJ5TD59OZMH8nfeZsZObKg2w/mVJlLoT5Fk0UGvUKrer5ONObBmpr5h29kM68X0+SIS1ZEomkktQ4gWUVmmXHoFZCYNldBJUrdBF0pJdoxaoSC5aLwLHmV4EFq6QgFyW40hUVWI4gF47tinK1g1w4rktasCQSyU1EA58GfDbgM9Lz0nlo3UNcyLpQ4ToMJh0dx7TmcI6V/MMppG/8q1wiy5qRT96pyyUeF0LQvoEfz97Zli3/6scrw9rTtr4v3+5NYPznO4h85RemLNnLiph4EjNKXh+vLPKtBRas10Z0ZFzXxvz81K388lRfPA06Pvv1FK/9eJQHF+yu9DkkEknNpsZFEbQqBvRUzoJlsS80LET5glzodDqEEM4oa64ugqAJLIPBTdAGhzjRGSsd5EKnLyqwigigKgty4bBgFRnsirryWc1gsoeFv6IgF1fJRVDOwZJIJDcp7QPbM2/gPB7++WEeXPsgCwYtoL53/QrVEdTYB12nOlw4mAzr/8Kakov/mFalLmacvOAQ5nNZNHylJ6KMxYY9DDru6xHCfT1CyMqz8NvxJDYcSWTLn0n878B57Toa+BLVug5RrevSqXFt9LryPTN2ugjqFHxMet4YFeY8FhLkzZHz2tyymDOXyDVbr/nCyBKJ5Maj5lmw0GFTBXq14mFZrU6Bpf3YlhWmHQqLHlcXQaDkQBdVEeTC1YJlya+Yi6A7C1NJQS4cbVWLuG4UdeWz5DnXCKucBSuv4JxXgxogsHQ6HREREc7XG2+8UW3nWrhwIVOnTq10+c2bN+Pn50enTp1o3bo1t956K2vWrKnCFhbnStp88OBBZ78GBAQQGhpKREQEt99+e7nKr169ulKfx8qVKxFCcPTo0QqXldQsOgR14LMBn3E57zIT107k5OWTFSovhKDf/e04bNBx1qQje18iGZsTSi1jvpBlf88uNV9RvE16BnUI5q17wtn5f/353xO9+dcdrfE26vl0yynu+XQ7nV75hYcW7uazLSfZ99elUt0J8yw2bRlKXXEx2KKuT6H9U0lZFWqrRCKRQA20YFlUyEdfKRdBi30OluMJXbGFht3gGjGwMi6ClQ7TXshFMK9iLoLuLEwlBbkoyaJUWpCLSlmwHFEEZZCLqsLT05PY2Nhr3Qy3WCyWYg8U+vTp4xRVsbGxDB8+HE9PT/r3738tmlgM1zZ37NjR2bcTJ05kyJAhjB49usT8RXFdy6siREdH07t3b5YuXcqsWbMqXL68WK1WuWjyTUBYnTDmDZjHtI3TmPDjBF7v/Tr9mvQrd3lFEUQODuXX6GN4N/SGdXEoXnq8u9Z3u0aW4m3AlmHm8uqTBE3qgFKJRYYdboTtG/gxpV8L0nPNbDuezK/Hk9l5OoWNRxMB8PM00LdVHXq1CKRrSABNArycFq58iw2jTnFrbZt+e0v2xKXSt3Vdonf9xYmkTNo18K1wOyUSSc2mxgksq1UlHwN6teI3+VbLVbJgOdZ6uhILlquLXkWDXLgN015GkIuiuBNCBk8tQMgVhWm/Wi6CVy/IxeUfTpJ/rmqfkhobeFP77uaVKhsSEsIDDzzADz/8gNlsZsWKFbRp04bMzEymTZtGTEwMQghefPFFRo0aRXR0NK+99hqqqnLXXXfx5ptvArBgwQJef/11goODadWqFSaT1qdJSUlMnjyZv/7Sopi9//779OrVi1mzZnHu3Dni4uIICgpiyZIlJbYxIiKCF154gY8++oj+/fuXWOf11GbQFmnu2bMn27ZtY+jQobRq1YrZs2eTn59PYGAgixcvpl69eixcuJCYmBg++ugjJk6ciK+vLzExMVy4cIE5c+YUE2sAmZmZbNu2jU2bNjF06FCnwLJarTzzzDOsW7cOIQQPP/ww06ZNY/fu3Tz55JNkZWVhMpnYsGED3377rfO8AEOGDOGf//wnUVFR+Pj48PTTT7Nu3TreeecdNm7cyA8//EBOTg49e/bks88+QwjBiRMnmDx5MklJSeh0OlasWMGsWbMYPXo0w4YNA2DChAmMHTu2UiJSUrV0rNORpUOWMn3TdKZvns47fd/h9qbls7QCdLi1IZmXcvntpzMMae3H5ZUnsF7KxW9QaLG8DtGVH59BxpYE/AaGXHH7fT0M3NkxmDs7BgOQmJHLzlOpbD6WxJY/k1i9XwvkUbeWia4hAQT6GPlmTwImvfvxu3kdH7bNuI08i41lu/9i56kUBrWvj7GE/BKJROKOmiewVBULevSVsmDZy4jyBbkA9wKrTAuWvX4tyEWBsKmQBcvoUXDgagS5KIo7Vz6dXZDdEC6Ceu1zuIktWDk5OURERDj3n332WcaOHQtAUFAQe/fu5T//+Q9vv/028+fP55VXXsHPz4+DBw8CcOnSJc6dO8czzzzDnj178Pf3Z+DAgaxatYru3bvz4osvsmfPHvz8/OjXrx+dOnUC4Mknn+Spp56id+/e/PXXX9xxxx0cOXIEgD179rB161Y8PcteRyEyMpK33nqr1DqvtzYDXL58mS1btjjbs2PHDoQQzJ8/nzlz5rhdM+v8+fNs3bqVo0ePMnToULcCa9WqVQwaNIhWrVoREBDA3r17iYyMZN68eZw+fZp9+/ah1+tJTU0lPz+fsWPHsmzZMrp27Up6enqZ7c/KyqJDhw68/PLLgLbG1wsvvADAfffdx5o1a7j77ruZMGECM2bMYMSIEeTm5mKz2Zg0aRLvvfcew4YNIy0tjd9//52vvvqqXP0lqX7qe9fnyzu+5O/r/s5Tm5/i0bBHeTzicRRRPlERcXsTTsUm8+PpDIZ2rUvG5gSsmWZqDw5F8TKg2lQSP47FmpaP8NCh5lrJjk3CFOqHsUmtSlmySqJuLQ/uDm/A3eENUFWVE4mZ7P3rEuuPJHLkfDrJmXk0CfDiod7FBaADIQQeBh0dG9Vm8c6/+D72HA/1DuWp21uWOsdMIpFIHNQ8gWVTsWBAV5kogpbCAqusMO1Q2KpUbgsW9mhMOhMWS4Flo2JzsFyEiCWvuFCoijDtiq5iFizHnK0bwUUQKi8GK0hlLU1XSmkugiNHjgSgc+fOfPfddwCsX7+epUuXOvP4+/vz66+/EhUVRZ06dQDNMvHrr78CFEofO3Ysf/75p7Oew4cPO+tJT08nIyMD0FzjyitUHMFjSqvzemuzo14HCQkJjB07lvPnz5Ofn09oqPubvuHDh6MoCu3atePixYtu80RHRzN9+nQAxo0bR3R0NJGRkaxfv57Jkyc7fx8CAgI4ePAgwcHBdO3aFQBf37JdoHQ6HaNGjXLub9q0iTlz5pCdnU1qairt27cnKiqKs2fPMmLECAA8PLQHPX379mXKlCkkJiby3XffMWrUqDJ/zyRXFy+DFwvvXMjsHbP57MBnxFyMYVaPWYT4hZRZ1sPbwLDpESybvYtNJ9O5o0cw2TsvYD6bSe0RLbCm5WE+mwmA38AQhEHh0rfHSf7iEF6RdQkY07parkkIQct6tWhZrxZjuzapcPllj9zC7yeTWb47gbkbjrPjZAqDO9anX5u6NA30roYWSySSm4UaN8JZbCpmtXIWLKtzLlXlLFjlnoNlx6YYCq2VVZZLYqFzuQosq1l7uVKqBcudwCqhv3RuoiCCeyGkM9w4FizQrqGk677JcbjG6XQ654MAVVWLPb11FTlFKelJr81mY/v27W5Fibe3dtOycuVKXnrpJQDmz5/vtp59+/bRtm3bUuu8mm0uL675p02bxtNPP83QoUPZvHlzifOmHJ8HuG9/SkoKGzdu5NChQwghsFqtCCGYM2dOiX3g7loda/Q5yM0tiA7q4eHh/I3Jzc3l8ccfJyYmhsaNGzNr1ixyc3NL7dv77ruPxYsXs3TpUr788ssS80muHSadiZd7vkznep2Zs3sOo1aP4rGIx3ig/QMYlBJ+6+14+5m4/cF2rPlwP99vu8CIsS3J+d8pkv6zv1A+YdJhaubn3Lck5VTLtVQFHgYdt7WpR7/WdVn4exyLtp9h1g+HmfXDYRrW9qRzU3/nq039WuWOYiiRSG5+atyvgTYHS18pC1aBxUm7MSnPHCx3FqzyCiyrfUBz3FyV5ZpQyIXQ1bJUniAXrjdGZQW5MLk87RbCvRXLrcAyaQLpiixYV1Fg6Y03tYtgRRk4cKBzbg5o7m3du3dny5YtJCcnY7VaiY6Opm/fvnTv3p3NmzeTkpLinMdVUj3urGgjRowgNjaW2NhYunTpUuz4gQMHeOWVV5gyZUqpdV7NNleGtLQ0GjZsCHBFLnPffPMN999/P2fOnCEuLo74+HhCQ0PZunUrAwcO5NNPP3X+fqWmptKmTRvOnTvH7t3aOj8ZGRlYLBZCQkKIjY3FZrMRHx/Prl273J7PIbyCgoLIzMzkm2++ATRLWKNGjVi1ahUAeXl5ZGdrEeMmTpzI+++/D0D79u0rfa2S6kUIwfAWw1k9fDV9G/flg70fMPL7kfx46kdsRaPFFqFJu0BG/rsz5lwL636Mw/PBDtQe3gL/US2p/++u+I5sSX4DH/T+BS7s+fEZJM07wOUfT2HLK31MvFYIIXiwVygb/xnFpn9G8dLQ9kQ0rs3O0ym8uPoPhny4lbCXfmb8vB289MMfLN55hh2nUkjKyCv1oYNEIrl5qXEWLKuqBbnwtVXCgmW3ZgihgBCVnoNVtoug/XxCEykmk4m8vLJv9Au53BQLclGGi6Cr4HJrwXJJM3hCXrrLudxYpdyJQb3JbhWqpAVL0UM5+rzK0Jlu6jDtRedgDRo0qNTQ4M899xxTpkyhQ4cO6HQ6XnzxRUaOHMnrr79Ov379UFWVwYMHOwMZzJo1ix49ehAcHExkZKTzgcLcuXOZMmUKYWFhWCwWbr31Vj799NMy2/vbb7/RqVMnsrOzqVu3LnPnznVGECypzmvd5rKYNWsW99xzDw0bNuSWW27h9OnTlaonOjqaGTNmFEobNWoUS5Ys4cMPP+TPP/8kLCwMg8HAww8/zNSpU1m2bBnTpk0jJycHT09P1q9fT69evQgNDaVjx4506NCByMhIt+erXbs2Dz/8MB07diQkJMTpagiwaNEiHn30UV544QUMBgMrVqygWbNm1KtXj7Zt2zJ8+PBKXaPk6hLkGcS7Ue+yOX4zH+z9gGd+e4bPD37O1Iip3NbkthIf+NUP9WPQIx1Zv+Awqz7az+hnuuAToAmqbfuSOPXlYf7+Th+CJnXk0rd/Yr2UR96pNPJOpaEP9MSne/BVvMqKExrkTWiQNw/0DEFVVc5ezmHPmUvsPXOJvX9dZumueHLMBULR10NP87o+NK+jvVrU9aF5HW8aB3hhkBYvieSmRdxoT1e6dOmixsTEVLr8icQM0j+KonH9utR5/KcKld204BW2nLFyW8um7Pnf9zy1ZFWZZRYuXEhcXBwA9evXZ/LkyZw9e5bPP/+c8ePH07q1G9/zr+6G07+SOWQeb685QmBgICkpKXTt2pW77rqrxHNZLBZmz54NwKwH+sNXQ7QDYWOhWRSseqwgc7+Z0PffBfu56fBGY237zreg+yOFK9/xKax9Rtv2awxp8dB+BNyzEOY0h+zkwvnbDIGjRdYpGrMINr8OAc1g3OISr8Mt62ZCzAKYea5i5a6EuZ2gQSSM/qLKqz5y5IjTvU0iqQlkZ2fTsWNH9u7di5+fn9s87v4uhBB7VFUtbsa8TrnSMep6xKbaWBe3jv/E/oe49Dha1G7B+DbjGdFyRImugylnM/l2zh4s+Va6D2tGw1b+fDtnDwC3jmtFx6hG5BxOIeXrw3jfEkzWDm3x4Fq3NaZW30ZVGvjiamKzqZxPz+VkYiYnk7TXicRMTiZlkZRR8HBRERDs50lDf08a+XvSqLYnjfy9tG1/L+r7ecjIhRLJDUBJY9SN+Qt2BVhsmgVLsVUiTLvVioL2ZKo87oFQSQuWXfRahaFQ/rLEcGEXwWq0YDnmXTnaU97AE3qTVrYyViFLXsnzvaqLqxTkQiK52Vm/fj0PPfQQTz/9dIniSnL9ogiFO0PvZEDTAfx4+kf+e/i/vLLjFeYfnM+g0EGMbjmaJr6Fg0gENvRh6JMRbFx0lB2rThU6tn3VSYJb1CaoXSANZ/dC6BWMjWuR8WsCGRvjydp1Ad/+TfDuVh9xg1l5FEXQsLYnDWt7cmurOoWOpeWYOWUXXH+lZpNwKYezl3LYcTKF8+m5FB3ia3sZCPQ2Euhjsr8bCfQ2EeRjJMDbRKCPkSB7mp+nAcXN2mMSieTaUPMEllUlX9Wjq5SLoBUdNmxWa7ncA6GSYdod57N/POVd0LOQy4ari6A1v7ioKSocXAVXWWHaRZH2lBSqvSjOIBeVnIN1NQNcgNbeyswXk0gkhbj99tuda4hJblz0ip6hzYdyd7O72ZKwhWXHlrHoj0UsOLSAbvW7MSh0EP0a9yPIMwiA+s38GDY9gv0b4vHyNXL+RBqRg5ryv4/3s2z2LjoPakrXu0PRAd6d6+HduR55f6WT9tNpLn9/kszt5/DuWh/P9kHoAzxKb9wNgJ+ngU5N/OnUxL/YsXyLjQtpuSRc1oTXucs5pGTmk5KVR0pmPscTM9lxKo9L2e7vXXSKwN/LLrgcAszbsW8iwL7t72WkloeBWh56THr3iy1LJJIrp8YJLJuqBblQbBW3TFisVvTYUG02lHKKHtd5UeWOImjPZ6GwxatCP4SFgly4E1ilRBV0Jypcjzva4Xgvb+CJKw1ycTUDXIB9bpkUWBKJROKKEIKoxlFENY4iKTuJb49/y/9O/Y+Xt7/My9tfJsQ3hC71u9CzQU861+tMjxHNEUIQYV+/OOreNvy69Bh71p4h/kgqnQeF0KyTZu0xNfGlziNh5P6RQvrmeNL+d5q0/51GF+CBsaEPhoY+GBv5YGzgg+J1lb0aqhGjXqFJoBdNAr1KzWex2riUbXYKr+TMPFKz8p1iLDkzn5TMPA5eukxKZj4ZeSXP9TboBD4mPT4eemqZDPZ3bd/LqMfHpMPTqMfbqMPLWLDtadThZdTjZU/3MurxNOow6RUMOgWdtKRJJDVPYDlcBHW2jAqXtVpt6IQNm812RRascge5sKmF8lcIV2tPVbsIUuTHs7wWLEeQC/Pl8uV3xZJX/vNUFTd5kAuJRCK5Uup41WFy+GQeDXuUY5eOsePcDnZf3M3a02v55k8tumSgRyAdgjpQz6seLf1b0qFxB4a/1IGYpec4tuMCP312kODmfjSPrEuzTnXw8Tfh0T4Qzw5BWJJzyDmaSn5cGvlnM8k5WDDfV/HSow/0RB/ogS7QE32QJ3o/I0otI7paRoRJd9NZaPQ6hTq1TNSpVb4HjrlmK6lZ+aRmaWLscraZjFwzGXkWMnMtZORayMzT3jNyzZxPyyUryUJWnpaeay49cqQ7FAEmvQ4Pg4KHQYeHQRNfJoMOD72CUa9g1GnvBp320tKEc7sgTcGgExicebU8ekXBqBfoFU3QCQE6Iezb2rsiQK8omAxaPTpFFLyEQCm0rZVX7OkSyZVS4wSW1eawYFX8xtlitaEXKqrNWikLVkVdBC329WjK6yJYCF1ZLoJF9l0Fl9sw7aX0V7ktWMYbzIJl1IJ/SCQSiaRUhBC0CWhDm4A2TOwwEYvNQmxiLIdTDnM09ShHUo+wL3Efy/9c7izjgy9hHXoTZKuP+Vxzzq9IY+uK4wi9ilAE9dp5ERTsS4PGgdSOaoJvLQOeBoX8hEzMF7KwpORgScklLy4d6/4kKDpNWa+gq2VAV6tAdCleeoRRh2LUIYw6hFFBmHQoBp0myIxK4WM32BywongYdDSo7UmD2uVfDN0Vm00lx2wlO99Kdr7F/m4lJ99KVr6FnPyCY/lWmzYNw2Ijz2Il12wj12wl12J/N1vJM9vIyLVgttowW23kW2yYrSr5zm3H69oGYHMVXoooLMgUoX3fNUFGIUHnEGiObe1YwbZiF4LCXq4gHwiEi4OQQIA9vfA+CJf0gnKObVzEpqNuB+7KuKuPIuemaDnHvuOY/b9ix132nQ2xTzZUXdqk2Pu7PM9DyvvQpGg2RQj0dgHuODThliaY9JW4xy4HNU5gaXOwKhnkwqaiQ716Fizr9WrBKuVcZbXpSsK0XxMLlgxyIZFIJBVFr+jpUr8LXeoXBNdSVZXzWec5nHKY81nnScxO5FzmOeKyY9gRvAZzqiAkpSO1cgPQ24xkHWrL+dhsDnLBWYdNWLHq88n3yUL1sKBDj/A1Y2ygww8TPhjxQOChKPioRgxZFjwyc9ElgdEi0JmL+WCUjk6gmHQIgw6c4kvRBJhBQfHQOwWZaraieOpBJ7BlWVA8dCjeBoSHXrvZ0+7GEQra3Z8iEIr97tOxbd8X9rxaukt+Rz32G0Xsx4SueN2I8t+MloSiCLxNerxNeuDqPeS02VTMNrv4KiK8LI53m5ZmtWnTP2w2FauqYrWpqKp2z2ax2cizaC/X446XTVWLlS/Ip31nrUXSbaqWbrOXs6ra+Wwu57apBXWr9m2bS7rNBipamsVqQ0XLp73bxUehfa1exzFH0LNCx4rUYbHZcFk3vkj9rmUAl/1iee3buDmHvaRLm0tujytOIQnYrqGWvqdLIymwqorUhDjic+vzbb4J3vh32QVcOJetfRkST58st8AqbQ7WqVOn3EcGvFQP6ErqqQuF8lcspL7Lj2r6OYjfWfhw4mH47d2C/csuE9DP7i18DODcPpcdx1+VI4pgOf3gHRasrKTi9ZdFygnwqVexMleK3ggZFyre1vLg00ur+xqiq92Qju0LQmKPGzWMGU9Pq5ZzLVy8jJi9+/nondcqVX7zb78zbPxEmoU0JTs7h3p1g/j3k1MYcueAKm5pAVfa5tCO3Vj73RJat2zhTJv+zPM0CK7Pv6dPcVsmpENXYrasJSgwsNixffsPEtlnIGu/W8Idt/erVJuuOt51QKmewetqIYQYBHwA6ID5qqqWvFicpFSEEDTwaUADnwZuj9tUG2l5aaTmppKam0pKbgopaRe5fCGb3DQb5nSwZQqseSq6TE+ULANmm4opqTZWm+CyqidDLXpbU9xTRAH0AnRCuwnSC+Hc1gnHMYEeUIQNJUdFLwRGVYdOqPb8KnoU+z7oEdjsdQFYVNW5fS2xYb/Bdb5TsC+KpAsVm/2YcLmH0G6YBSpgU+x37DaBqthv8kXhe5Oidyqq65YAVRSkqqAJQVWAVQGhoipq8TwUL+O4occmUIUNRaegV4XmaeRQA86OULTMiqo1wKogBKh6VwXi8nmpRTb1KsWvDK3NOptW1ia0vtC5v1dTS/k6qI663eQpVptwuwl5Ou36hNZ/wiVToTqEu3e1UIYKaR5VgFVg01vB+V0oXJ/2v/0hAPbbR7Oi9aviUGOAVYBBLegPVaD9YalFqhUFn70VMBZxZVWLbKsCdI7vhcDxXcScBx7VM5ezxgms2uYUMnwakEEDyK1gYQX06alcPHuKJh3CylWkbt26+Pr6kp6eTpcu2pM8RVEICAjg1KlTnDp1yk2pRtrrxAUMBgOdOnXi0KFDdOzYsczzBQQEEBgYCB6+WoKxFmQlai9Pf8i5BJ4BmsDa8FLhwnoP8K4L5/Zqr6J4BkBOKvR/EZZNgE73aelBreHUZi26oGofzDo/CH+utbv12R+7eAdBUCs4sKz4uctDSO+Kl7kSglrD4e8r19ayuGM5ZFxli1wRPD1MxK5dVDgx43z1nCznMpizyl2/xWIpbLnNTqFP13DWfD0XgNhDxxj+96fxVLPo36d7NTSYK27zuLtvZ+mS//Li048CYLPZ+GblarZ9/2XJddqskHkRjMUt7NFL/kvvbhFER0dzR/c2Fb6c8mK1WivnluwOr0A0XXJjIoTQAR8DA4AEYLcQYrWqqoevbctuThSh4O/hj7+HP81pXnAgvHzlzVYzmfmZmPMt5GSaSU2/DF4WMhLzMXopZGeYMVvyybeZycs2Y1bysZhtmG1Wcq02rFkCm2c+1my784JV+5PEoj1lF55WVItAVVV0Fj02oxk1W4dVtYIqUGw6bGYLQhHYVIHVlItntieKyYxi1qHLNyKEimK/2ddZDNoNqc6KAHQWvVaP/d5POP9pt7wC4bx/FWhCURE6UG0IFZe8aCJFsaCz6dCpCoqqQ1EFCNWZRyBQEJq4ETZ0qs7p2uUqbRQ0ASMAnVWv1Y8NYdWuQ6iaWHEon6IawXVKk1Bdjxdsa4LPam+RorXJmaswxTSIsAtCR984LsAuIB3bruVtwqa1Ja80EVzgxKaUaPcsEKOaMAVKyV3a2Sp7zNkSUVjUlFfeV/QxgPOjroK6qqyOrMqdKy87j1q1fCpXuAxq3ELDFosZS75ZczmrxLXrTF4IRUGn15fbiuUOm81W5hws0MTYFd/smO1KUmcERbHbjt24vik6TSSVFNjBUb4oquo+jLrVUtjnVqcv3J6KojcVd6qtbirb1jI4cvwUbdtoN8k/rVvHhQtVa82qX78+d95xR6l5fHx9yUwvPscspFkzHrj/fn5Yswaz2cyKZcto06YNmZmZTHviCWL27EEIwYvPP8+oUaOIjo7mtTfeQFVV7ho8mDff0B7wL1iwgNfffJPg4GBatWyJyWTiow8/JCkpicmPPcZf8fEAvP/uu/Tq1YtZL73EuXPniIuLIygoiCWLCxaj3rx5M2+/8w5rfvjBmfbll1/yw5o1rPzuuxLrvJZtPnDgAGPHj+fIH384r+G5F15g66+/MnzECOITEsjNzeXJadN45JFHnH0fs2sXQUFBhT4TVVVp3rIlv6xbR5++fTl14gQeHlrY6jlvvcWi//4XRVG4c9Ag3nj9dU6cOMHkxx8nKSkJnU7HimXLiI+PL9SHU6dNo0vnzkycOJGQZs146MEH+fmXX5j6+ONkZGQwb/588vPzadG8OYu+/hovLy8uXrzI5Mce49Tp0wB88vHH/LR2LUFBQTz5xBMAzHzuOerVq8cT06Y5nPRL/R66cr0tNCyE6AHMUlX1Dvv+swCqqr5eUpmbcaFhiURSMqqqVlswlWL36EUtay64zomqsvMVOnXp98xCLdny5WiVTbU5z6PolGJ9pxb4HeIQiUIRWC02Z0WONGGf1wag2tQyXWJVm3YFiqI9JFHVqukzudCwHb3egF5vAEoPhVrdKIpS7sWKrxhDkfVDhCie5opSwfVGhHA/D0tXwtertHNfb1RXW4VwL1arkjLqz8nJISIy0rn/7LPPMnbsWACC6tRh7969/Oc//+Htd99l/vz5vPLqq/jVrs3BgwcBuHTpEucuXOCZZ59lz549+Pv7M3DgQFatXk337t158aWX2LNnD35+fvTr149OnTqBovDkU0/x1NNP07t3b/766y/uuOMOjhw5AkKwZ+9etm7diqdnkQnZilKszyK7dOGtd94ptc5r2eawiAgURWH/wYOEh4ezdPlyxo8fD4rClwsWEBAQQE5ODl27dmXUPfdolmfHtRb57LZt3UpoaCjNW7YkKiqKH9euZeTIkfz000+s+v57du7ciZeXF6mpqaAoTLjvPmbMmMGIESPIzc3FZrMRf/Zs4T50bNv3PTw92bp1KwApKSk8/KhmeXvuuef4YsECpk2bxhPTp9M3KoqVq1ZhtVrJzMykQaNGjBw5kienT8dms7F02TJ27dpV/d/vq0NDIN5lPwEoZjIVQjwCPALQpEmTooclEslNTHVGqixWd0nugdV1vkKnLuOMouw26Yp6NJRpntTQG0o3NIhyRH4USsEViHIG1LgSapzAkkiuN+68885rcl5PT09iY2PdHhs5ciQAnTt35rvvvgNg/fr1LF261JnH39+fX3/9laioKOrU0dawmTBhAr/++itAofSxY8fy559/Ous5fLjAwyo9PZ2MDG3ZhKFDhxYXVyXg+qStpDqvdZvHjx/P0qVLad++Pd9//z0vv/wyAHPnzmXlypUAxMfHc/z48QKB5Ybo6GjGjRsHwLhx41i0aBEjR45k/fr1PPjgg3h5aQ+MAgICyMjI4OzZs4wYMQLAaekqC4e4Bjh06BDPPfccly9fJjMzkzvs1tCNGzfy9ddfA9rcUD8/P/z8/AgMDGTfvn1cvHiRTp06lXotNxjuhuBiD2lVVZ0HzAPNglXdjZJIJBLJ9Y0UWBKJpBgmk2aR1Ol0zmiX7twgSnMnKOlJmM1mY/v27W5Fibe3NwArV67kpZe0uW/z5893W8++ffuc7mQl1Xk12+yO8ePHM3DgQPr27UtYWBh169Zl8+bNrF+/nu3bt+Pl5UVUVBS5uSW7olqtVr799ltWr17Nq6++iqqqpKSkkJGRUaHr0+v12FxCShU9p+t1TJw4kVWrVhEeHs7ChQvZvHlzie0DmDRpEgsXLuTChQs89NBDpea9wUgAGrvsNwLOXaO2SCQSieQG4abw4ZBIJNXPwIED+eijj5z7ly5donv37mzZsoXk5GSsVivR0dH07duX7t27s3nzZlJSUrR5XCtWlFiPOyvaiBEjiI2NJTY21hkcxpUDBw7wyiuvMGXKlFLrvJptdkfz5s0JDAxkxowZmnsgkJaWhr+/P15eXhw9epQdO3aUWsf69esJDw8nPj6euLg4zpw5w6hRo1i1ahUDBw7kyy+/JDs7G4DU1FR8fX1p1KgRq1atAiAvL4/s7GyaNm3K4cOHycvLIy0tjQ0bNpR4zoyMDIKDgzGbzSx2mVfWv39/PvnkE0ATfun2OXwjRoxg7dq17N6922ntuknYDbQUQoQKIYzAOGD1NW6TRCKRSK5zpMCSSGooOTk5REREOF8zZswoNf9zzz3HpUuX6NChA+Hh4WzatIng4GBef/11+vXrR3h4OJGRkQwbNozg4GBmzZpFjx49uP3224l0mes1d+5cYmJiCAsLo127dnz66aflau9vv/1Gp06daN26NVOmTGHu3Ln079+/1DqvdZtBs2IdPXrU6bI3aNAgLBYLYWFhPP/889xyyy2llo+OjnaWdTBq1CiWLFnCoEGDGDp0KF26dCEiIoK3334bgEWLFjF37lzCwsLo2bMnFy5coHHjxowZM4awsDAmTJigzS8rgVdeeYXu3bszYMAA2rQpiFj4wQcfsGnTJjp27Ejnzp35wx7Aw2g00q9fP8aMGVN1EQivA1RVtQBTgXXAEWC5qqp/XNtWSSQSieR6p8ZFEZRIrgfcRUuTSG5UbDYbkZGRrFixgpYtW1a6nustimBlkGOURCKR1BxKGqOkBUsikUgklebw4cO0aNGC/v37X5G4kkgkEonkZkEGuZBIJBJJpWnXrl0JC6ZLJBKJRFIzkRYsieQacaO550ok1Yn8e5BIJBLJzYIUWBLJNcDDw4OUlBR5UymRgDP0fHnX7JJIJBKJ5HpGughKJNeARo0akZCQQFJS0rVuikRyXeDh4UGjRo2udTMkEolEIrlipMCSSK4BBoOB0NDQa90MiUQikUgkEkkVI10EJRKJRCKRSCQSiaSKkAJLIpFIJBKJRCKRSKoIKbAkEolEIpFIJBKJpIoQN1oUMyFEEnDmCqsJApKroDk3G7JfiiP7pDiyT9wj+6U4VdEnTVVVrVMVjbkayDGqWpH9UhzZJ8WRfeIe2S/FqbYx6oYTWFWBECJGVdUu17od1xuyX4oj+6Q4sk/cI/ulOLJPKofsN/fIfimO7JPiyD5xj+yX4lRnn0gXQYlEIpFIJBKJRCKpIqTAkkgkEolEIpFIJJIqoqYKrHnXugHXKbJfiiP7pDiyT9wj+6U4sk8qh+w398h+KY7sk+LIPnGP7JfiVFuf1Mg5WBKJRCKRSCQSiURSHdRUC5ZEIpFIJBKJRCKRVDlSYEkkEolEIpFIJBJJFVHjBJYQYpAQ4pgQ4oQQYsa1bs/VQgjxpRAiUQhxyCUtQAjxixDiuP3d3+XYs/Y+OiaEuOPatLp6EUI0FkJsEkIcEUL8IYR40p5e0/vFQwixSwix394vL9nTa3S/AAghdEKIfUKINfb9Gt0nQog4IcRBIUSsECLGnlaj++RKkWOUHKMcyDHKPXKMKhk5RhXmmo5RqqrWmBegA04CzQAjsB9od63bdZWu/VYgEjjkkjYHmGHfngG8ad9uZ+8bExBq7zPdtb6GauiTYCDSvl0L+NN+7TW9XwTgY982ADuBW2p6v9iv9WlgCbDGvl+j+wSIA4KKpNXoPrnC/pRjlByjXPtEjlHu+0WOUSX3jRyjCvfHNRujapoFqxtwQlXVU6qq5gNLgWHXuE1XBVVVfwVSiyQPA76yb38FDHdJX6qqap6qqqeBE2h9d1Ohqup5VVX32rczgCNAQ2S/qKqqZtp3DfaXSg3vFyFEI+AuYL5Lco3ukxKQfVJ55BhVmBr9XZJjlHvkGOUeOUaVm6vSJzVNYDUE4l32E+xpNZV6qqqeB+2HHKhrT69x/SSECAE6oT0Jq/H9YncziAUSgV9UVZX9Au8D/wZsLmk1vU9U4GchxB4hxCP2tJreJ1eC7KPCyO+SHTlGFUaOUW55HzlGFeWajVH6yha8QRFu0mSc+uLUqH4SQvgA3wLTVVVNF8Ld5WtZ3aTdlP2iqqoViBBC1AZWCiE6lJL9pu8XIcQQIFFV1T1CiKjyFHGTdlP1iZ1eqqqeE0LUBX4RQhwtJW9N6ZMrQfZR+ahR/STHqOLIMaowcowqkWs2RtU0C1YC0NhlvxFw7hq15XrgohAiGMD+nmhPrzH9JIQwoA1ci1VV/c6eXOP7xYGqqpeBzcAgana/9AKGCiHi0Ny2bhNC/Jea3SeoqnrO/p4IrERzp6jRfXKFyD4qTI3/LskxqnTkGOVEjlFuuJZjVE0TWLuBlkKIUCGEERgHrL7GbbqWrAYesG8/AHzvkj5OCGESQoQCLYFd16B91YrQHgN+ARxRVfVdl0M1vV/q2J8KIoTwBG4HjlKD+0VV1WdVVW2kqmoI2u/GRlVV/0YN7hMhhLcQopZjGxgIHKIG90kVIMeowtTo75Ico9wjx6jiyDGqONd8jKrKaB03wgsYjBaJ5yQw81q35ypedzRwHjCjqfS/A4HABuC4/T3AJf9Mex8dA+681u2vpj7pjWb+PQDE2l+DZb8QBuyz98sh4AV7eo3uF5drjaIgQlON7RO0SHf77a8/HL+nNblPqqhf5RglxyjHNcoxyn2/yDGq9P6RY5R67ccoYa9QIpFIJBKJRCKRSCRXSE1zEZRIJBKJRCKRSCSSakMKLIlEIpFIJBKJRCKpIqTAkkgkEolEIpFIJJIqQgosiUQikUgkEolEIqkipMCSSCQSiUQikUgkkipCCiyJ5CoghLAKIWJdXjOqsO4QIcShqqpPIpFIJDULOUZJJFWL/lo3QCKpIeSoqhpxrRshkUgkEokb5BglkVQh0oIlkVxDhBBxQog3hRC77K8W9vSmQogNQogD9vcm9vR6QoiVQoj99ldPe1U6IcTnQog/hBA/21e3RwjxhBDisL2epdfoMiUSiURyAyLHKImkckiBJZFcHTyLuF+MdTmWrqpqN+Aj4H172kfA16qqhgGLgbn29LnAFlVVw4FItNXJAVoCH6uq2h64DIyyp88AOtnrmVw9lyaRSCSSGxw5RkkkVYhQVfVat0EiuekRQmSqqurjJj0OuE1V1VNCCANwQVXVQCFEMhCsqqrZnn5eVdUgIUQS0EhV1TyXOkKAX1RVbWnffwYwqKo6WwixFsgEVgGrVFXNrOZLlUgkEskNhhyjJJKqRVqwJJJrj1rCdkl53JHnsm2lYH7lXcDHQGdgjxBCzruUSCQSSUWQY5REUkGkwJJIrj1jXd6327d/B8bZtycAW+3bG4DHAIQQOiGEb0mVCiEUoLGqqpuAfwO1gWJPKCUSiUQiKQU5RkkkFUQ+KZBIrg6eQohYl/21qqo6wuCahBA70R54jLenPQF8KYT4F5AEPGhPfxKYJ4T4O9pTwMeA8yWcUwf8VwjhBwjgPVVVL1fR9UgkEonk5kGOURJJFSLnYEkk1xC7f3sXVVWTr3VbJBKJRCJxRY5REknlkC6CEolEIpFIJBKJRFJFSAuWRCKRSCQSiUQikVQR0oIlkUgkEolEIpFIJFWEFFgSiUQikUgkEolEUkVIgSWRSCQSiUQikUgkVYQUWBKJRCKRSCQSiURSRUiBJZFIJBKJRCKRSCRVxP8DnKpqlErG+wwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy and loss for all models\n",
    "def plot_metrics(history_dict):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for model_name, history in history_dict.items():\n",
    "        plt.plot(history.history['accuracy'], label=f'{model_name} Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label=f'{model_name} Val Accuracy')\n",
    "    plt.title('Accuracy Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for model_name, history in history_dict.items():\n",
    "        plt.plot(history.history['loss'], label=f'{model_name} Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label=f'{model_name} Val Loss')\n",
    "    plt.title('Loss Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the comparison metrics\n",
    "plot_metrics(history_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
